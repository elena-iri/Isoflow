{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27aa5acc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Real Latents: (2110, 50)\n",
      "Gen Latents:  torch.Size([1000, 50])\n",
      "Running UMAP on Latent Space...\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 43\u001b[39m\n\u001b[32m     40\u001b[39m reducer = umap.UMAP()\n\u001b[32m     42\u001b[39m \u001b[38;5;66;03m# Combine for joint reduction\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m43\u001b[39m combined = \u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mreal_latents\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgen_latents\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     44\u001b[39m labels = np.array([\u001b[33m\"\u001b[39m\u001b[33mReal\u001b[39m\u001b[33m\"\u001b[39m] * \u001b[38;5;28mlen\u001b[39m(real_latents) + [\u001b[33m\"\u001b[39m\u001b[33mGenerated\u001b[39m\u001b[33m\"\u001b[39m] * \u001b[38;5;28mlen\u001b[39m(gen_latents))\n\u001b[32m     46\u001b[39m embedding = reducer.fit_transform(combined)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/venv_1/lib/python3.11/site-packages/numpy/_core/shape_base.py:289\u001b[39m, in \u001b[36mvstack\u001b[39m\u001b[34m(tup, dtype, casting)\u001b[39m\n\u001b[32m    220\u001b[39m \u001b[38;5;129m@array_function_dispatch\u001b[39m(_vhstack_dispatcher)\n\u001b[32m    221\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mvstack\u001b[39m(tup, *, dtype=\u001b[38;5;28;01mNone\u001b[39;00m, casting=\u001b[33m\"\u001b[39m\u001b[33msame_kind\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m    222\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    223\u001b[39m \u001b[33;03m    Stack arrays in sequence vertically (row wise).\u001b[39;00m\n\u001b[32m    224\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    287\u001b[39m \n\u001b[32m    288\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m289\u001b[39m     arrs = \u001b[43matleast_2d\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43mtup\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    290\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arrs, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[32m    291\u001b[39m         arrs = (arrs,)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/venv_1/lib/python3.11/site-packages/numpy/_core/shape_base.py:121\u001b[39m, in \u001b[36matleast_2d\u001b[39m\u001b[34m(*arys)\u001b[39m\n\u001b[32m    119\u001b[39m res = []\n\u001b[32m    120\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m ary \u001b[38;5;129;01min\u001b[39;00m arys:\n\u001b[32m--> \u001b[39m\u001b[32m121\u001b[39m     ary = \u001b[43masanyarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mary\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    122\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m ary.ndim == \u001b[32m0\u001b[39m:\n\u001b[32m    123\u001b[39m         result = ary.reshape(\u001b[32m1\u001b[39m, \u001b[32m1\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/venv_1/lib/python3.11/site-packages/torch/_tensor.py:1211\u001b[39m, in \u001b[36mTensor.__array__\u001b[39m\u001b[34m(self, dtype)\u001b[39m\n\u001b[32m   1209\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(Tensor.__array__, (\u001b[38;5;28mself\u001b[39m,), \u001b[38;5;28mself\u001b[39m, dtype=dtype)\n\u001b[32m   1210\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1211\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1212\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1213\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.numpy().astype(dtype, copy=\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[31mRuntimeError\u001b[39m: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead."
     ]
    }
   ],
   "source": [
    "import scanpy as sc\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "import umap\n",
    "\n",
    "# --- 1. Load Data ---\n",
    "# We compare against the TRAINING latents (because that's what the flow learned)\n",
    "# Update this path to where your training data with latents is stored\n",
    "TRAIN_DATA_PATH = \"/dtu/blackhole/06/213542/paperdata/pbmc3k_train_with_latent.h5ad\"\n",
    "GEN_LATENT_PATH = \"/dtu/blackhole/06/213542/paperdata/simple_generated_latent.pt\" # Note: Load the latent, not counts!\n",
    "\n",
    "print(\"Loading data...\")\n",
    "adata_train = sc.read_h5ad(TRAIN_DATA_PATH)\n",
    "real_latents = adata_train.obsm[\"X_latent\"]\n",
    "\n",
    "# Load Generated Latents\n",
    "# (We need the output of the Flow model, before decoding)\n",
    "# If you haven't saved the intermediate latents in the new loop, you might need to grab them from the 'generated_full' tensor in the training notebook\n",
    "# For now, let's assume you saved it or can access the variable 'generated_full' directly if running in the same session.\n",
    "if 'generated_full' in locals():\n",
    "    gen_latents = generated_full.detach().cpu().numpy()\n",
    "else:\n",
    "    # If you saved it to a file in the previous step, load it here:\n",
    "    # You might need to update your training script to save 'generated_latent.pt' *after* the loop.\n",
    "    try:\n",
    "        gen_latents = torch.load(GEN_LATENT_PATH, map_location='cpu').detach().numpy()\n",
    "    except:\n",
    "        print(\"Could not find generated_latent.pt. Please ensure you save the 'generated_full' tensor in the training script.\")\n",
    "        # Stop here if we can't find data\n",
    "        gen_latents = None\n",
    "\n",
    "if gen_latents is not None:\n",
    "    print(f\"Real Latents: {real_latents.shape}\")\n",
    "    print(f\"Gen Latents:  {gen_latents.shape}\")\n",
    "\n",
    "    # --- 2. Run UMAP on Latents ---\n",
    "    print(\"Running UMAP on Latent Space...\")\n",
    "    reducer = umap.UMAP()\n",
    "    \n",
    "    # Combine for joint reduction\n",
    "    combined = np.vstack([real_latents, gen_latents])\n",
    "    labels = np.array([\"Real\"] * len(real_latents) + [\"Generated\"] * len(gen_latents))\n",
    "    \n",
    "    embedding = reducer.fit_transform(combined)\n",
    "\n",
    "    # --- 3. Plot ---\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    # Plot Real (Blue)\n",
    "    mask_real = labels == \"Real\"\n",
    "    plt.scatter(embedding[mask_real, 0], embedding[mask_real, 1], \n",
    "                c='tab:blue', s=10, alpha=0.3, label='Real (Train)')\n",
    "    \n",
    "    # Plot Generated (Orange)\n",
    "    mask_gen = labels == \"Generated\"\n",
    "    plt.scatter(embedding[mask_gen, 0], embedding[mask_gen, 1], \n",
    "                c='tab:orange', s=10, alpha=0.5, label='Generated')\n",
    "    \n",
    "    plt.legend()\n",
    "    plt.title(\"Latent Space Comparison (Flow Output)\")\n",
    "    plt.xlabel(\"UMAP 1\")\n",
    "    plt.ylabel(\"UMAP 2\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1284dc7b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
