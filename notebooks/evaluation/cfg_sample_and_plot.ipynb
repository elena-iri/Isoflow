{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Flow Sampling & Visualization\n",
    "\n",
    "**Description:** Sampling from the trained Flow model using Euler integration, decoding via VAE, and plotting UMAPs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import math\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import anndata as ad\n",
    "import scanpy as sc\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "from scvi.distributions import NegativeBinomial\n",
    "\n",
    "# Import VAE utils\n",
    "sys.path.append(\"../../\")\n",
    "from utils.autoencoder_utils import NB_Autoencoder\n",
    "\n",
    "# Set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration & Data Stats\n",
    "We load the data here primarily to recover cell type mappings and library size statistics for sampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file_path = \"/dtu/blackhole/06/213542/paperdata/pbmc3k_train_with_latent.h5ad\"\n",
    "vae_model_path = \"/dtu/blackhole/06/213542/paperdata/pbmc3k_train_nb_autoencoder.pt\"\n",
    "flow_model_save_path = \"/dtu/blackhole/06/213542/paperdata/lib_size_flow_model.pt\"\n",
    "\n",
    "# Sampling Hyperparameters\n",
    "guidance_scale = 2.0\n",
    "n_steps = 50 \n",
    "latent_dim = 50\n",
    "\n",
    "# Load Data for Reference\n",
    "adata = ad.read_h5ad(input_file_path)\n",
    "latent = adata.obsm[\"X_latent\"]\n",
    "latent_tensor = torch.tensor(latent, dtype=torch.float32, device=device)\n",
    "\n",
    "# Library Stats\n",
    "if \"total_counts\" in adata.obs:\n",
    "    lib_sizes = adata.obs[\"total_counts\"].values\n",
    "else:\n",
    "    lib_sizes = np.array(adata.X.sum(1)).flatten()\n",
    "\n",
    "log_lib_sizes = np.log1p(lib_sizes)\n",
    "log_lib_tensor = torch.tensor(log_lib_sizes, dtype=torch.float32, device=device).unsqueeze(1)\n",
    "lib_mean, lib_std = log_lib_tensor.mean(), log_lib_tensor.std()\n",
    "\n",
    "# Cell Type Mappings\n",
    "cell_types = adata.obs[\"cell_type\"].astype(str).values\n",
    "unique_types, inverse_idx = np.unique(cell_types, return_inverse=True)\n",
    "num_cell_types = len(unique_types)\n",
    "\n",
    "print(f\"Loaded metadata. {num_cell_types} cell types found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Re-defining Model Classes\n",
    "Required to load the model architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeEmbedder(nn.Module):\n",
    "    def __init__(self, embed_dim=32):\n",
    "        super().__init__()\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(embed_dim, embed_dim), nn.SiLU(),\n",
    "            nn.Linear(embed_dim, embed_dim), nn.SiLU()\n",
    "        )\n",
    "        self.embed_dim = embed_dim\n",
    "    def forward(self, t):\n",
    "        half_dim = self.embed_dim // 2\n",
    "        emb = math.log(10000) / (half_dim - 1)\n",
    "        emb = torch.exp(torch.arange(half_dim, device=t.device) * -emb)\n",
    "        emb = t * emb[None, :]\n",
    "        emb = torch.cat((torch.sin(emb), torch.cos(emb)), dim=1)\n",
    "        return self.mlp(emb)\n",
    "    \n",
    "class ResNetBlock(nn.Module):\n",
    "    def __init__(self, dim, hidden_dim):\n",
    "        super().__init__()\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(dim, hidden_dim), nn.SiLU(),\n",
    "            nn.Linear(hidden_dim, dim)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return x + self.mlp(x)\n",
    "\n",
    "class NeuralVectorField(nn.Module):\n",
    "    def __init__(self, latent_dim, hidden_dim=256, n_resblocks=5, time_embed_dim=64):\n",
    "        super().__init__()\n",
    "        self.x_proj = nn.Linear(latent_dim, hidden_dim)\n",
    "        self.c_proj = nn.Linear(latent_dim, hidden_dim)\n",
    "        self.l_proj = nn.Linear(1, hidden_dim)\n",
    "        self.time_embedder = TimeEmbedder(time_embed_dim)\n",
    "        self.null_cond = nn.Parameter(torch.randn(1, latent_dim))\n",
    "\n",
    "        input_dim = hidden_dim * 3 + time_embed_dim \n",
    "        self.resblocks = nn.ModuleList([\n",
    "            ResNetBlock(input_dim, hidden_dim * 3) for _ in range(n_resblocks)\n",
    "        ])\n",
    "        self.output_layer = nn.Sequential(\n",
    "            nn.Linear(hidden_dim * 3 + time_embed_dim, hidden_dim),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(hidden_dim, latent_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x, c, t, l):\n",
    "        xh = self.x_proj(x)\n",
    "        ch = self.c_proj(c) \n",
    "        th = self.time_embedder(t)\n",
    "        lh = self.l_proj(l) \n",
    "        h = torch.cat([xh, ch, lh, th], dim=-1)\n",
    "        for block in self.resblocks:\n",
    "            h = block(h)\n",
    "        return self.output_layer(h)\n",
    "\n",
    "class CellTypeConditioner(nn.Module):\n",
    "    def __init__(self, n_types, latent_dim):\n",
    "        super().__init__()\n",
    "        self.embed = nn.Embedding(n_types, latent_dim)\n",
    "    def forward(self, idx):\n",
    "        return self.embed(idx)\n",
    "\n",
    "# Euler Integration Class\n",
    "class LearnedVectorFieldODE:\n",
    "    def __init__(self, vf_model, conditioner, z_target_idx, l_target, guidance_scale=2.0):\n",
    "        self.vf = vf_model\n",
    "        self.c = conditioner(z_target_idx) # Embed the cell type indices\n",
    "        self.l = l_target\n",
    "        self.scale = guidance_scale\n",
    "        self.c_null = self.vf.null_cond.expand(self.c.shape[0], -1)\n",
    "    \n",
    "    def drift(self, x, t):\n",
    "        # Duplicate inputs for [Conditional, Unconditional] batching\n",
    "        x_in = torch.cat([x, x], dim=0)\n",
    "        t_in = torch.cat([t, t], dim=0)\n",
    "        l_in = torch.cat([self.l, self.l], dim=0)\n",
    "        \n",
    "        # Stack: [Conditioned, Null]\n",
    "        c_in = torch.cat([self.c, self.c_null], dim=0)\n",
    "        \n",
    "        # Forward Pass\n",
    "        v_out = self.vf(x_in, c_in, t_in, l_in)\n",
    "        v_cond, v_uncond = v_out.chunk(2, dim=0)\n",
    "        \n",
    "        # CFG Formula: v = v_uncond + s * (v_cond - v_uncond)\n",
    "        return v_uncond + self.scale * (v_cond - v_uncond)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Initialize and Load Flow Model\n",
    "conditioner = CellTypeConditioner(n_types=num_cell_types, latent_dim=latent_dim).to(device)\n",
    "vf_model = NeuralVectorField(latent_dim=latent_dim).to(device)\n",
    "\n",
    "checkpoint = torch.load(flow_model_save_path, map_location=device)\n",
    "vf_model.load_state_dict(checkpoint['vf_state'])\n",
    "conditioner.load_state_dict(checkpoint['cond_state'])\n",
    "print(\"Flow model loaded.\")\n",
    "\n",
    "# 2. Load VAE for Decoding\n",
    "vae = NB_Autoencoder(num_features=adata.n_vars, latent_dim=latent_dim)\n",
    "try:\n",
    "    vae.load_state_dict(torch.load(vae_model_path, map_location=device))\n",
    "    vae.to(device)\n",
    "    vae.eval()\n",
    "    print(\"VAE loaded successfully.\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"Warning: VAE model not found at {vae_model_path}. Decoding will fail.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sampling & Decoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_samples(target_type_idx, num_samples, fix_library_size=True):\n",
    "    vf_model.eval()\n",
    "    conditioner.eval()\n",
    "    \n",
    "    x = torch.randn(num_samples, latent_dim, device=device)\n",
    "    \n",
    "    # Conditions\n",
    "    type_tensor = torch.full((num_samples,), target_type_idx, dtype=torch.long, device=device)\n",
    "\n",
    "    if fix_library_size:\n",
    "        l_val = lib_mean.item()\n",
    "        l_tensor = torch.full((num_samples, 1), l_val, device=device)\n",
    "    else:\n",
    "        l_tensor = torch.normal(lib_mean.item(), lib_std.item(), (num_samples, 1), device=device)\n",
    "\n",
    "    # ODE Integration\n",
    "    ode = LearnedVectorFieldODE(vf_model, conditioner, type_tensor, l_tensor, guidance_scale)\n",
    "    dt = 1.0 / n_steps\n",
    "    t = torch.zeros(num_samples, 1, device=device)\n",
    "    \n",
    "    print(f\"Sampling {num_samples} cells (Type {target_type_idx})...\")\n",
    "    with torch.no_grad():\n",
    "        for _ in range(n_steps):\n",
    "            v = ode.drift(x, t)\n",
    "            x = x + v * dt\n",
    "            t = t + dt\n",
    "            \n",
    "    return x\n",
    "\n",
    "# Example single sampling run\n",
    "target_idx = 2\n",
    "n_gen = 200\n",
    "generated_latents = generate_samples(target_idx, n_gen)\n",
    "\n",
    "# Rescaling Logic\n",
    "std_orig = latent_tensor.std(dim=0)\n",
    "mean_orig = latent_tensor.mean(dim=0)\n",
    "std_gen = generated_latents.std(dim=0)\n",
    "mean_gen = generated_latents.mean(dim=0)\n",
    "\n",
    "generated_rescaled = (generated_latents - mean_gen) / std_gen * std_orig + mean_orig\n",
    "\n",
    "# Decode with Fixed Library Size\n",
    "target_lib_size = 1000 \n",
    "print(\"Decoding to counts...\")\n",
    "with torch.no_grad():\n",
    "    outputs = vae.decode(generated_rescaled, adata, target_lib_size)\n",
    "    mu = outputs[\"mu\"]\n",
    "    theta = torch.exp(outputs[\"theta\"])\n",
    "    nb_dist = NegativeBinomial(mu=mu, theta=theta)\n",
    "    X_gen_counts = nb_dist.sample().cpu().numpy()\n",
    "\n",
    "# Save single batch\n",
    "save_dir = \"/dtu/blackhole/06/213542/paperdata/\"\n",
    "counts_save_path = os.path.join(save_dir, \"new_generated_pbmc3k_counts.h5ad\")\n",
    "adata_gen = ad.AnnData(X=X_gen_counts)\n",
    "if 'adata' in globals():\n",
    "    adata_gen.var_names = adata.var_names\n",
    "    adata_gen.obs['cell_type'] = unique_types[target_idx]\n",
    "adata_gen.write(counts_save_path)\n",
    "print(f\"Saved generated counts to: {counts_save_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full Dataset Generation & Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_full_dataset(n_per_type=200):\n",
    "    \"\"\"\n",
    "    Generates samples for all cell types to create a full synthetic dataset.\n",
    "    \"\"\"\n",
    "    vf_model.eval()\n",
    "    conditioner.eval()\n",
    "    \n",
    "    all_latents = []\n",
    "    all_lib_sizes = []\n",
    "    all_types = []\n",
    "    \n",
    "    print(f\"Generating {n_per_type} cells per type for {len(unique_types)} types...\")\n",
    "    for idx, ct in enumerate(unique_types):\n",
    "        # Conditions\n",
    "        type_tensor = torch.full((n_per_type,), idx, dtype=torch.long, device=device)\n",
    "        l_tensor = torch.normal(lib_mean.item(), lib_std.item(), (n_per_type, 1), device=device)\n",
    "        \n",
    "        # Initial Noise\n",
    "        x = torch.randn(n_per_type, latent_dim, device=device)\n",
    "        \n",
    "        # Integration\n",
    "        ode = LearnedVectorFieldODE(vf_model, conditioner, type_tensor, l_tensor, guidance_scale=10.0)\n",
    "        dt = 1.0 / n_steps\n",
    "        t = torch.zeros(n_per_type, 1, device=device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for _ in range(n_steps):\n",
    "                v = ode.drift(x, t)\n",
    "                x = x + v * dt\n",
    "                t = t + dt\n",
    "        \n",
    "        all_latents.append(x)\n",
    "        all_lib_sizes.append(l_tensor)\n",
    "        all_types.extend([ct] * n_per_type)\n",
    "        \n",
    "    gen_latents_tensor = torch.cat(all_latents, dim=0)\n",
    "    gen_libs_tensor = torch.cat(all_lib_sizes, dim=0)\n",
    "    \n",
    "    # Rescaling\n",
    "    mean_gen = gen_latents_tensor.mean(dim=0)\n",
    "    std_gen = gen_latents_tensor.std(dim=0)\n",
    "    mean_orig = latent_tensor.mean(dim=0)\n",
    "    std_orig = latent_tensor.std(dim=0)\n",
    "    \n",
    "    gen_rescaled = (gen_latents_tensor - mean_gen) / std_gen * std_orig + mean_orig\n",
    "    \n",
    "    # Decode to Counts\n",
    "    lib_counts = torch.exp(gen_libs_tensor) - 1\n",
    "    \n",
    "    print(\"Decoding full dataset...\")\n",
    "    with torch.no_grad():\n",
    "        outputs = vae.decode(gen_rescaled, adata, lib_counts)\n",
    "        mu = outputs[\"mu\"]\n",
    "        theta = torch.exp(outputs[\"theta\"])\n",
    "        nb_dist = NegativeBinomial(mu=mu, theta=theta)\n",
    "        X_counts = nb_dist.sample().cpu().numpy()\n",
    "        \n",
    "    return X_counts, np.array(all_types)\n",
    "\n",
    "# Generate and Save\n",
    "X_gen_all, types_gen_all = generate_full_dataset(n_per_type=250)\n",
    "\n",
    "adata_gen = ad.AnnData(X=X_gen_all)\n",
    "adata_gen.obs['cell_type'] = types_gen_all\n",
    "adata_gen.obs['dataset'] = 'Generated'\n",
    "adata_gen.var_names = adata.var_names\n",
    "\n",
    "save_gen_path = os.path.join(os.path.dirname(flow_model_save_path), \"generated_cells.h5ad\")\n",
    "adata_gen.write(save_gen_path)\n",
    "print(f\"Saved all generated cells to: {save_gen_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting Results (Figure A2 Style)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare Merged Dataset\n",
    "adata_real = adata.copy()\n",
    "adata_real.obs['dataset'] = 'Real'\n",
    "if hasattr(adata_real.X, \"toarray\"):\n",
    "    adata_real.X = adata_real.X.toarray()\n",
    "\n",
    "adata_merged = ad.concat([adata_real, adata_gen], join='outer', label='batch', keys=['Real', 'Generated'])\n",
    "adata_merged.obs['cell_type'] = adata_merged.obs['cell_type'].astype('category')\n",
    "\n",
    "# Preprocessing & Embedding\n",
    "print(\"Running PCA and UMAP on merged dataset...\")\n",
    "sc.pp.normalize_total(adata_merged, target_sum=1e4)\n",
    "sc.pp.log1p(adata_merged)\n",
    "sc.pp.pca(adata_merged, n_comps=30)\n",
    "sc.pp.neighbors(adata_merged, n_neighbors=15)\n",
    "sc.tl.umap(adata_merged)\n",
    "\n",
    "# Visualization\n",
    "print(\"\\n--- Starting Visualization Generation ---\")\n",
    "highlight_types = ['B cells', 'CD14+ Monocytes', 'CD4 T cells', 'CD8 T cells']\n",
    "\n",
    "fig = plt.figure(figsize=(18, 10))\n",
    "gs = gridspec.GridSpec(2, 3, figure=fig)\n",
    "\n",
    "def plot_umap_scatter(ax, adata_subset, color_col, title, palette=None, s=10):\n",
    "    sc.pl.umap(adata_subset, color=color_col, ax=ax, show=False, \n",
    "               title=title, frameon=True, s=s, palette=palette, legend_loc='on data')\n",
    "    ax.set_xlabel(\"UMAP1\")\n",
    "    ax.set_ylabel(\"UMAP2\")\n",
    "\n",
    "# Panel 1: Real Data\n",
    "ax1 = fig.add_subplot(gs[0, 0])\n",
    "plot_umap_scatter(ax1, adata_merged[adata_merged.obs['dataset']=='Real'], \n",
    "                  'cell_type', 'Real Data')\n",
    "\n",
    "# Panel 2: Generated Data\n",
    "ax2 = fig.add_subplot(gs[0, 1])\n",
    "plot_umap_scatter(ax2, adata_merged[adata_merged.obs['dataset']=='Generated'], \n",
    "                  'cell_type', 'Generated (All)')\n",
    "\n",
    "def plot_overlap(ax, c_type):\n",
    "    mask_r = (adata_merged.obs['dataset'] == 'Real') & (adata_merged.obs['cell_type'] == c_type)\n",
    "    mask_g = (adata_merged.obs['dataset'] == 'Generated') & (adata_merged.obs['cell_type'] == c_type)\n",
    "    \n",
    "    umap_r = adata_merged[mask_r].obsm['X_umap']\n",
    "    umap_g = adata_merged[mask_g].obsm['X_umap']\n",
    "    \n",
    "    ax.scatter(umap_r[:, 0], umap_r[:, 1], s=15, c='#377eb8', alpha=0.5, label='Real')\n",
    "    ax.scatter(umap_g[:, 0], umap_g[:, 1], s=15, c='#e41a1c', alpha=0.6, label='Generated')\n",
    "    \n",
    "    ax.set_title(c_type)\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "\n",
    "# Overlap Panels\n",
    "locs = [(0, 2), (1, 0), (1, 1), (1, 2)]\n",
    "for i, c_type in enumerate(highlight_types):\n",
    "    if i >= len(locs): break\n",
    "    ax = fig.add_subplot(gs[locs[i]])\n",
    "    plot_overlap(ax, c_type)\n",
    "    if i == 0:\n",
    "        ax.legend(frameon=False, loc='upper right', markerscale=2)\n",
    "\n",
    "plt.tight_layout()\n",
    "save_plot_path = os.path.join(os.path.dirname(flow_model_save_path), \"cfgen_results_figure_a2.png\")\n",
    "plt.savefig(save_plot_path, dpi=300)\n",
    "print(f\"Figure saved to {save_plot_path}\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}