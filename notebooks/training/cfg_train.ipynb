{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifier-Free Guidance.\n",
    "\n",
    "**Description:** Training the Flow Matching model with Classifier-Free Guidance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import math\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import anndata as ad\n",
    "import matplotlib.pyplot as plt\n",
    "sys.path.append(\"../../\")\n",
    "from utils.autoencoder_utils import NB_Autoencoder\n",
    "from utils.classifier_free_guidance import *\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration & Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Shape: (2110, 50)\n",
      "Library Size: Min=6.49, Max=7.86, Mean=7.42\n",
      "Cell Types: ['B cells' 'CD14+ Monocytes' 'CD4 T cells' 'CD8 T cells' 'Dendritic cells'\n",
      " 'FCGR3A+ Monocytes' 'Megakaryocytes' 'NK cells']\n"
     ]
    }
   ],
   "source": [
    "# Paths\n",
    "input_file_path = \"/dtu/blackhole/06/213542/paperdata/pbmc3k_train_with_latent.h5ad\"\n",
    "flow_model_save_path = \"/dtu/blackhole/06/213542/paperdata/lib_size_flow_model.pt\"\n",
    "\n",
    "os.makedirs(os.path.dirname(flow_model_save_path), exist_ok=True)\n",
    "\n",
    "# Hyperparameters\n",
    "batch_size = 256\n",
    "num_epochs = 400\n",
    "learning_rate = 5e-4\n",
    "latent_dim = 50\n",
    "p_uncond = 0.1   # Classifier-free guidance dropout probability\n",
    "\n",
    "# Load Data\n",
    "adata = ad.read_h5ad(input_file_path)\n",
    "latent = adata.obsm[\"X_latent\"]\n",
    "latent_tensor = torch.tensor(latent, dtype=torch.float32, device=device)\n",
    "\n",
    "# Library Sizes\n",
    "if \"total_counts\" in adata.obs:\n",
    "    lib_sizes = adata.obs[\"total_counts\"].values\n",
    "else:\n",
    "    lib_sizes = np.array(adata.X.sum(1)).flatten()\n",
    "\n",
    "log_lib_sizes = np.log1p(lib_sizes)\n",
    "log_lib_tensor = torch.tensor(log_lib_sizes, dtype=torch.float32, device=device).unsqueeze(1)\n",
    "\n",
    "# Stats for normalization (needed for training context if we normalize, but mostly for sampling later)\n",
    "lib_min, lib_max = log_lib_tensor.min(), log_lib_tensor.max()\n",
    "lib_mean, lib_std = log_lib_tensor.mean(), log_lib_tensor.std()\n",
    "\n",
    "# Cell Types\n",
    "cell_types = adata.obs[\"cell_type\"].astype(str).values\n",
    "unique_types, inverse_idx = np.unique(cell_types, return_inverse=True)\n",
    "num_cell_types = len(unique_types)\n",
    "cell_type_idx = torch.tensor(inverse_idx, dtype=torch.long, device=device)\n",
    "\n",
    "print(f\"Data Shape: {latent.shape}\")\n",
    "print(f\"Library Size: Min={lib_min:.2f}, Max={lib_max:.2f}, Mean={lib_mean:.2f}\")\n",
    "print(f\"Cell Types: {unique_types}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting CFG Training...\n",
      "[0] Loss: 1.435534\n",
      "[50] Loss: 0.866035\n",
      "[100] Loss: 0.762702\n",
      "[150] Loss: 0.739563\n",
      "[200] Loss: 0.733395\n",
      "[250] Loss: 0.729226\n",
      "[300] Loss: 0.729674\n",
      "[350] Loss: 0.729088\n",
      "Saved models to /dtu/blackhole/06/213542/paperdata/lib_size_flow_model.pt\n"
     ]
    }
   ],
   "source": [
    "# Initialisation\n",
    "emp_dist = EmpiricalDistribution(latent_tensor)\n",
    "latent_dim = latent_tensor.shape[1]\n",
    "\n",
    "# Initialize models\n",
    "conditioner = CellTypeConditioner(n_types=num_cell_types, latent_dim=latent_dim).to(device)\n",
    "vf_model = NeuralVectorField(latent_dim=latent_dim).to(device)\n",
    "\n",
    "# Optimize both model and conditioner\n",
    "optimizer = torch.optim.AdamW(list(vf_model.parameters()) + list(conditioner.parameters()), lr=learning_rate)\n",
    "\n",
    "epochs_list = []\n",
    "loss_list = []\n",
    "\n",
    "print(\"Starting CFG Training...\")\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # 1. Sample Indices and Data\n",
    "    indices = torch.randint(0, latent_tensor.shape[0], (batch_size,))\n",
    "    z = latent_tensor[indices].to(device)          # Target (Data)\n",
    "    c_idx = cell_type_idx[indices].to(device)      # Condition (Cell Type)\n",
    "    l = log_lib_tensor[indices].to(device)         # Condition (Library Size)\n",
    "\n",
    "    # 2. Sample Noise and Time\n",
    "    x = torch.randn(batch_size, latent_dim, device=device)\n",
    "    t = torch.rand(batch_size, 1, device=device)\n",
    "    \n",
    "    # 3. Compute Flow Target (Noise -> Data)\n",
    "    u_target = z - x \n",
    "    \n",
    "    # Normalize target\n",
    "    u_mean = u_target.mean(dim=0, keepdim=True)\n",
    "    u_std = u_target.std(dim=0, keepdim=True) + 1e-6\n",
    "    u_target_norm = (u_target - u_mean) / u_std\n",
    "    \n",
    "    # 4. CFG: Condition masking\n",
    "    c_emb = conditioner(c_idx)\n",
    "    \n",
    "    # Create mask (1 = drop condition, 0 = keep condition)\n",
    "    mask = (torch.rand(batch_size, 1, device=device) < p_uncond).float()\n",
    "    \n",
    "    # Apply Mask: Replace dropped conditions with null_cond\n",
    "    c_input = mask * vf_model.null_cond.expand(batch_size, -1) + (1 - mask) * c_emb\n",
    "    \n",
    "    # 5. Forward pass\n",
    "    v_pred = vf_model(x, c_input, t, l)\n",
    "    \n",
    "    # 6. Loss\n",
    "    loss = F.mse_loss(v_pred, u_target_norm)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    torch.nn.utils.clip_grad_norm_(vf_model.parameters(), 1.0)\n",
    "    optimizer.step()\n",
    "    \n",
    "    epochs_list.append(epoch)\n",
    "    loss_list.append(loss.item())\n",
    "    \n",
    "    if epoch % 50 == 0:\n",
    "        print(f\"[{epoch}] Loss: {loss.item():.6f}\")\n",
    "\n",
    "# Save Models\n",
    "torch.save({\n",
    "    'vf_state': vf_model.state_dict(),\n",
    "    'cond_state': conditioner.state_dict()\n",
    "}, flow_model_save_path)\n",
    "print(f\"Saved models to {flow_model_save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ed8e49f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
