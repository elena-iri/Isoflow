{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a076340e-f762-43f8-83b3-d57bf4f43af2",
   "metadata": {},
   "source": [
    "# Training of the flow matching model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e43b027b-4538-46d1-8106-512436554998",
   "metadata": {},
   "source": [
    "In this script we will train the flow matching model.\n",
    "For this purpose we will use the training data already encoded in a 50 dimension space."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "676047f1-cc46-491a-a20d-b0d1c6362468",
   "metadata": {},
   "source": [
    "- Loading libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1207d54f-991f-42c1-8874-175aafd89f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from abc import ABC, abstractmethod\n",
    "from typing import Optional #, List, Type, Tuple, Dict\n",
    "import math\n",
    "import anndata as ad\n",
    "#import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "#import matplotlib.cm as cm\n",
    "#from matplotlib.axes._axes import Axes\n",
    "import torch\n",
    "import torch.distributions as D\n",
    "#from torch.func import vmap, jacrev\n",
    "#from tqdm import tqdm\n",
    "#import seaborn as sns\n",
    "#from sklearn.datasets import make_moons, make_circles\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a3c52a8-12c0-4707-85c0-b2957b475d9b",
   "metadata": {},
   "source": [
    "- Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e98a63f9-469b-4f22-9da0-a88d91f27b7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of latent space: (2110, 50)\n",
      "[[-1.4144031   1.3279299   0.757624   ...  1.9632016   3.2006185\n",
      "   1.0286264 ]\n",
      " [-3.0197775  -1.5338613   1.2328798  ... -1.762154    3.0394304\n",
      "  -0.13480194]\n",
      " [-2.9895246  -0.5492041   0.01084488 ...  1.2618108  -1.4493724\n",
      "   0.35208455]\n",
      " ...\n",
      " [ 1.2099221   0.04875063 -0.70176685 ...  1.5337447   1.6093717\n",
      "  -0.77522033]\n",
      " [ 0.16601333  0.13243417  1.3788003  ...  0.4668453  -1.8225284\n",
      "   0.20945628]\n",
      " [-2.644291    0.13521816  0.795208   ... -0.2699267   1.9044281\n",
      "  -2.3405967 ]]\n"
     ]
    }
   ],
   "source": [
    "# Load the encoded data from the autoencoder\n",
    "data_dir = \"/dtu/blackhole/1e/213566/data/datasets/pbmc3k/\"\n",
    "input_file_path = data_dir + \"pbmc3k_train_with_latent.h5ad\"\n",
    "adata = ad.read_h5ad(input_file_path)\n",
    "\n",
    "# Access latent representation\n",
    "latent = adata.obsm[\"X_latent\"]\n",
    "# make it to a tensor and save in GPU\n",
    "latent_tensor = torch.tensor(latent, dtype=torch.float32, device = device)\n",
    "print(\"Shape of latent space:\", latent.shape)\n",
    "print(latent)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b15f8bc-9816-4525-8bee-a6df32baf3fd",
   "metadata": {},
   "source": [
    "### Defining the flow model classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2569d01-79f5-44c9-a09f-e2d82049488e",
   "metadata": {},
   "source": [
    "- Training data **empirical distribution** class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2d9554cd-e92b-4ffd-a307-89cfcadca6ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmpiricalDistribution(torch.nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        data: torch.Tensor, #data inputted must be a torch tensor\n",
    "        bandwidth: Optional[float] = None,\n",
    "        compute_log_density: bool = True,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        assert data.dim() == 2, \"data must be shape (N, D)\"\n",
    "        data = data.contiguous()\n",
    "        \n",
    "        self.register_buffer(\"data\", data)   # (N, D)\n",
    "        self.n = data.shape[0]\n",
    "        self.data_dim = data.shape[1]        # <-- renamed attribute\n",
    "        self.compute_log_density_flag = compute_log_density\n",
    "\n",
    "        # Bandwidth estimation\n",
    "        if bandwidth is None:\n",
    "            std = torch.std(data, dim=0).mean().item()\n",
    "            factor = (4.0 / (self.data_dim + 2.0)) ** (1.0 / (self.data_dim + 4.0))\n",
    "            bw = factor * (self.n ** (-1.0 / (self.data_dim + 4.0))) * (std + 1e-6)\n",
    "            self.bandwidth = torch.tensor(float(bw), device=self.data.device)\n",
    "        else:\n",
    "            self.bandwidth = torch.tensor(float(bandwidth), device=self.data.device)\n",
    "\n",
    "        self._log_const = -0.5 * self.data_dim * math.log(2.0 * math.pi) - self.data_dim * torch.log(self.bandwidth).item()\n",
    "\n",
    "    @property\n",
    "    def dim(self):\n",
    "        return self.data_dim\n",
    "    def sample(self, num_samples: int) -> torch.Tensor:\n",
    "        idx = torch.randint(0, self.n, (num_samples,), device=self.data.device)\n",
    "        return self.data[idx]\n",
    "\n",
    "    def log_density(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        if not self.compute_log_density_flag:\n",
    "            raise RuntimeError(\"log_density disabled (compute_log_density=False).\")\n",
    "\n",
    "        assert x.dim() == 2 and x.shape[1] == self.data_dim\n",
    "\n",
    "        x = x.to(self.data.device)\n",
    "        x_norm2 = (x ** 2).sum(dim=1, keepdim=True)\n",
    "        data_norm2 = (self.data ** 2).sum(dim=1).unsqueeze(0)\n",
    "        cross = x @ self.data.t()\n",
    "        d2 = x_norm2 + data_norm2 - 2.0 * cross\n",
    "\n",
    "        sigma2 = (self.bandwidth ** 2).item()\n",
    "        exponents = -0.5 * d2 / (sigma2 + 1e-12)\n",
    "        lse = torch.logsumexp(exponents, dim=1, keepdim=True)\n",
    "\n",
    "        log_prob = math.log(1.0 / self.n) + lse + self._log_const\n",
    "        return log_prob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72f72b90-9672-44bf-9358-24f026c2ea3a",
   "metadata": {},
   "source": [
    "Testing of empirical distribution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cbd6c723-2603-4ee4-a2e4-4444bf07beb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.7671, -0.8103,  0.2970,  1.6390,  0.1274, -1.2363,  1.9235, -4.3299,\n",
      "          2.1813, -3.8893,  0.7677, -1.5698,  0.9597,  0.5786,  0.6900,  1.3617,\n",
      "          0.2969, -1.1785, -1.9800, -0.7150,  3.2856, -0.6615,  0.4548,  1.5628,\n",
      "         -0.4066, -2.9041,  2.1282,  1.0879,  0.4325,  1.0976, -0.2116, -3.0244,\n",
      "          1.7222,  1.2245,  0.5542, -2.2088,  0.6585,  0.2948, -3.8150,  1.0588,\n",
      "         -1.5514, -2.2644, -1.5104,  2.4733,  1.2375, -0.0816,  0.7579, -0.0564,\n",
      "          0.9352, -0.7903],\n",
      "        [-2.5925,  0.7356,  0.7758, -0.5614, -0.7704,  1.4198, -1.4670,  0.0695,\n",
      "         -1.8360, -3.5882,  1.8434, -0.3252, -0.6560, -2.3070, -0.5978, -0.4421,\n",
      "         -0.0694, -0.0385, -1.9725,  2.1604, -1.2356,  0.2688,  1.5906, -0.4997,\n",
      "          0.4905, -0.4472,  3.0207, -0.7605,  0.7823, -2.0035,  0.0756, -2.1183,\n",
      "          0.1849,  3.1985,  0.5716, -2.4397, -2.9252,  2.3158,  0.3504, -0.1939,\n",
      "          0.5654, -0.9013,  2.5226, -1.1669, -2.0652,  0.4353,  0.7351,  1.4710,\n",
      "          1.3175,  1.0595],\n",
      "        [-1.2393, -0.6354,  2.0811, -1.9447,  3.8953, -1.8863,  0.2157,  0.3794,\n",
      "          0.7542,  1.3119, -0.0178, -0.8172, -1.4652,  1.9249,  2.4468, -1.6272,\n",
      "          0.9094,  2.4539,  1.9311,  0.7275,  0.6850, -0.0486, -0.7737,  0.7894,\n",
      "         -1.5112,  0.3244, -2.0540,  1.0615, -1.1976,  0.5557,  3.3610, -3.2025,\n",
      "         -0.3922,  1.6544, -0.6337,  1.8787, -1.1690,  1.9559, -2.5942,  0.9479,\n",
      "          0.8060,  4.4884, -0.6192,  0.3528,  0.0332, -1.0125,  2.5043, -0.5774,\n",
      "          4.2870, -0.9216]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# lets test if the empirical distribution class actually works by sampling from it\n",
    "\n",
    "dist = EmpiricalDistribution(latent_tensor)\n",
    "samples = dist.sample(3)\n",
    "print(samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caf21e2b-de0f-424d-95a6-e50ed4c990ee",
   "metadata": {},
   "source": [
    "- **Gaussian distribution** class to draw from the noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7cbc68f2-372e-428d-b98e-4d1f3a4d9b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Gaussian(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Multivariate Gaussian distribution\n",
    "    \"\"\"\n",
    "    def __init__(self, mean: torch.Tensor, cov: torch.Tensor):\n",
    "        \"\"\"\n",
    "        mean: shape (dim,)\n",
    "        cov: shape (dim,dim)\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.register_buffer(\"mean\", mean)\n",
    "        self.register_buffer(\"cov\", cov)\n",
    "\n",
    "    @property\n",
    "    def dim(self) -> int:\n",
    "        return self.mean.shape[0]\n",
    "\n",
    "    @property\n",
    "    def distribution(self):\n",
    "        return D.MultivariateNormal(self.mean, self.cov, validate_args=False)\n",
    "\n",
    "    def sample(self, num_samples) -> torch.Tensor:\n",
    "        return self.distribution.sample((num_samples,))\n",
    "        \n",
    "    def log_density(self, x: torch.Tensor):\n",
    "        return self.distribution.log_prob(x).view(-1, 1)\n",
    "\n",
    "    @classmethod\n",
    "    def isotropic(cls, dim: int, std: float) -> \"Gaussian\":\n",
    "        mean = torch.zeros(dim)\n",
    "        cov = torch.eye(dim) * std ** 2\n",
    "        return cls(mean, cov)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afdb31e9-4b1e-4769-b8d6-a4a0590edc17",
   "metadata": {},
   "source": [
    "- **Alpha** and **beta** classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3f10e95-090c-43e7-89be-1b8563cdfc1e",
   "metadata": {},
   "source": [
    "We use $\\alpha_t$ and $\\beta_t$ to schedule the noise in the Gaussian probability paths.\n",
    "\n",
    "These are two continuously differentiable, monotonic functions that follow:\n",
    "\n",
    "$\\alpha_0$ = $\\beta_1$ = 0     and     $\\alpha_1$ = $\\beta_0$ = 1.\n",
    "\n",
    "We have chosen a linear form with a simple derivative:\n",
    "\n",
    "$\\alpha_t$ = t ; $\\alpha_t$' = 1\n",
    "\n",
    "$\\beta_t$ = 1 - t ; $\\beta_t$' = -1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3433c200-5e40-4dc6-8fca-201b13c7b531",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We want to go with Gaussian probability path, therefore we need to load functions for alpha and beta\n",
    "class LinearAlpha():\n",
    "    \"\"\"Implements alpha_t = t\"\"\"\n",
    "    \n",
    "    def __call__(self, t: torch.Tensor) -> torch.Tensor:\n",
    "        return t  # linear in time\n",
    "\n",
    "    def dt(self, t: torch.Tensor) -> torch.Tensor:\n",
    "        return torch.ones_like(t)  # derivative of t is 1\n",
    "\n",
    "\n",
    "class LinearBeta():\n",
    "    \"\"\"Implements beta_t = 1 - t\"\"\"\n",
    "    \n",
    "    def __call__(self, t: torch.Tensor) -> torch.Tensor:\n",
    "        return 1 - t\n",
    "\n",
    "    def dt(self, t: torch.Tensor) -> torch.Tensor:\n",
    "        return -torch.ones_like(t)  # derivative of 1 - t is -1\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a050fb6b-4c77-4587-9f4a-c993f6e7431d",
   "metadata": {},
   "source": [
    "- **Gaussian probability path** class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "98ba9fdd-c53b-4e8e-b80d-a142773b04aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GaussianConditionalProbabilityPath():\n",
    "    def __init__(self, p_data, alpha, beta):\n",
    "        self.p_data = p_data \n",
    "        p_simple = Gaussian.isotropic(p_data.dim, 1.0)\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "\n",
    "    def sample_conditioning_variable(self, num_samples: int) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Samples the conditioning variable z ~ p_data(x)\n",
    "        Args:\n",
    "            - num_samples: the number of samples\n",
    "        Returns:\n",
    "            - z: samples from p(z), (num_samples, dim)\n",
    "        \"\"\"\n",
    "        return self.p_data.sample(num_samples)\n",
    "    \n",
    "    def sample_conditional_path(self, z: torch.Tensor, t: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Samples from the conditional distribution p_t(x|z) = N(alpha_t * z, beta_t**2 * I_d)\n",
    "        Args:\n",
    "            - z: conditioning variable (num_samples, dim)\n",
    "            - t: time (num_samples, 1)\n",
    "        Returns:\n",
    "            - x: samples from p_t(x|z), (num_samples, dim)\n",
    "        \"\"\"\n",
    "        return self.alpha(t) * z + self.beta(t) * torch.randn_like(z)\n",
    "        \n",
    "    def conditional_vector_field(self, x: torch.Tensor, z: torch.Tensor, t: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Evaluates the conditional vector field u_t(x|z)\n",
    "        Note: Only defined on t in [0,1)\n",
    "        Args:\n",
    "            - x: position variable (num_samples, dim)\n",
    "            - z: conditioning variable (num_samples, dim)\n",
    "            - t: time (num_samples, 1)\n",
    "        Returns:\n",
    "            - conditional_vector_field: conditional vector field (num_samples, dim)\n",
    "        \"\"\" \n",
    "        alpha_t = self.alpha(t) # (num_samples, 1)\n",
    "        beta_t = self.beta(t) # (num_samples, 1)\n",
    "        dt_alpha_t = self.alpha.dt(t) # (num_samples, 1)\n",
    "        dt_beta_t = self.beta.dt(t) # (num_samples, 1)\n",
    "\n",
    "        return (dt_alpha_t - dt_beta_t / beta_t * alpha_t) * z + dt_beta_t / beta_t * x\n",
    "\n",
    "    def conditional_score(self, x: torch.Tensor, z: torch.Tensor, t: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Evaluates the conditional score of p_t(x|z) = N(alpha_t * z, beta_t**2 * I_d)\n",
    "        Note: Only defined on t in [0,1)\n",
    "        Args:\n",
    "            - x: position variable (num_samples, dim)\n",
    "            - z: conditioning variable (num_samples, dim)\n",
    "            - t: time (num_samples, 1)\n",
    "        Returns:\n",
    "        - conditional_score: conditional score (num_samples, dim)\n",
    "        \"\"\" \n",
    "        alpha_t = self.alpha(t)\n",
    "        beta_t = self.beta(t)\n",
    "        return (z * alpha_t - x) / beta_t ** 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ec9d082-03e5-4938-bdda-e4648270bddc",
   "metadata": {},
   "source": [
    "- **Marginal vector field** class using the Euler method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "40eeef4d-a9d8-4815-af8c-fec7c41e3aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we somehow want to model the marginal vector field from the conditonal vector field\n",
    "# for that we will use eulers:\n",
    "class EulerSimulator():\n",
    "    def __init__(self, ode, z: torch.Tensor, u_mean, u_std):\n",
    "        self.ode = ode\n",
    "        self.z = z\n",
    "        self.u_mean = u_mean\n",
    "        self.u_std = u_std\n",
    "\n",
    "    def step(self, xt: torch.Tensor, t: torch.Tensor, h: float):\n",
    "        # Expand z to match batch size\n",
    "        if self.z.shape[0] == 1:\n",
    "            z_exp = self.z.expand(xt.shape[0], -1)\n",
    "        else:\n",
    "            z_exp = self.z\n",
    "\n",
    "        # Get normalized drift from model\n",
    "        dx_norm = self.ode.drift_coefficient(xt, t, z_exp)\n",
    "\n",
    "        # Un-normalize to match the real vector field scale\n",
    "        dx = dx_norm * self.u_std + self.u_mean\n",
    "\n",
    "        # Euler update\n",
    "        return xt + dx * h"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48117493-9b52-4e5d-8a72-e02524a9863f",
   "metadata": {},
   "source": [
    "- **Time** embedder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f9800bb9-9fb3-495e-8bf0-cd054df473d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeEmbedder(nn.Module):\n",
    "    def __init__(self, embed_dim=64, max_freq=1e4):\n",
    "        super().__init__()\n",
    "        self.embed_dim = embed_dim\n",
    "        self.max_freq = max_freq\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(embed_dim, embed_dim*2),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(embed_dim*2, embed_dim*2),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(embed_dim*2, embed_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, t):\n",
    "        freqs = torch.exp(torch.linspace(0, math.log(self.max_freq), self.embed_dim // 2, device=t.device))\n",
    "        args = t * freqs\n",
    "        emb = torch.cat([torch.sin(args), torch.cos(args)], dim=-1)\n",
    "        return self.mlp(emb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ad5cbfd-4285-4c37-8794-e7388673bbf7",
   "metadata": {},
   "source": [
    "- **ResNetBlock** class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "419a9677-716a-4fea-b001-cd68903d73d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNetBlock(nn.Module):\n",
    "    def __init__(self, dim, hidden_dim=None):\n",
    "        super().__init__()\n",
    "        hidden_dim = hidden_dim or dim*2\n",
    "        self.block = nn.Sequential(\n",
    "            nn.Linear(dim, hidden_dim),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(hidden_dim, dim),\n",
    "            nn.LayerNorm(dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x + self.block(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "192768de-0061-4c9e-a836-6fee09b422b6",
   "metadata": {},
   "source": [
    "- **Neural vector field** class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "950fe7c8-431a-491c-8f30-f127d786ee87",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralVectorField(nn.Module):\n",
    "    def __init__(self, latent_dim, hidden_dim=256, n_resblocks=5, time_embed_dim=64):\n",
    "        super().__init__()\n",
    "        self.x_proj = nn.Linear(latent_dim, hidden_dim)\n",
    "        self.z_proj = nn.Linear(latent_dim, hidden_dim)\n",
    "        self.time_embedder = TimeEmbedder(time_embed_dim)\n",
    "\n",
    "        self.resblocks = nn.ModuleList([\n",
    "            ResNetBlock(hidden_dim*2 + time_embed_dim, hidden_dim*2) for _ in range(n_resblocks)\n",
    "        ])\n",
    "        self.output_layer = nn.Sequential(\n",
    "            nn.Linear(hidden_dim*2 + time_embed_dim, hidden_dim),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(hidden_dim, latent_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x, z, t):\n",
    "        xh = self.x_proj(x)\n",
    "        zh = self.z_proj(z)\n",
    "        th = self.time_embedder(t)\n",
    "        h = torch.cat([xh, zh, th], dim=-1)\n",
    "        for block in self.resblocks:\n",
    "            h = block(h)\n",
    "        return self.output_layer(h)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "030d5d2d-a2f8-4f79-b703-bac71b375480",
   "metadata": {},
   "source": [
    "## Hyperparameters and initialisation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cacd85d3-d1e3-48ae-9775-5b49006d297e",
   "metadata": {},
   "source": [
    "- Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "70f5c11f-6ca6-4f7f-8e9d-8085c690337b",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 2000\n",
    "num_epochs = 5000\n",
    "learning_rate = 1e-4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d79aefe2-7e3e-41cd-a8fa-569216dadcb0",
   "metadata": {},
   "source": [
    "- Initialisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8b44fee9-b80d-4755-ba62-3f83f82a5d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "emp_dist = EmpiricalDistribution(latent_tensor)\n",
    "alpha = LinearAlpha()\n",
    "beta = LinearBeta()\n",
    "latent_dim = latent_tensor.shape[1] # 50 in our case\n",
    "vf_model = NeuralVectorField(latent_dim=latent_dim).to(device)\n",
    "optimizer = torch.optim.AdamW(vf_model.parameters(), lr=learning_rate)\n",
    "# Initialize GaussianConditionalProbabilityPath\n",
    "path = GaussianConditionalProbabilityPath(emp_dist, alpha, beta)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dba24da0-11a4-4d9b-90bf-6c38cca18444",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6127f93f-e40f-494e-adba-49807386c7f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] Loss: 1.253904\n",
      "[50] Loss: 0.053890\n",
      "[100] Loss: 0.025504\n",
      "[150] Loss: 0.018876\n",
      "[200] Loss: 0.014524\n",
      "[250] Loss: 0.013706\n",
      "[300] Loss: 0.010967\n",
      "[350] Loss: 0.011267\n",
      "[400] Loss: 0.009629\n",
      "[450] Loss: 0.009211\n",
      "[500] Loss: 0.008915\n",
      "[550] Loss: 0.009134\n",
      "[600] Loss: 0.007979\n",
      "[650] Loss: 0.007438\n",
      "[700] Loss: 0.007302\n",
      "[750] Loss: 0.006706\n",
      "[800] Loss: 0.006445\n",
      "[850] Loss: 0.005799\n",
      "[900] Loss: 0.006176\n",
      "[950] Loss: 0.006564\n",
      "[1000] Loss: 0.006209\n",
      "[1050] Loss: 0.006535\n",
      "[1100] Loss: 0.005145\n",
      "[1150] Loss: 0.005617\n",
      "[1200] Loss: 0.004738\n",
      "[1250] Loss: 0.005157\n",
      "[1300] Loss: 0.004871\n",
      "[1350] Loss: 0.005255\n",
      "[1400] Loss: 0.005374\n",
      "[1450] Loss: 0.005785\n",
      "[1500] Loss: 0.005466\n",
      "[1550] Loss: 0.004767\n",
      "[1600] Loss: 0.004598\n",
      "[1650] Loss: 0.004870\n",
      "[1700] Loss: 0.004812\n",
      "[1750] Loss: 0.004291\n",
      "[1800] Loss: 0.004429\n",
      "[1850] Loss: 0.004983\n",
      "[1900] Loss: 0.003215\n",
      "[1950] Loss: 0.004458\n",
      "[2000] Loss: 0.003820\n",
      "[2050] Loss: 0.004810\n",
      "[2100] Loss: 0.004454\n",
      "[2150] Loss: 0.003958\n",
      "[2200] Loss: 0.005512\n",
      "[2250] Loss: 0.003212\n",
      "[2300] Loss: 0.004473\n",
      "[2350] Loss: 0.004113\n",
      "[2400] Loss: 0.004014\n",
      "[2450] Loss: 0.003879\n",
      "[2500] Loss: 0.003555\n",
      "[2550] Loss: 0.004972\n",
      "[2600] Loss: 0.004512\n",
      "[2650] Loss: 0.004319\n",
      "[2700] Loss: 0.003385\n",
      "[2750] Loss: 0.002837\n",
      "[2800] Loss: 0.003697\n",
      "[2850] Loss: 0.004040\n",
      "[2900] Loss: 0.005051\n",
      "[2950] Loss: 0.003685\n",
      "[3000] Loss: 0.004946\n",
      "[3050] Loss: 0.003741\n",
      "[3100] Loss: 0.003819\n",
      "[3150] Loss: 0.003373\n",
      "[3200] Loss: 0.003055\n",
      "[3250] Loss: 0.004026\n",
      "[3300] Loss: 0.003363\n",
      "[3350] Loss: 0.003230\n",
      "[3400] Loss: 0.004104\n",
      "[3450] Loss: 0.003268\n",
      "[3500] Loss: 0.003245\n",
      "[3550] Loss: 0.003334\n",
      "[3600] Loss: 0.003576\n",
      "[3650] Loss: 0.002701\n",
      "[3700] Loss: 0.003403\n",
      "[3750] Loss: 0.002562\n",
      "[3800] Loss: 0.003779\n",
      "[3850] Loss: 0.003329\n",
      "[3900] Loss: 0.002427\n",
      "[3950] Loss: 0.004352\n",
      "[4000] Loss: 0.003294\n",
      "[4050] Loss: 0.003074\n",
      "[4100] Loss: 0.003631\n",
      "[4150] Loss: 0.003122\n",
      "[4200] Loss: 0.002788\n",
      "[4250] Loss: 0.002915\n",
      "[4300] Loss: 0.003462\n",
      "[4350] Loss: 0.003821\n",
      "[4400] Loss: 0.003369\n",
      "[4450] Loss: 0.003853\n",
      "[4500] Loss: 0.003564\n",
      "[4550] Loss: 0.003351\n",
      "[4600] Loss: 0.002527\n",
      "[4650] Loss: 0.002893\n",
      "[4700] Loss: 0.003890\n",
      "[4750] Loss: 0.002932\n",
      "[4800] Loss: 0.002921\n",
      "[4850] Loss: 0.002875\n",
      "[4900] Loss: 0.002596\n",
      "[4950] Loss: 0.002601\n"
     ]
    }
   ],
   "source": [
    "epochs_list = []\n",
    "loss_list = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # Sample noise\n",
    "    x = torch.randn(batch_size, latent_dim, device=device)\n",
    "    \n",
    "    # Sample target latent points\n",
    "    indices = torch.randint(0, latent_tensor.shape[0], (batch_size,))\n",
    "    z = latent_tensor[indices].to(device)\n",
    "    \n",
    "    # Optional time embedding\n",
    "    t = torch.rand(batch_size, 1, device=device)\n",
    "    \n",
    "    # Target vector field: simple difference\n",
    "    u_target = z - x\n",
    "    \n",
    "    # Normalize target\n",
    "    u_mean = u_target.mean(dim=0, keepdim=True)\n",
    "    u_std = u_target.std(dim=0, keepdim=True) + 1e-6\n",
    "    u_target_norm = (u_target - u_mean) / u_std\n",
    "    \n",
    "    # Forward pass\n",
    "    v_pred = vf_model(x, z, t)\n",
    "    \n",
    "    # Loss\n",
    "    loss = F.mse_loss(v_pred, u_target_norm)\n",
    "    \n",
    "    # Backprop\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    torch.nn.utils.clip_grad_norm_(vf_model.parameters(), 1.0)\n",
    "    optimizer.step()\n",
    "    \n",
    "    epochs_list.append(epoch)\n",
    "    loss_list.append(loss.item())\n",
    "    \n",
    "    if epoch % 50 == 0:\n",
    "        print(f\"[{epoch}] Loss: {loss.item():.6f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "427ac129-020c-4a0f-8502-616dc13f80a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(epochs_list, loss_list)\n",
    "plt.title('Training of flow')\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edcaa092-345b-4a13-aea5-c93461e48f7b",
   "metadata": {},
   "source": [
    "## Saving files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6d426990-cbc7-46ae-b0b2-d13ed410cec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the last u_mean and u_std\n",
    "save_path = data_dir + \"normalization_stats.pt\"\n",
    "torch.save({\n",
    "    'u_mean': u_mean,\n",
    "    'u_std': u_std\n",
    "}, save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5c1cd184-80d2-48a0-93ac-38e25a43c206",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = data_dir + \"vf_model_weights.pt\"\n",
    "\n",
    "torch.save(vf_model.state_dict(), save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b46c5956-d23f-463a-8541-7e85d2e52888",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we want to save the best vector field:\n",
    "class LearnedVectorFieldODE():\n",
    "    def __init__(self, vf_model):\n",
    "        self.vf_model = vf_model\n",
    "\n",
    "    def drift_coefficient(self, x: torch.Tensor, t: torch.Tensor, z: torch.Tensor) -> torch.Tensor:\n",
    "        # x, z: (batch_size, latent_dim)\n",
    "        # t: (batch_size, 1)\n",
    "        return self.vf_model(x, z, t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2376f019-c84c-4f60-bc09-84ec341a1511",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrap the trained neural network\n",
    "learned_ode = LearnedVectorFieldODE(vf_model)\n",
    "save_path = data_dir + \"learned_ode.pt\"\n",
    "# Save the wrapper\n",
    "torch.save(learned_ode, save_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
