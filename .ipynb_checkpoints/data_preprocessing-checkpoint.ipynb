{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cc06406",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full data shape: (19882, 45263)\n",
      "Loaded subset: (5000, 45263)\n",
      "After filtering: (5000, 45138)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/zhome/df/7/213542/venv_1/lib/python3.11/site-packages/scanpy/preprocessing/_normalization.py:269: UserWarning: Received a view of an AnnData. Making a copy.\n",
      "  view_to_actual(adata)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: adata.X seems to be already log-transformed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/zhome/df/7/213542/venv_1/lib/python3.11/site-packages/legacy_api_wrap/__init__.py:88: UserWarning: `flavor='seurat_v3'` expects raw count data, but non-integers were found.\n",
      "  return fn(*args_all, **kw)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final shape: (5000, 2000)\n"
     ]
    }
   ],
   "source": [
    "import scanpy as sc\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "so basically i was really stuggled with the size of the dataset and i needed to do something sbout it,\n",
    "so here just take the subset\n",
    "also the data from the paper - wasnt able to get it to server because you need to download the full\n",
    "zip file and i dont have that space left on my account :((((\n",
    "\n",
    "i think this should be more or less ready to go to encodergit \n",
    "\"\"\"\n",
    "\n",
    "#load the data with backed = \"r\", otherwise i just got a RAM probelm\n",
    "\n",
    "DATA_PATH = \"/work3/s193518/scIsoPred/data/bulk_processed_genes.h5ad\"\n",
    "adata_meta = sc.read_h5ad(DATA_PATH, backed=\"\")\n",
    "print(\"Full data shape:\", adata_meta.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1987c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# subset of the data - otherwise i got RAM error - again\n",
    "n_cells_keep = 5000\n",
    "idx = np.random.choice(adata_meta.n_obs, size=n_cells_keep, replace=False)\n",
    "idx.sort()\n",
    "\n",
    "# Load only those cells fully into memory\n",
    "adata = sc.read_h5ad(DATA_PATH)\n",
    "adata = adata[idx, :] \n",
    "\n",
    "print(\"Loaded subset:\", adata.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ed31351",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filter weakly expressed genes using existing stats - they did that in the paper\n",
    "#and this is basically only preprocessing we need to do\n",
    "if \"n_cells_by_counts\" in adata.var.columns:\n",
    "    keep = adata.var[\"n_cells_by_counts\"] >= 20\n",
    "    adata = adata[:, keep]  \n",
    "else:\n",
    "    print(\"No precomputed n_cells_by_counts; skipping\")\n",
    "\n",
    "print(\"After filtering:\", adata.shape)\n",
    "\n",
    "\n",
    "adata = adata[:, adata.var[\"highly_variable\"]] \n",
    "print(\"Final shape:\", adata.shape)\n",
    "\n",
    "# new smaller dataset\n",
    "adata.write_h5ad(\"adata_preprocessed_50k_2kgenes.h5ad\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
