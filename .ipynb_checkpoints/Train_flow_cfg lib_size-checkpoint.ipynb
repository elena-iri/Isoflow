{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e48c73bf-fec7-4795-b432-646e53a6bae1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Nov 30 19:37:19 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 580.105.08             Driver Version: 580.105.08     CUDA Version: 13.0     |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  Tesla V100-PCIE-16GB           On  |   00000000:37:00.0 Off |                    0 |\n",
      "| N/A   36C    P0             38W /  250W |   16144MiB /  16384MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "|   1  Tesla V100-PCIE-16GB           On  |   00000000:AF:00.0 Off |                    0 |\n",
      "| N/A   33C    P0             37W /  250W |    3552MiB /  16384MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "\n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A         2660287      C   ...24028/venvs/myenv/bin/python3      15452MiB |\n",
      "|    0   N/A  N/A         3232133      C   ...f/7/213542/venv_1/bin/python3        688MiB |\n",
      "|    1   N/A  N/A         2997494      C   python3                                 434MiB |\n",
      "|    1   N/A  N/A         2999424      C   python3                                 434MiB |\n",
      "|    1   N/A  N/A         3007260      C   python3                                 432MiB |\n",
      "|    1   N/A  N/A         3008633      C   python3                                 434MiB |\n",
      "|    1   N/A  N/A         3168641      C   python3                                 470MiB |\n",
      "|    1   N/A  N/A         3173101      C   python3                                 434MiB |\n",
      "|    1   N/A  N/A         3211836      C   python3                                 434MiB |\n",
      "|    1   N/A  N/A         3233736      C   python3                                 472MiB |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "# cfg_flow_celltype.py\n",
    "# Full script: classifier-free guidance trained on cell type\n",
    "import os\n",
    "from typing import Optional\n",
    "import math\n",
    "import anndata as ad\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.distributions as D\n",
    "from tqdm import tqdm\n",
    "\n",
    "!nvidia-smi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "36282d56-f328-4d07-8e92-804d54471f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# ---- paths (edit if needed)\n",
    "input_file_path = \"/dtu/blackhole/06/213542/paperdata/pbmc3k_train_with_latent.h5ad\"\n",
    "flow_model_save_path = \"/dtu/blackhole/06/213542/paperdata/simple_flow_model_state.pth\"\n",
    "generated_save_path = \"/dtu/blackhole/06/213542/paperdata/simple_generated_latent.pt\"\n",
    "os.makedirs(os.path.dirname(flow_model_save_path), exist_ok=True)\n",
    "os.makedirs(os.path.dirname(generated_save_path), exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4a96f78b-0433-437b-8648-7c573cb27875",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of latent space: (2110, 50)\n",
      "Found 8 cell types: ['B cells' 'CD14+ Monocytes' 'CD4 T cells' 'CD8 T cells' 'Dendritic cells'\n",
      " 'FCGR3A+ Monocytes' 'Megakaryocytes' 'NK cells']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# ---- load data\n",
    "adata = ad.read_h5ad(input_file_path)\n",
    "latent = adata.obsm[\"X_latent\"]\n",
    "\n",
    "\n",
    "\n",
    "latent_tensor = torch.tensor(latent, dtype=torch.float32, device=device)\n",
    "print(\"Shape of latent space:\", latent.shape)\n",
    "\n",
    "# ---- cell type labels\n",
    "cell_types = adata.obs[\"cell_type\"].astype(str).values\n",
    "# map to indices\n",
    "unique_types, inverse_idx = np.unique(cell_types, return_inverse=True)\n",
    "num_cell_types = len(unique_types)\n",
    "cell_type_idx = torch.tensor(inverse_idx, dtype=torch.long, device=device)  # length N\n",
    "\n",
    "print(f\"Found {num_cell_types} cell types: {unique_types}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f0db0785-b539-4dfc-aa03-a28c0bac11ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Empirical distribution (KDE-like sampler/log density)\n",
    "class EmpiricalDistribution(torch.nn.Module):\n",
    "    def __init__(self, data: torch.Tensor, bandwidth: Optional[float] = None, compute_log_density: bool = True):\n",
    "        super().__init__()\n",
    "        assert data.dim() == 2, \"data must be shape (N, D)\"\n",
    "        data = data.contiguous()\n",
    "        self.register_buffer(\"data\", data)   # (N, D)\n",
    "        self.n = data.shape[0]\n",
    "        self.data_dim = data.shape[1]\n",
    "        self.compute_log_density_flag = compute_log_density\n",
    "\n",
    "        # bandwidth scalar\n",
    "        if bandwidth is None:\n",
    "            std = torch.std(data, dim=0).mean().item()\n",
    "            factor = (4.0 / (self.data_dim + 2.0)) ** (1.0 / (self.data_dim + 4.0))\n",
    "            bw = factor * (self.n ** (-1.0 / (self.data_dim + 4.0))) * (std + 1e-6)\n",
    "            bw = float(bw)\n",
    "        else:\n",
    "            bw = float(bandwidth)\n",
    "        self.register_buffer(\"bandwidth\", torch.tensor(bw, device=self.data.device))\n",
    "        # log constant as tensor\n",
    "        self._log_const = -0.5 * self.data_dim * math.log(2.0 * math.pi) - self.data_dim * torch.log(self.bandwidth)\n",
    "\n",
    "    @property\n",
    "    def dim(self):\n",
    "        return self.data_dim\n",
    "\n",
    "    def sample(self, num_samples: int) -> torch.Tensor:\n",
    "        idx = torch.randint(0, self.n, (num_samples,), device=self.data.device)\n",
    "        return self.data[idx]\n",
    "\n",
    "    def log_density(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        if not self.compute_log_density_flag:\n",
    "            raise RuntimeError(\"log_density disabled (compute_log_density=False).\")\n",
    "        assert x.dim() == 2 and x.shape[1] == self.data_dim\n",
    "        x = x.to(self.data.device)\n",
    "        x_norm2 = (x ** 2).sum(dim=1, keepdim=True)             # (bs,1)\n",
    "        data_norm2 = (self.data ** 2).sum(dim=1).unsqueeze(0)    # (1, N)\n",
    "        cross = x @ self.data.t()                               # (bs, N)\n",
    "        d2 = x_norm2 + data_norm2 - 2.0 * cross\n",
    "        sigma2 = (self.bandwidth ** 2)\n",
    "        exponents = -0.5 * d2 / (sigma2 + 1e-12)\n",
    "        lse = torch.logsumexp(exponents, dim=1, keepdim=True)\n",
    "        log_prob = math.log(1.0 / self.n) + lse + self._log_const\n",
    "        return log_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f26842e5-953c-4adf-b7c7-fc90f7c853c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "emp_dist = EmpiricalDistribution(latent_tensor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "51658583-76f9-4359-9c3f-648ea5605e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Gaussian conditional path / analytic vector field\n",
    "class LinearAlpha():\n",
    "    def __call__(self, t: torch.Tensor) -> torch.Tensor:\n",
    "        return t\n",
    "    def dt(self, t: torch.Tensor) -> torch.Tensor:\n",
    "        return torch.ones_like(t)\n",
    "\n",
    "class LinearBeta():\n",
    "    def __call__(self, t: torch.Tensor) -> torch.Tensor:\n",
    "        return 1 - t\n",
    "    def dt(self, t: torch.Tensor) -> torch.Tensor:\n",
    "        return -torch.ones_like(t)\n",
    "\n",
    "class GaussianConditionalProbabilityPath():\n",
    "    def __init__(self, p_data, alpha, beta):\n",
    "        self.p_data = p_data\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "\n",
    "    def sample_conditioning_variable(self, num_samples: int) -> torch.Tensor:\n",
    "        return self.p_data.sample(num_samples)\n",
    "\n",
    "    def sample_conditional_path(self, z: torch.Tensor, t: torch.Tensor) -> torch.Tensor:\n",
    "        # p_t(x|z) = N(alpha_t * z, beta_t^2 I)\n",
    "        return self.alpha(t) * z + self.beta(t) * torch.randn_like(z)\n",
    "\n",
    "    def conditional_vector_field(self, x: torch.Tensor, z: torch.Tensor, t: torch.Tensor) -> torch.Tensor:\n",
    "        # u_t(x|z) as in your formula\n",
    "        alpha_t = self.alpha(t)\n",
    "        beta_t = self.beta(t)\n",
    "        dt_alpha_t = self.alpha.dt(t)\n",
    "        dt_beta_t = self.beta.dt(t)\n",
    "        return (dt_alpha_t - dt_beta_t / beta_t * alpha_t) * z + (dt_beta_t / beta_t) * x\n",
    "\n",
    "    def conditional_score(self, x: torch.Tensor, z: torch.Tensor, t: torch.Tensor) -> torch.Tensor:\n",
    "        alpha_t = self.alpha(t)\n",
    "        beta_t = self.beta(t)\n",
    "        return (z * alpha_t - x) / beta_t ** 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9245e61d-0c84-42c6-8bc9-016a457befe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "alpha = LinearAlpha()\n",
    "beta = LinearBeta()\n",
    "path = GaussianConditionalProbabilityPath(emp_dist, alpha, beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6699f75e-902f-422c-9f8f-8e2fd433418e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ---- Neural vector field\n",
    "class TimeEmbedder(nn.Module):\n",
    "    def __init__(self, embed_dim=32, max_freq=1e4):\n",
    "        super().__init__()\n",
    "        assert embed_dim % 2 == 0\n",
    "        self.embed_dim = embed_dim\n",
    "        self.max_freq = max_freq\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(embed_dim, embed_dim),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(embed_dim, embed_dim),\n",
    "            nn.SiLU()\n",
    "        )\n",
    "    def forward(self, t):\n",
    "        freqs = torch.exp(torch.linspace(0, math.log(self.max_freq), self.embed_dim // 2, device=t.device))\n",
    "        args = t * freqs\n",
    "        emb = torch.cat([torch.sin(args), torch.cos(args)], dim=-1)\n",
    "        return self.mlp(emb)\n",
    "\n",
    "class ResNetBlock(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super().__init__()\n",
    "        self.block = nn.Sequential(\n",
    "            nn.Linear(dim, dim),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(dim, dim)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return x + self.block(x)\n",
    "\n",
    "class NeuralVectorField(nn.Module):\n",
    "    def __init__(self, latent_dim, hidden_dim=256, n_resblocks=3, time_embed_dim=64):\n",
    "        super().__init__()\n",
    "        self.x_proj = nn.Linear(latent_dim, hidden_dim)\n",
    "        # z is cell-type conditioning vector projected into hidden_dim\n",
    "        self.z_proj = nn.Linear(latent_dim, hidden_dim)\n",
    "        self.time_embedder = TimeEmbedder(time_embed_dim)\n",
    "        in_dim = hidden_dim * 2 + time_embed_dim\n",
    "        self.resblocks = nn.ModuleList([ResNetBlock(in_dim) for _ in range(n_resblocks)])\n",
    "        self.output_layer = nn.Linear(in_dim, latent_dim)\n",
    "\n",
    "    def forward(self, x, z, t):\n",
    "        \"\"\"\n",
    "        x: (bs, latent_dim)\n",
    "        z: (bs, latent_dim) -- conditioning (from cell type)\n",
    "        t: (bs, 1)\n",
    "        \"\"\"\n",
    "        xh = self.x_proj(x)\n",
    "        zh = self.z_proj(z)\n",
    "        th = self.time_embedder(t)  # (bs, time_embed_dim)\n",
    "        h = torch.cat([xh, zh, th], dim=-1)\n",
    "        for block in self.resblocks:\n",
    "            h = block(h)\n",
    "        return self.output_layer(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2b3a53f2-2ba9-4cc0-8fdf-7e7e7b8508a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ---- cell-type conditioning module: one-hot projection + learned embedding\n",
    "class CellTypeConditioner(nn.Module):\n",
    "    def __init__(self, n_cell_types, latent_dim, use_one_hot=True, one_hot_proj_dim=None, embed_dim=None):\n",
    "        super().__init__()\n",
    "        self.n_types = n_cell_types\n",
    "        self.latent_dim = latent_dim\n",
    "        self.use_one_hot = use_one_hot\n",
    "        # learned embedding\n",
    "        embed_dim = latent_dim if embed_dim is None else embed_dim\n",
    "        self.type_embed = nn.Embedding(n_cell_types, embed_dim)\n",
    "        # project one-hot into same space if requested\n",
    "        if self.use_one_hot:\n",
    "            one_hot_proj_dim = latent_dim if one_hot_proj_dim is None else one_hot_proj_dim\n",
    "            self.one_hot_proj = nn.Linear(n_cell_types, embed_dim)\n",
    "        else:\n",
    "            self.one_hot_proj = None\n",
    "        # final projector to the latent_dim (z must be latent_dim)\n",
    "        self.final_proj = nn.Linear(embed_dim, latent_dim)\n",
    "\n",
    "    def forward(self, type_idx: torch.LongTensor):\n",
    "        # type_idx: (bs,) long\n",
    "        emb = self.type_embed(type_idx)   # (bs, embed_dim)\n",
    "        if self.use_one_hot:\n",
    "            # build one-hot\n",
    "            bs = type_idx.shape[0]\n",
    "            one_hot = torch.zeros(bs, self.n_types, device=type_idx.device)\n",
    "            one_hot.scatter_(1, type_idx.unsqueeze(1), 1.0)\n",
    "            oh_proj = self.one_hot_proj(one_hot)  # (bs, embed_dim)\n",
    "            emb = emb + oh_proj\n",
    "        z = self.final_proj(emb)  # (bs, latent_dim)\n",
    "        return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d3d23631-7158-4b3f-a5a3-b69c1a95664c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# ---- ODE wrapper and Euler simulator (stateless, accepts z)\n",
    "class LearnedVectorFieldODE():\n",
    "    def __init__(self, vf_model: nn.Module):\n",
    "        self.vf_model = vf_model\n",
    "    def drift_coefficient(self, x: torch.Tensor, t: torch.Tensor, z: torch.Tensor) -> torch.Tensor:\n",
    "        return self.vf_model(x, z, t)\n",
    "\n",
    "class EulerSimulator():\n",
    "    def __init__(self, ode: LearnedVectorFieldODE):\n",
    "        self.ode = ode\n",
    "    def step(self, xt: torch.Tensor, t: torch.Tensor, h: float, z: torch.Tensor):\n",
    "        dx = self.ode.drift_coefficient(xt, t, z)\n",
    "        return xt + dx * h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0407ef41-901d-48a3-aa6c-523150b155a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ---- hyperparams\n",
    "batch_size = 256\n",
    "num_epochs = 2000\n",
    "learning_rate = 1e-3\n",
    "latent_dim = latent_tensor.shape[1]\n",
    "drop_prob = 0.1   # classifier-free: drop conditioning p=0.1\n",
    "guidance_scale = 2.0  # sampling: positive amplifies conditioning\n",
    "n_steps = 50\n",
    "dt = 1.0 / n_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "32a545c8-df4c-49b5-8fc5-a296867ed0d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|                                        | 0/2000 [00:00<?, ?it/s]/tmp/ipykernel_3232133/3428351390.py:55: UserWarning: Converting a tensor with requires_grad=True to a scalar may lead to unexpected behavior.\n",
      "Consider using tensor.detach() first. (Triggered internally at /pytorch/torch/csrc/autograd/generated/python_variable_methods.cpp:836.)\n",
      "  loss_list.append(float(loss))\n",
      "Training: 100%|█████████| 2000/2000 [00:12<00:00, 165.69it/s, loss=3.791525e-02]\n"
     ]
    }
   ],
   "source": [
    "# ---- models\n",
    "vf_model = NeuralVectorField(latent_dim=latent_dim, hidden_dim=256, n_resblocks=3, time_embed_dim=64).to(device)\n",
    "cell_conditioner = CellTypeConditioner(n_cell_types=num_cell_types, latent_dim=latent_dim, use_one_hot=True).to(device)\n",
    "optimizer = torch.optim.AdamW(list(vf_model.parameters()) + list(cell_conditioner.parameters()), lr=learning_rate)\n",
    "\n",
    "# ---- training loop (Classifier-Free Guidance training on cell type)\n",
    "# We'll train so that when we drop conditioning we feed z_null (zero vector) and sample x consistent with that null conditioning.\n",
    "z_null = torch.zeros(1, latent_dim, device=device)  # null token (broadcastable)\n",
    "\n",
    "num_data = latent_tensor.shape[0]\n",
    "# create a mapping from dataset indices to cell type indices (to sample cell-type for each sampled latent index)\n",
    "# We will sample cell types by sampling indices in dataset\n",
    "dataset_indices = torch.arange(num_data, device=device)\n",
    "cell_type_indices_per_data = cell_type_idx  # length N longs\n",
    "\n",
    "pbar = tqdm(range(num_epochs), desc=\"Training\")\n",
    "\n",
    "loss_list = []\n",
    "epoch_list= []\n",
    "\n",
    "for epoch in pbar:\n",
    "    # sample dataset indices for batch (with replacement)\n",
    "    idx = torch.randint(0, num_data, (batch_size,), device=device)\n",
    "    # get cell types for those indices\n",
    "    types = cell_type_indices_per_data[idx]  # (bs,)\n",
    "    # create drop mask for classifier-free (True => drop -> unconditional)\n",
    "    drop_mask = (torch.rand(batch_size, device=device) < drop_prob)\n",
    "\n",
    "    # create z_used (conditioning) per example: either cell-type embedding or null\n",
    "    # but sample z_used such that x is sampled from p_t(x | z_used)\n",
    "    t = torch.rand(batch_size, 1, device=device)  # times\n",
    "    # compute type-conditioned z vectors\n",
    "    z_type = cell_conditioner(types)  # (bs, latent_dim)\n",
    "    # mask and choose z_used\n",
    "    z_used = z_type.clone()\n",
    "    if drop_mask.any():\n",
    "        z_used[drop_mask] = z_null  # unconditional entries\n",
    "\n",
    "    # sample x from conditional path consistent with z_used\n",
    "    with torch.no_grad():\n",
    "        x = path.sample_conditional_path(z_used, t)          # (bs, latent_dim)\n",
    "        u_target = path.conditional_vector_field(x, z_used, t)  # target vector field (bs, latent_dim)\n",
    "\n",
    "    # forward pass through network (it receives the same z_used the target was computed with)\n",
    "    v_pred = vf_model(x, z_used, t)\n",
    "\n",
    "    # loss: direct MSE between predicted and analytic vector field (no ad-hoc normalization)\n",
    "    loss = F.mse_loss(v_pred, u_target)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    torch.nn.utils.clip_grad_norm_(vf_model.parameters(), max_norm=1.0)\n",
    "    optimizer.step()\n",
    "\n",
    "    loss_list.append(float(loss))\n",
    "    epoch_list.append(epoch)\n",
    "\n",
    "    if epoch % 50 == 0:\n",
    "        pbar.set_postfix_str(f\"loss={loss.item():.6e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "63449016-51d9-412d-9faa-dd1b4cefab49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(epoch_list, loss_list)\n",
    "plt.title('Training of flow')\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Average loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e24d889e-7f18-4956-b87d-19677c2bf38b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model state to /dtu/blackhole/06/213542/paperdata/simple_flow_model_state.pth\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ---- save state dicts\n",
    "torch.save({\n",
    "    'vf_state': vf_model.state_dict(),\n",
    "    'cell_conditioner_state': cell_conditioner.state_dict(),\n",
    "    'latent_dim': latent_dim,\n",
    "    'num_cell_types': num_cell_types,\n",
    "}, flow_model_save_path)\n",
    "print(\"Saved model state to\", flow_model_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4d8d9d09-6ab2-4c0a-a43e-44f8f866cd26",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# ---- sampling with classifier-free guidance (generate latent samples conditioned on a desired cell type)\n",
    "def sample_with_cfg(vf_model, cell_conditioner, target_type_idx:int, n_samples=1000, guidance_scale=2.0, n_steps=50, dt=1.0/50, device='cpu'):\n",
    "    vf_model.eval()\n",
    "    cell_conditioner.eval()\n",
    "    latent_dim = next(vf_model.parameters()).shape[-1] if False else latent_dim_global  # we'll supply latent_dim_global below\n",
    "\n",
    "    # initial noise\n",
    "    x = torch.randn(n_samples, latent_dim, device=device)\n",
    "\n",
    "    # conditioning vectors\n",
    "    # z_cond: conditioning embedding for the requested cell type (broadcasted to n_samples)\n",
    "    type_idx_tensor = torch.full((n_samples,), target_type_idx, dtype=torch.long, device=device)\n",
    "    z_cond = cell_conditioner(type_idx_tensor)  # (n_samples, latent_dim)\n",
    "    # z_uncond: null token (zeros)\n",
    "    z_uncond = torch.zeros(n_samples, latent_dim, device=device)\n",
    "\n",
    "    t = torch.zeros(n_samples, 1, device=device)  # starting t=0, we'll step forward to t=1 (note: your alpha/beta definitions use t in [0,1])\n",
    "    # We trained with sampling x from p_t(x|z) with t drawn ~ Uniform(0,1). For sampling path integration: integrate from t=0 to t=1 with learned vector field\n",
    "    for step in range(n_steps):\n",
    "        # compute current time (t scalar for this step) as a tensor matching batch\n",
    "        # in our simple Euler loop we keep t increasing uniformly\n",
    "        # t is used inside the network TimeEmbedder; we keep it as current t\n",
    "        # compute predictions for cond and uncond\n",
    "        v_uncond = vf_model(x, z_uncond, t)\n",
    "        v_cond = vf_model(x, z_cond, t)\n",
    "        # classifier-free guidance: uncond + scale * (cond - uncond)\n",
    "        v_guided = v_uncond + guidance_scale * (v_cond - v_uncond)\n",
    "\n",
    "        # Euler step\n",
    "        x = x + v_guided * dt\n",
    "\n",
    "        # increment time\n",
    "        t = t + dt\n",
    "\n",
    "    return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "81efd971-c9fc-4e3e-ae68-33195432c742",
   "metadata": {},
   "outputs": [
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 15.77 GiB of which 256.00 KiB is free. Process 2660287 has 15.09 GiB memory in use. Including non-PyTorch memory, this process has 688.00 MiB memory in use. Of the allocated memory 301.06 MiB is allocated by PyTorch, and 2.94 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mOutOfMemoryError\u001b[39m                          Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[47]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# Example: generate 1000 samples conditioned on the first cell type\u001b[39;00m\n\u001b[32m      5\u001b[39m target_type_idx_example = \u001b[32m0\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m generated = \u001b[43msample_with_cfg\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvf_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcell_conditioner\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_type_idx_example\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_samples\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1000\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m                            \u001b[49m\u001b[43mguidance_scale\u001b[49m\u001b[43m=\u001b[49m\u001b[43mguidance_scale\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_steps\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_steps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdt\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mGenerated shape:\u001b[39m\u001b[33m\"\u001b[39m, generated.shape)\n\u001b[32m     10\u001b[39m torch.save(generated.cpu(), generated_save_path)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[38]\u001b[39m\u001b[32m, line 8\u001b[39m, in \u001b[36msample_with_cfg\u001b[39m\u001b[34m(vf_model, cell_conditioner, target_type_idx, n_samples, guidance_scale, n_steps, dt, device)\u001b[39m\n\u001b[32m      5\u001b[39m latent_dim = \u001b[38;5;28mnext\u001b[39m(vf_model.parameters()).shape[-\u001b[32m1\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m latent_dim_global  \u001b[38;5;66;03m# we'll supply latent_dim_global below\u001b[39;00m\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m# initial noise\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m x = \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrandn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_samples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlatent_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[38;5;66;03m# conditioning vectors\u001b[39;00m\n\u001b[32m     11\u001b[39m \u001b[38;5;66;03m# z_cond: conditioning embedding for the requested cell type (broadcasted to n_samples)\u001b[39;00m\n\u001b[32m     12\u001b[39m type_idx_tensor = torch.full((n_samples,), target_type_idx, dtype=torch.long, device=device)\n",
      "\u001b[31mOutOfMemoryError\u001b[39m: CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 15.77 GiB of which 256.00 KiB is free. Process 2660287 has 15.09 GiB memory in use. Including non-PyTorch memory, this process has 688.00 MiB memory in use. Of the allocated memory 301.06 MiB is allocated by PyTorch, and 2.94 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "# convenience helper to provide latent_dim into sampling function\n",
    "latent_dim_global = latent_dim  # make available for sampling helper above\n",
    "\n",
    "# Example: generate 1000 samples conditioned on the first cell type\n",
    "target_type_idx_example = 0\n",
    "generated = sample_with_cfg(vf_model, cell_conditioner, target_type_idx_example, n_samples=1000,\n",
    "                            guidance_scale=guidance_scale, n_steps=n_steps, dt=dt, device=device)\n",
    "\n",
    "print(\"Generated shape:\", generated.shape)\n",
    "torch.save(generated.cpu(), generated_save_path)\n",
    "print(\"Saved generated latent to\", generated_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9585bfba-2d2d-4a6d-940d-8cd34e15715f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4824f906-224c-4aaa-83db-0ef7995132e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1207d54f-991f-42c1-8874-175aafd89f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this the cleaner version of the flow matching model\n",
    "# import all packages and data\n",
    "# the data comes from the encoder in 50 dimensional format\n",
    "from abc import ABC, abstractmethod\n",
    "from typing import Optional, List, Type, Tuple, Dict\n",
    "import math\n",
    "import anndata as ad\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "from matplotlib.axes._axes import Axes\n",
    "import torch\n",
    "import torch.distributions as D\n",
    "from torch.func import vmap, jacrev\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "from sklearn.datasets import make_moons, make_circles\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e98a63f9-469b-4f22-9da0-a88d91f27b7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of latent space: (2110, 50)\n",
      "[[-4.8265247e+00  6.4398712e-01  2.9313943e-01  3.0890481e+00\n",
      "   1.1765828e+00 -7.8912878e-01 -5.3665400e+00 -1.3968008e+00\n",
      "   1.2098600e+00  3.3365767e+00 -3.8481004e+00  7.0330495e-01\n",
      "  -3.4451597e+00  4.1077366e+00  4.2849655e+00  6.9920130e+00\n",
      "   3.0892158e+00 -7.6523461e+00 -1.8158824e+00  2.7222965e+00\n",
      "  -2.8834870e+00 -2.7645674e+00  1.6244851e+00  4.3940554e+00\n",
      "   6.3701739e+00 -2.4180744e+00  3.1864629e+00 -1.7486143e+00\n",
      "  -2.4821444e+00  5.4535675e+00 -3.1519279e+00  2.4320188e+00\n",
      "  -3.4471009e+00  1.7183326e+00 -1.6651822e+00  5.9247975e+00\n",
      "  -5.0021301e-04  2.7415204e+00  3.2821023e+00  6.1637068e+00\n",
      "  -6.2996321e+00  3.1250734e+00  1.8593316e+00 -7.3208661e+00\n",
      "  -1.1019467e+00 -1.6716359e+00  6.3101897e+00  6.6704327e-01\n",
      "   1.1906556e+00  9.7726297e+00]\n",
      " [ 1.5488584e+00  8.6747295e-01  2.4328077e+00  5.4669249e-01\n",
      "  -1.4461365e+00  9.0370119e-01 -1.4667183e+00  5.5467706e+00\n",
      "   2.7354531e+00  5.1444712e+00 -3.5800772e+00  6.4247775e-01\n",
      "   2.1787410e+00  6.3186998e+00 -5.5455709e-01  4.6751018e+00\n",
      "  -9.3820441e-01 -2.2597036e+00 -2.7249477e+00 -1.9599915e+00\n",
      "  -5.9335990e+00  1.2720106e+00 -4.6455646e-01  5.3204620e-01\n",
      "  -2.9415808e+00  3.6324754e+00  1.7678853e+00 -2.8310272e-01\n",
      "  -3.7237737e+00  7.9976339e+00 -2.0772293e+00  2.4106984e+00\n",
      "  -9.8446913e+00 -1.4068246e+00 -1.4844252e+00 -6.1113896e+00\n",
      "   3.8356486e-01 -6.3886142e+00  7.1353310e-01  6.3777995e+00\n",
      "  -8.9152366e-01  5.6871819e+00 -5.4136047e+00 -1.4658002e+00\n",
      "   2.8592350e+00  7.9939657e-01  4.8240552e+00 -3.8440723e+00\n",
      "  -2.6065490e+00 -1.9924434e+00]\n",
      " [ 6.7751184e+00 -1.9650035e+00  6.6917911e-03  1.6059226e+00\n",
      "   2.7730074e+00  2.9611313e+00  1.4775300e+00  3.0489528e+00\n",
      "  -4.7885275e+00  4.4003568e+00  1.2807679e+00 -2.3877699e+00\n",
      "   2.0206100e-01 -4.9933977e+00  2.8354318e+00 -1.6389264e+00\n",
      "  -4.4867449e+00 -5.4850860e+00 -7.4981719e-01 -4.0616407e+00\n",
      "  -1.0990691e+00  3.9984593e+00  3.1979673e+00 -4.0054750e+00\n",
      "  -1.9100716e+00  8.1177788e+00 -6.0076094e+00 -2.9372659e-01\n",
      "   2.2602201e+00 -3.2328019e+00  5.0461969e+00  3.2422843e+00\n",
      "  -7.6047438e-01  5.0867615e+00 -5.5351119e+00 -9.0320683e+00\n",
      "  -1.5276861e+00  7.4957901e-01  3.1575108e+00  5.0317769e+00\n",
      "  -4.1042337e+00 -3.7397331e-01 -2.0166941e+00 -2.7442350e+00\n",
      "   8.2472286e+00  3.2472920e+00 -5.4465232e+00  2.3579447e+00\n",
      "   2.0914984e+00 -1.8767326e+00]\n",
      " [ 5.0700288e+00  2.2409852e+00  2.3104541e+00 -6.6748877e+00\n",
      "   2.8069370e+00 -4.8635693e+00  1.4162869e+00 -3.3387730e+00\n",
      "  -2.6978464e+00  2.0403345e+00 -5.6362209e+00 -7.7254191e-02\n",
      "   5.5195814e-01 -3.0642953e+00  7.0819384e-01 -4.0020428e+00\n",
      "   5.1475711e+00 -1.7155046e+00 -9.2213974e+00 -1.9366992e+00\n",
      "  -2.8229001e+00  3.0421391e+00 -7.3566008e-01 -9.2591009e+00\n",
      "   7.8342052e+00  1.3716816e+00 -5.7953882e+00  5.1934987e-01\n",
      "   4.5598283e+00  1.8589866e+00  1.2835141e-01  3.5464725e+00\n",
      "   8.3187437e+00  5.7540255e+00  2.2155868e-01  2.0466888e+00\n",
      "   3.0196857e+00 -7.0920529e+00 -4.6274800e+00 -6.4521365e+00\n",
      "   2.0799942e+00  5.8254786e+00  7.6756306e+00 -1.8239713e+00\n",
      "   4.4370918e+00  3.6463275e+00  2.8738267e+00  2.3060329e+00\n",
      "  -6.2184973e+00  1.8938814e+00]\n",
      " [-2.3850689e+00 -5.7374591e-01 -1.3855569e+00  3.8847613e-01\n",
      "   7.0980268e+00 -5.4684505e+00 -2.6609707e+00 -4.7543464e+00\n",
      "   4.8109221e+00 -3.7715290e+00 -4.3458061e+00  3.7296431e+00\n",
      "  -4.3459749e-01  4.3304949e+00  3.2698853e+00  4.4319296e+00\n",
      "   1.3189467e+00  1.8493114e+00  4.4517989e+00 -3.1720688e+00\n",
      "  -4.5946267e-01 -9.7169036e-01  9.4882574e+00  2.5796080e+00\n",
      "  -3.2056787e+00  5.5426359e-01 -1.7064942e+00  1.9991691e+00\n",
      "  -6.2869930e+00  6.2788601e+00 -2.2004094e+00  5.5189166e+00\n",
      "  -4.0317602e+00 -2.3209066e+00  4.5294300e-01 -6.5755069e-01\n",
      "   8.3470106e-01  2.0718412e+00  3.8887563e+00  1.0863941e+00\n",
      "  -1.4920738e+00 -4.4379124e-01 -1.6892056e+00 -6.5763249e+00\n",
      "   3.8011248e+00 -1.2591158e+00 -1.7584739e+00  8.0035706e+00\n",
      "   2.2274804e+00  3.4165080e+00]]\n"
     ]
    }
   ],
   "source": [
    "# Load the encoded data from the autoencoder\n",
    "input_file_path = \"/dtu/blackhole/1e/213566/data/datasets/pbmc3k/pbmc3k_train_with_latent.h5ad\"\n",
    "flow_model_save_path = \"/dtu/blackhole/1e/213566/models/simple_flow_model.pt\"\n",
    "adata = ad.read_h5ad(input_file_path)\n",
    "\n",
    "# Access latent representation\n",
    "latent = adata.obsm[\"X_latent\"]\n",
    "# make it to a tensor and save in GPU\n",
    "latent_tensor = torch.tensor(latent, dtype=torch.float32, device = device)\n",
    "print(\"Shape of latent space:\", latent.shape)\n",
    "print(latent[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2d9554cd-e92b-4ffd-a307-89cfcadca6ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a way of encoding our data for empirical data\n",
    "class EmpiricalDistribution(torch.nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        data: torch.Tensor,\n",
    "        bandwidth: Optional[float] = None,\n",
    "        compute_log_density: bool = True,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        assert data.dim() == 2, \"data must be shape (N, D)\"\n",
    "        data = data.contiguous()\n",
    "        \n",
    "        self.register_buffer(\"data\", data)   # (N, D)\n",
    "        self.n = data.shape[0]\n",
    "        self.data_dim = data.shape[1]        # <-- renamed attribute\n",
    "        self.compute_log_density_flag = compute_log_density\n",
    "\n",
    "        # Bandwidth estimation\n",
    "        if bandwidth is None:\n",
    "            std = torch.std(data, dim=0).mean().item()\n",
    "            factor = (4.0 / (self.data_dim + 2.0)) ** (1.0 / (self.data_dim + 4.0))\n",
    "            bw = factor * (self.n ** (-1.0 / (self.data_dim + 4.0))) * (std + 1e-6)\n",
    "            self.bandwidth = torch.tensor(float(bw), device=self.data.device)\n",
    "        else:\n",
    "            self.bandwidth = torch.tensor(float(bandwidth), device=self.data.device)\n",
    "\n",
    "        self._log_const = -0.5 * self.data_dim * math.log(2.0 * math.pi) - self.data_dim * torch.log(self.bandwidth).item()\n",
    "\n",
    "    @property\n",
    "    def dim(self):\n",
    "        return self.data_dim\n",
    "    def sample(self, num_samples: int) -> torch.Tensor:\n",
    "        idx = torch.randint(0, self.n, (num_samples,), device=self.data.device)\n",
    "        return self.data[idx]\n",
    "\n",
    "    def log_density(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        if not self.compute_log_density_flag:\n",
    "            raise RuntimeError(\"log_density disabled (compute_log_density=False).\")\n",
    "\n",
    "        assert x.dim() == 2 and x.shape[1] == self.data_dim\n",
    "\n",
    "        x = x.to(self.data.device)\n",
    "        x_norm2 = (x ** 2).sum(dim=1, keepdim=True)\n",
    "        data_norm2 = (self.data ** 2).sum(dim=1).unsqueeze(0)\n",
    "        cross = x @ self.data.t()\n",
    "        d2 = x_norm2 + data_norm2 - 2.0 * cross\n",
    "\n",
    "        sigma2 = (self.bandwidth ** 2).item()\n",
    "        exponents = -0.5 * d2 / (sigma2 + 1e-12)\n",
    "        lse = torch.logsumexp(exponents, dim=1, keepdim=True)\n",
    "\n",
    "        log_prob = math.log(1.0 / self.n) + lse + self._log_const\n",
    "        return log_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cbd6c723-2603-4ee4-a2e4-4444bf07beb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-111.4463],\n",
      "        [-111.4463],\n",
      "        [-111.4463]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# lets test if the empirical distribution class actually works\n",
    "# the data has to be a torch tensor\n",
    "\n",
    "dist = EmpiricalDistribution(latent_tensor)\n",
    "samples = dist.sample(3)\n",
    "logp = dist.log_density(samples)\n",
    "print(logp)\n",
    "\n",
    "# it seems to work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7cbc68f2-372e-428d-b98e-4d1f3a4d9b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we have to have a class that can draw from a Gaussian distribution\n",
    "\n",
    "class Gaussian(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Multivariate Gaussian distribution\n",
    "    \"\"\"\n",
    "    def __init__(self, mean: torch.Tensor, cov: torch.Tensor):\n",
    "        \"\"\"\n",
    "        mean: shape (dim,)\n",
    "        cov: shape (dim,dim)\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.register_buffer(\"mean\", mean)\n",
    "        self.register_buffer(\"cov\", cov)\n",
    "\n",
    "    @property\n",
    "    def dim(self) -> int:\n",
    "        return self.mean.shape[0]\n",
    "\n",
    "    @property\n",
    "    def distribution(self):\n",
    "        return D.MultivariateNormal(self.mean, self.cov, validate_args=False)\n",
    "\n",
    "    def sample(self, num_samples) -> torch.Tensor:\n",
    "        return self.distribution.sample((num_samples,))\n",
    "        \n",
    "    def log_density(self, x: torch.Tensor):\n",
    "        return self.distribution.log_prob(x).view(-1, 1)\n",
    "\n",
    "    @classmethod\n",
    "    def isotropic(cls, dim: int, std: float) -> \"Gaussian\":\n",
    "        mean = torch.zeros(dim)\n",
    "        cov = torch.eye(dim) * std ** 2\n",
    "        return cls(mean, cov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3433c200-5e40-4dc6-8fca-201b13c7b531",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We want to go with Gaussian probability path, therefore we need to load functions for alpha and beta\n",
    "class LinearAlpha():\n",
    "    \"\"\"Implements alpha_t = t\"\"\"\n",
    "    \n",
    "    def __call__(self, t: torch.Tensor) -> torch.Tensor:\n",
    "        return t  # linear in time\n",
    "\n",
    "    def dt(self, t: torch.Tensor) -> torch.Tensor:\n",
    "        return torch.ones_like(t)  # derivative of t is 1\n",
    "\n",
    "\n",
    "class LinearBeta():\n",
    "    \"\"\"Implements beta_t = 1 - t\"\"\"\n",
    "    \n",
    "    def __call__(self, t: torch.Tensor) -> torch.Tensor:\n",
    "        return 1 - t\n",
    "\n",
    "    def dt(self, t: torch.Tensor) -> torch.Tensor:\n",
    "        return -torch.ones_like(t)  # derivative of 1 - t is -1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "98ba9fdd-c53b-4e8e-b80d-a142773b04aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GaussianConditionalProbabilityPath():\n",
    "    def __init__(self, p_data, alpha, beta):\n",
    "        self.p_data = p_data \n",
    "        p_simple = Gaussian.isotropic(p_data.dim, 1.0)\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "\n",
    "    def sample_conditioning_variable(self, num_samples: int) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Samples the conditioning variable z ~ p_data(x)\n",
    "        Args:\n",
    "            - num_samples: the number of samples\n",
    "        Returns:\n",
    "            - z: samples from p(z), (num_samples, dim)\n",
    "        \"\"\"\n",
    "        return self.p_data.sample(num_samples)\n",
    "    \n",
    "    def sample_conditional_path(self, z: torch.Tensor, t: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Samples from the conditional distribution p_t(x|z) = N(alpha_t * z, beta_t**2 * I_d)\n",
    "        Args:\n",
    "            - z: conditioning variable (num_samples, dim)\n",
    "            - t: time (num_samples, 1)\n",
    "        Returns:\n",
    "            - x: samples from p_t(x|z), (num_samples, dim)\n",
    "        \"\"\"\n",
    "        return self.alpha(t) * z + self.beta(t) * torch.randn_like(z)\n",
    "        \n",
    "    def conditional_vector_field(self, x: torch.Tensor, z: torch.Tensor, t: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Evaluates the conditional vector field u_t(x|z)\n",
    "        Note: Only defined on t in [0,1)\n",
    "        Args:\n",
    "            - x: position variable (num_samples, dim)\n",
    "            - z: conditioning variable (num_samples, dim)\n",
    "            - t: time (num_samples, 1)\n",
    "        Returns:\n",
    "            - conditional_vector_field: conditional vector field (num_samples, dim)\n",
    "        \"\"\" \n",
    "        alpha_t = self.alpha(t) # (num_samples, 1)\n",
    "        beta_t = self.beta(t) # (num_samples, 1)\n",
    "        dt_alpha_t = self.alpha.dt(t) # (num_samples, 1)\n",
    "        dt_beta_t = self.beta.dt(t) # (num_samples, 1)\n",
    "\n",
    "        return (dt_alpha_t - dt_beta_t / beta_t * alpha_t) * z + dt_beta_t / beta_t * x\n",
    "\n",
    "    def conditional_score(self, x: torch.Tensor, z: torch.Tensor, t: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Evaluates the conditional score of p_t(x|z) = N(alpha_t * z, beta_t**2 * I_d)\n",
    "        Note: Only defined on t in [0,1)\n",
    "        Args:\n",
    "            - x: position variable (num_samples, dim)\n",
    "            - z: conditioning variable (num_samples, dim)\n",
    "            - t: time (num_samples, 1)\n",
    "        Returns:\n",
    "        - conditional_score: conditional score (num_samples, dim)\n",
    "        \"\"\" \n",
    "        alpha_t = self.alpha(t)\n",
    "        beta_t = self.beta(t)\n",
    "        return (z * alpha_t - x) / beta_t ** 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8b44fee9-b80d-4755-ba62-3f83f82a5d6c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'emp_dist' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m alpha = LinearAlpha()\n\u001b[32m      2\u001b[39m beta = LinearBeta()\n\u001b[32m      3\u001b[39m path = GaussianConditionalProbabilityPath(\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m     p_data=\u001b[43memp_dist\u001b[49m,\n\u001b[32m      5\u001b[39m     alpha=alpha,\n\u001b[32m      6\u001b[39m     beta=beta\n\u001b[32m      7\u001b[39m )\n\u001b[32m      8\u001b[39m \u001b[38;5;28mprint\u001b[39m(path)\n",
      "\u001b[31mNameError\u001b[39m: name 'emp_dist' is not defined"
     ]
    }
   ],
   "source": [
    "alpha = LinearAlpha()\n",
    "beta = LinearBeta()\n",
    "emp_dist=\n",
    "\n",
    "path = GaussianConditionalProbabilityPath(\n",
    "    p_data=emp_dist,\n",
    "    alpha=alpha,\n",
    "    beta=beta\n",
    ")\n",
    "print(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "901c8e9e-c97e-49a9-8c88-a2645798df18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now that we were able to construct a Gaussian probability path, we have to be able to make a conditional vector field\n",
    "\n",
    "class ConditionalVectorFieldODE():\n",
    "    def __init__(self, path, z: torch.Tensor):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "        - path: the ConditionalProbabilityPath object to which this vector field corresponds\n",
    "        - z: the conditioning variable, (1, dim)\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.path = path\n",
    "        self.z = z\n",
    "\n",
    "    def drift_coefficient(self, x: torch.Tensor, t: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Returns the conditional vector field u_t(x|z)\n",
    "        Args:\n",
    "            - x: state at time t, shape (bs, dim)\n",
    "            - t: time, shape (bs,.)\n",
    "        Returns:\n",
    "            - u_t(x|z): shape (batch_size, dim)\n",
    "        \"\"\"\n",
    "        bs = x.shape[0]\n",
    "        z = self.z.expand(bs, *self.z.shape[1:])\n",
    "        return self.path.conditional_vector_field(x,z,t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "8de56993-96dc-427b-a843-1c0dc16a7ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "cvf_ode = ConditionalVectorFieldODE(path, z)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "8fbd6bfb-437d-45e7-a33c-5f97c26691f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we somehow want to model the marginal vector field from the conditonal vector field\n",
    "# for that we will use eulers:\n",
    "class EulerSimulator():\n",
    "    def __init__(self, ode, z: torch.Tensor):\n",
    "        self.ode = ode\n",
    "        self.z = z\n",
    "\n",
    "    def step(self, xt: torch.Tensor, t: torch.Tensor, h: float):\n",
    "        \n",
    "        # Expand z to match batch size\n",
    "        if self.z.shape[0] == 1:\n",
    "            z_exp = self.z.expand(xt.shape[0], -1)\n",
    "        else:\n",
    "            z_exp = self.z\n",
    "        dx = self.ode.drift_coefficient(xt, t, z_exp)\n",
    "        return xt + dx * h\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "302131ba-68b1-4470-818b-979253a25ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch.nn as nn\n",
    "\n",
    "class TimeEmbedder(nn.Module):\n",
    "    def __init__(self, embed_dim=32, max_freq=1e4):\n",
    "        super().__init__()\n",
    "        self.embed_dim = embed_dim\n",
    "        self.max_freq = max_freq\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(embed_dim, embed_dim),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(embed_dim, embed_dim),\n",
    "            nn.SiLU()\n",
    "        )\n",
    "\n",
    "    def forward(self, t):\n",
    "        freqs = torch.exp(torch.linspace(0, math.log(self.max_freq), self.embed_dim // 2, device=t.device))\n",
    "        args = t * freqs\n",
    "        emb = torch.cat([torch.sin(args), torch.cos(args)], dim=-1)\n",
    "        return self.mlp(emb)\n",
    "\n",
    "class ResNetBlock(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super().__init__()\n",
    "        self.block = nn.Sequential(\n",
    "            nn.Linear(dim, dim),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(dim, dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x + self.block(x)\n",
    "\n",
    "class NeuralVectorField(nn.Module):\n",
    "    def __init__(self, latent_dim, hidden_dim=128, n_resblocks=3, time_embed_dim=32):\n",
    "        super().__init__()\n",
    "        self.x_proj = nn.Linear(latent_dim, hidden_dim)\n",
    "        self.z_proj = nn.Linear(latent_dim, hidden_dim)\n",
    "        self.time_embedder = TimeEmbedder(time_embed_dim)\n",
    "\n",
    "        self.resblocks = nn.ModuleList([\n",
    "            ResNetBlock(hidden_dim*2 + time_embed_dim) for _ in range(n_resblocks)\n",
    "        ])\n",
    "        self.output_layer = nn.Linear(hidden_dim*2 + time_embed_dim, latent_dim)\n",
    "\n",
    "    def forward(self, x, z, t):\n",
    "        xh = self.x_proj(x)\n",
    "        zh = self.z_proj(z)\n",
    "        th = self.time_embedder(t)\n",
    "        h = torch.cat([xh, zh, th], dim=-1)\n",
    "        for block in self.resblocks:\n",
    "            h = block(h)\n",
    "        return self.output_layer(h)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "2986d674-1040-4060-afd7-e60f1fdd74c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] Loss: 1.900425\n",
      "[50] Loss: 0.076403\n",
      "[100] Loss: 0.064227\n",
      "[150] Loss: 0.061644\n",
      "[200] Loss: 0.053724\n",
      "[250] Loss: 0.035737\n",
      "[300] Loss: 0.027486\n",
      "[350] Loss: 0.023804\n",
      "[400] Loss: 0.021102\n",
      "[450] Loss: 0.019818\n",
      "[500] Loss: 0.017939\n",
      "[550] Loss: 0.016885\n",
      "[600] Loss: 0.015444\n",
      "[650] Loss: 0.015229\n",
      "[700] Loss: 0.013819\n",
      "[750] Loss: 0.013889\n",
      "[800] Loss: 0.013724\n",
      "[850] Loss: 0.012990\n",
      "[900] Loss: 0.012491\n",
      "[950] Loss: 0.012056\n",
      "[1000] Loss: 0.011001\n",
      "[1050] Loss: 0.011520\n",
      "[1100] Loss: 0.011166\n",
      "[1150] Loss: 0.012368\n",
      "[1200] Loss: 0.010196\n",
      "[1250] Loss: 0.010411\n",
      "[1300] Loss: 0.010866\n",
      "[1350] Loss: 0.010570\n",
      "[1400] Loss: 0.011119\n",
      "[1450] Loss: 0.009777\n",
      "[1500] Loss: 0.010421\n",
      "[1550] Loss: 0.010046\n",
      "[1600] Loss: 0.010495\n",
      "[1650] Loss: 0.010226\n",
      "[1700] Loss: 0.009873\n",
      "[1750] Loss: 0.009400\n",
      "[1800] Loss: 0.010520\n",
      "[1850] Loss: 0.009726\n",
      "[1900] Loss: 0.008957\n",
      "[1950] Loss: 0.009032\n",
      "[2000] Loss: 0.009762\n",
      "[2050] Loss: 0.008079\n",
      "[2100] Loss: 0.008867\n",
      "[2150] Loss: 0.009604\n",
      "[2200] Loss: 0.009041\n",
      "[2250] Loss: 0.009238\n",
      "[2300] Loss: 0.009397\n",
      "[2350] Loss: 0.009499\n",
      "[2400] Loss: 0.009006\n",
      "[2450] Loss: 0.009298\n",
      "[2500] Loss: 0.009147\n",
      "[2550] Loss: 0.009095\n",
      "[2600] Loss: 0.008846\n",
      "[2650] Loss: 0.008508\n",
      "[2700] Loss: 0.010306\n",
      "[2750] Loss: 0.008183\n",
      "[2800] Loss: 0.009226\n",
      "[2850] Loss: 0.009003\n",
      "[2900] Loss: 0.009155\n",
      "[2950] Loss: 0.009024\n",
      "[3000] Loss: 0.008712\n",
      "[3050] Loss: 0.008452\n",
      "[3100] Loss: 0.008235\n",
      "[3150] Loss: 0.008883\n",
      "[3200] Loss: 0.009288\n",
      "[3250] Loss: 0.009641\n",
      "[3300] Loss: 0.008679\n",
      "[3350] Loss: 0.008965\n",
      "[3400] Loss: 0.009653\n",
      "[3450] Loss: 0.008329\n",
      "[3500] Loss: 0.008213\n",
      "[3550] Loss: 0.008264\n",
      "[3600] Loss: 0.009620\n",
      "[3650] Loss: 0.009602\n",
      "[3700] Loss: 0.008745\n",
      "[3750] Loss: 0.009466\n",
      "[3800] Loss: 0.008676\n",
      "[3850] Loss: 0.008274\n",
      "[3900] Loss: 0.008808\n",
      "[3950] Loss: 0.007877\n",
      "[4000] Loss: 0.007999\n",
      "[4050] Loss: 0.008510\n",
      "[4100] Loss: 0.008512\n",
      "[4150] Loss: 0.008992\n",
      "[4200] Loss: 0.008901\n",
      "[4250] Loss: 0.009591\n",
      "[4300] Loss: 0.009030\n",
      "[4350] Loss: 0.008808\n",
      "[4400] Loss: 0.009364\n",
      "[4450] Loss: 0.009096\n",
      "[4500] Loss: 0.008839\n",
      "[4550] Loss: 0.008918\n",
      "[4600] Loss: 0.010165\n",
      "[4650] Loss: 0.008653\n",
      "[4700] Loss: 0.009057\n",
      "[4750] Loss: 0.009093\n",
      "[4800] Loss: 0.008296\n",
      "[4850] Loss: 0.008383\n",
      "[4900] Loss: 0.009410\n",
      "[4950] Loss: 0.009202\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "batch_size = 2110\n",
    "num_epochs = 5000\n",
    "learning_rate = 1e-3\n",
    "latent_dim = latent_tensor.shape[1]  # e.g., 50\n",
    "epochs_list = []\n",
    "loss_list = []\n",
    "\n",
    "vf_model = NeuralVectorField(latent_dim=latent_dim).to(device)\n",
    "optimizer = torch.optim.AdamW(vf_model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Initialize GaussianConditionalProbabilityPath and ConditionalVectorFieldODE\n",
    "path = GaussianConditionalProbabilityPath(emp_dist, alpha, beta)  # define alpha, beta\n",
    "cvf_ode = ConditionalVectorFieldODE(path, z=torch.zeros(1, latent_dim, device=device))\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # --- Sample conditioning variable z ---\n",
    "    z = emp_dist.sample(batch_size).to(device)\n",
    "\n",
    "    # --- Sample time ---\n",
    "    t = torch.rand(batch_size, 1, device=device)\n",
    "\n",
    "    # --- Sample x_t from conditional path ---\n",
    "    with torch.no_grad():\n",
    "        x = path.sample_conditional_path(z, t)\n",
    "        u_target = path.conditional_vector_field(x, z, t)\n",
    "\n",
    "    # --- Normalize target ---\n",
    "    u_mean = u_target.mean(dim=0, keepdim=True)\n",
    "    u_std = u_target.std(dim=0, keepdim=True) + 1e-6\n",
    "    u_target_norm = (u_target - u_mean) / u_std\n",
    "\n",
    "    # --- Forward pass ---\n",
    "    v_pred = vf_model(x, z, t)\n",
    "\n",
    "    # --- Loss ---\n",
    "    loss = F.mse_loss(v_pred, u_target_norm)\n",
    "\n",
    "    # --- Backprop ---\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    torch.nn.utils.clip_grad_norm_(vf_model.parameters(), max_norm=1.0)\n",
    "    optimizer.step()\n",
    "\n",
    "    # --- Save stats ---\n",
    "    epochs_list.append(epoch)\n",
    "    loss_list.append(float(loss))\n",
    "\n",
    "    if epoch % 50 == 0:\n",
    "        print(f\"[{epoch}] Loss: {loss.item():.6f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0379eb13-6e48-4e09-9699-b7a932bb9ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(epoch_list, loss_list)\n",
    "plt.title('Training of flow')\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Average loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "b46c5956-d23f-463a-8541-7e85d2e52888",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we want to save the best vector field:\n",
    "class LearnedVectorFieldODE():\n",
    "    def __init__(self, vf_model):\n",
    "        self.vf_model = vf_model\n",
    "\n",
    "    def drift_coefficient(self, x: torch.Tensor, t: torch.Tensor, z: torch.Tensor) -> torch.Tensor:\n",
    "        # x, z: (batch_size, latent_dim)\n",
    "        # t: (batch_size, 1)\n",
    "        return self.vf_model(x, z, t)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "2376f019-c84c-4f60-bc09-84ec341a1511",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrap the trained neural network\n",
    "learned_ode = LearnedVectorFieldODE(vf_model)\n",
    "\n",
    "# Save the wrapper\n",
    "torch.save(learned_ode, flow_model_save_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "d6f33abc-c1b8-410a-bc3c-8e047d42ce30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1000, 50])\n"
     ]
    }
   ],
   "source": [
    "# Number of samples and latent dimension\n",
    "n_samples = 1000\n",
    "latent_dim = latent_tensor.shape[1]\n",
    "\n",
    "# Starting points (noise)\n",
    "x = torch.randn(n_samples, latent_dim, device=device)\n",
    "\n",
    "# Conditioning variable z\n",
    "# Single vector, broadcast to all samples\n",
    "z = torch.zeros(1, latent_dim, device=device)  # or z = emp_dist.sample(1)\n",
    "\n",
    "# Wrap the trained neural network as an ODE\n",
    "learned_ode = LearnedVectorFieldODE(vf_model)\n",
    "\n",
    "# Create Euler simulator with the conditioning variable\n",
    "simulator = EulerSimulator(learned_ode, z)\n",
    "\n",
    "# Simulation parameters\n",
    "t0, t1 = 0.0, 1.0\n",
    "n_steps = 50\n",
    "dt = (t1 - t0) / n_steps\n",
    "\n",
    "# Store trajectory\n",
    "trajectory = [x.clone()]\n",
    "t = torch.full((n_samples, 1), t0, device=device)\n",
    "\n",
    "# Euler integration\n",
    "for _ in range(n_steps):\n",
    "    x = simulator.step(x, t, dt)\n",
    "    trajectory.append(x.clone())\n",
    "    t = t + dt\n",
    "\n",
    "# Final generated samples\n",
    "generated_cells = trajectory[-1]\n",
    "print(generated_cells.shape)  # (1000, latent_dim)\n",
    "torch.save(generated_cells, \"/dtu/blackhole/1e/213566/gen_data/pbmc3k/simple_generated_latent.pt\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
