{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e48c73bf-fec7-4795-b432-646e53a6bae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cfg_flow_celltype.py\n",
    "# Full script: classifier-free guidance trained on cell type\n",
    "import os\n",
    "from typing import Optional\n",
    "import math\n",
    "import anndata as ad\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.distributions as D\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "36282d56-f328-4d07-8e92-804d54471f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# ---- paths (edit if needed)\n",
    "input_file_path = \"/dtu/blackhole/1e/213566/data/datasets/pbmc3k/pbmc3k_train_with_latent.h5ad\"\n",
    "flow_model_save_path = \"/dtu/blackhole/1e/213566/models/simple_flow_model_state.pth\"\n",
    "generated_save_path = \"/dtu/blackhole/1e/213566/gen_data/pbmc3k/simple_generated_latent.pt\"\n",
    "os.makedirs(os.path.dirname(flow_model_save_path), exist_ok=True)\n",
    "os.makedirs(os.path.dirname(generated_save_path), exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4a96f78b-0433-437b-8648-7c573cb27875",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of latent space: (2110, 50)\n",
      "Found 8 cell types: ['B cells' 'CD14+ Monocytes' 'CD4 T cells' 'CD8 T cells' 'Dendritic cells'\n",
      " 'FCGR3A+ Monocytes' 'Megakaryocytes' 'NK cells']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# ---- load data\n",
    "adata = ad.read_h5ad(input_file_path)\n",
    "latent = adata.obsm[\"X_latent\"]\n",
    "latent_tensor = torch.tensor(latent, dtype=torch.float32, device=device)\n",
    "print(\"Shape of latent space:\", latent.shape)\n",
    "\n",
    "# ---- cell type labels\n",
    "cell_types = adata.obs[\"cell_type\"].astype(str).values\n",
    "# map to indices\n",
    "unique_types, inverse_idx = np.unique(cell_types, return_inverse=True)\n",
    "num_cell_types = len(unique_types)\n",
    "cell_type_idx = torch.tensor(inverse_idx, dtype=torch.long, device=device)  # length N\n",
    "\n",
    "print(f\"Found {num_cell_types} cell types: {unique_types}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f0db0785-b539-4dfc-aa03-a28c0bac11ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Empirical distribution (KDE-like sampler/log density)\n",
    "class EmpiricalDistribution(torch.nn.Module):\n",
    "    def __init__(self, data: torch.Tensor, bandwidth: Optional[float] = None, compute_log_density: bool = True):\n",
    "        super().__init__()\n",
    "        assert data.dim() == 2, \"data must be shape (N, D)\"\n",
    "        data = data.contiguous()\n",
    "        self.register_buffer(\"data\", data)   # (N, D)\n",
    "        self.n = data.shape[0]\n",
    "        self.data_dim = data.shape[1]\n",
    "        self.compute_log_density_flag = compute_log_density\n",
    "\n",
    "        # bandwidth scalar\n",
    "        if bandwidth is None:\n",
    "            std = torch.std(data, dim=0).mean().item()\n",
    "            factor = (4.0 / (self.data_dim + 2.0)) ** (1.0 / (self.data_dim + 4.0))\n",
    "            bw = factor * (self.n ** (-1.0 / (self.data_dim + 4.0))) * (std + 1e-6)\n",
    "            bw = float(bw)\n",
    "        else:\n",
    "            bw = float(bandwidth)\n",
    "        self.register_buffer(\"bandwidth\", torch.tensor(bw, device=self.data.device))\n",
    "        # log constant as tensor\n",
    "        self._log_const = -0.5 * self.data_dim * math.log(2.0 * math.pi) - self.data_dim * torch.log(self.bandwidth)\n",
    "\n",
    "    @property\n",
    "    def dim(self):\n",
    "        return self.data_dim\n",
    "\n",
    "    def sample(self, num_samples: int) -> torch.Tensor:\n",
    "        idx = torch.randint(0, self.n, (num_samples,), device=self.data.device)\n",
    "        return self.data[idx]\n",
    "\n",
    "    def log_density(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        if not self.compute_log_density_flag:\n",
    "            raise RuntimeError(\"log_density disabled (compute_log_density=False).\")\n",
    "        assert x.dim() == 2 and x.shape[1] == self.data_dim\n",
    "        x = x.to(self.data.device)\n",
    "        x_norm2 = (x ** 2).sum(dim=1, keepdim=True)             # (bs,1)\n",
    "        data_norm2 = (self.data ** 2).sum(dim=1).unsqueeze(0)    # (1, N)\n",
    "        cross = x @ self.data.t()                               # (bs, N)\n",
    "        d2 = x_norm2 + data_norm2 - 2.0 * cross\n",
    "        sigma2 = (self.bandwidth ** 2)\n",
    "        exponents = -0.5 * d2 / (sigma2 + 1e-12)\n",
    "        lse = torch.logsumexp(exponents, dim=1, keepdim=True)\n",
    "        log_prob = math.log(1.0 / self.n) + lse + self._log_const\n",
    "        return log_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f26842e5-953c-4adf-b7c7-fc90f7c853c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "emp_dist = EmpiricalDistribution(latent_tensor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "51658583-76f9-4359-9c3f-648ea5605e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Gaussian conditional path / analytic vector field\n",
    "class LinearAlpha():\n",
    "    def __call__(self, t: torch.Tensor) -> torch.Tensor:\n",
    "        return t\n",
    "    def dt(self, t: torch.Tensor) -> torch.Tensor:\n",
    "        return torch.ones_like(t)\n",
    "\n",
    "class LinearBeta():\n",
    "    def __call__(self, t: torch.Tensor) -> torch.Tensor:\n",
    "        return 1 - t\n",
    "    def dt(self, t: torch.Tensor) -> torch.Tensor:\n",
    "        return -torch.ones_like(t)\n",
    "\n",
    "class GaussianConditionalProbabilityPath():\n",
    "    def __init__(self, p_data, alpha, beta):\n",
    "        self.p_data = p_data\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "\n",
    "    def sample_conditioning_variable(self, num_samples: int) -> torch.Tensor:\n",
    "        return self.p_data.sample(num_samples)\n",
    "\n",
    "    def sample_conditional_path(self, z: torch.Tensor, t: torch.Tensor) -> torch.Tensor:\n",
    "        # p_t(x|z) = N(alpha_t * z, beta_t^2 I)\n",
    "        return self.alpha(t) * z + self.beta(t) * torch.randn_like(z)\n",
    "\n",
    "    def conditional_vector_field(self, x: torch.Tensor, z: torch.Tensor, t: torch.Tensor) -> torch.Tensor:\n",
    "        # u_t(x|z) as in your formula\n",
    "        alpha_t = self.alpha(t)\n",
    "        beta_t = self.beta(t)\n",
    "        dt_alpha_t = self.alpha.dt(t)\n",
    "        dt_beta_t = self.beta.dt(t)\n",
    "        return (dt_alpha_t - dt_beta_t / beta_t * alpha_t) * z + (dt_beta_t / beta_t) * x\n",
    "\n",
    "    def conditional_score(self, x: torch.Tensor, z: torch.Tensor, t: torch.Tensor) -> torch.Tensor:\n",
    "        alpha_t = self.alpha(t)\n",
    "        beta_t = self.beta(t)\n",
    "        return (z * alpha_t - x) / beta_t ** 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9245e61d-0c84-42c6-8bc9-016a457befe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "alpha = LinearAlpha()\n",
    "beta = LinearBeta()\n",
    "path = GaussianConditionalProbabilityPath(emp_dist, alpha, beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6699f75e-902f-422c-9f8f-8e2fd433418e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ---- Neural vector field\n",
    "class TimeEmbedder(nn.Module):\n",
    "    def __init__(self, embed_dim=32, max_freq=1e4):\n",
    "        super().__init__()\n",
    "        assert embed_dim % 2 == 0\n",
    "        self.embed_dim = embed_dim\n",
    "        self.max_freq = max_freq\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(embed_dim, embed_dim),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(embed_dim, embed_dim),\n",
    "            nn.SiLU()\n",
    "        )\n",
    "    def forward(self, t):\n",
    "        freqs = torch.exp(torch.linspace(0, math.log(self.max_freq), self.embed_dim // 2, device=t.device))\n",
    "        args = t * freqs\n",
    "        emb = torch.cat([torch.sin(args), torch.cos(args)], dim=-1)\n",
    "        return self.mlp(emb)\n",
    "\n",
    "class ResNetBlock(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super().__init__()\n",
    "        self.block = nn.Sequential(\n",
    "            nn.Linear(dim, dim),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(dim, dim)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return x + self.block(x)\n",
    "\n",
    "class NeuralVectorField(nn.Module):\n",
    "    def __init__(self, latent_dim, hidden_dim=256, n_resblocks=3, time_embed_dim=64):\n",
    "        super().__init__()\n",
    "        self.x_proj = nn.Linear(latent_dim, hidden_dim)\n",
    "        # z is cell-type conditioning vector projected into hidden_dim\n",
    "        self.z_proj = nn.Linear(latent_dim, hidden_dim)\n",
    "        self.time_embedder = TimeEmbedder(time_embed_dim)\n",
    "        in_dim = hidden_dim * 2 + time_embed_dim\n",
    "        self.resblocks = nn.ModuleList([ResNetBlock(in_dim) for _ in range(n_resblocks)])\n",
    "        self.output_layer = nn.Linear(in_dim, latent_dim)\n",
    "\n",
    "    def forward(self, x, z, t):\n",
    "        \"\"\"\n",
    "        x: (bs, latent_dim)\n",
    "        z: (bs, latent_dim) -- conditioning (from cell type)\n",
    "        t: (bs, 1)\n",
    "        \"\"\"\n",
    "        xh = self.x_proj(x)\n",
    "        zh = self.z_proj(z)\n",
    "        th = self.time_embedder(t)  # (bs, time_embed_dim)\n",
    "        h = torch.cat([xh, zh, th], dim=-1)\n",
    "        for block in self.resblocks:\n",
    "            h = block(h)\n",
    "        return self.output_layer(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2b3a53f2-2ba9-4cc0-8fdf-7e7e7b8508a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ---- cell-type conditioning module: one-hot projection + learned embedding\n",
    "class CellTypeConditioner(nn.Module):\n",
    "    def __init__(self, n_cell_types, latent_dim, use_one_hot=True, one_hot_proj_dim=None, embed_dim=None):\n",
    "        super().__init__()\n",
    "        self.n_types = n_cell_types\n",
    "        self.latent_dim = latent_dim\n",
    "        self.use_one_hot = use_one_hot\n",
    "        # learned embedding\n",
    "        embed_dim = latent_dim if embed_dim is None else embed_dim\n",
    "        self.type_embed = nn.Embedding(n_cell_types, embed_dim)\n",
    "        # project one-hot into same space if requested\n",
    "        if self.use_one_hot:\n",
    "            one_hot_proj_dim = latent_dim if one_hot_proj_dim is None else one_hot_proj_dim\n",
    "            self.one_hot_proj = nn.Linear(n_cell_types, embed_dim)\n",
    "        else:\n",
    "            self.one_hot_proj = None\n",
    "        # final projector to the latent_dim (z must be latent_dim)\n",
    "        self.final_proj = nn.Linear(embed_dim, latent_dim)\n",
    "\n",
    "    def forward(self, type_idx: torch.LongTensor):\n",
    "        # type_idx: (bs,) long\n",
    "        emb = self.type_embed(type_idx)   # (bs, embed_dim)\n",
    "        if self.use_one_hot:\n",
    "            # build one-hot\n",
    "            bs = type_idx.shape[0]\n",
    "            one_hot = torch.zeros(bs, self.n_types, device=type_idx.device)\n",
    "            one_hot.scatter_(1, type_idx.unsqueeze(1), 1.0)\n",
    "            oh_proj = self.one_hot_proj(one_hot)  # (bs, embed_dim)\n",
    "            emb = emb + oh_proj\n",
    "        z = self.final_proj(emb)  # (bs, latent_dim)\n",
    "        return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d3d23631-7158-4b3f-a5a3-b69c1a95664c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# ---- ODE wrapper and Euler simulator (stateless, accepts z)\n",
    "class LearnedVectorFieldODE():\n",
    "    def __init__(self, vf_model: nn.Module):\n",
    "        self.vf_model = vf_model\n",
    "    def drift_coefficient(self, x: torch.Tensor, t: torch.Tensor, z: torch.Tensor) -> torch.Tensor:\n",
    "        return self.vf_model(x, z, t)\n",
    "\n",
    "class EulerSimulator():\n",
    "    def __init__(self, ode: LearnedVectorFieldODE):\n",
    "        self.ode = ode\n",
    "    def step(self, xt: torch.Tensor, t: torch.Tensor, h: float, z: torch.Tensor):\n",
    "        dx = self.ode.drift_coefficient(xt, t, z)\n",
    "        return xt + dx * h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0407ef41-901d-48a3-aa6c-523150b155a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ---- hyperparams\n",
    "batch_size = 256\n",
    "num_epochs = 2000\n",
    "learning_rate = 1e-3\n",
    "latent_dim = latent_tensor.shape[1]\n",
    "drop_prob = 0.1   # classifier-free: drop conditioning p=0.1\n",
    "guidance_scale = 2.0  # sampling: positive amplifies conditioning\n",
    "n_steps = 50\n",
    "dt = 1.0 / n_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "32a545c8-df4c-49b5-8fc5-a296867ed0d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|                                                                                                                                    | 0/2000 [00:00<?, ?it/s]/tmp/ipykernel_2039594/3428351390.py:55: UserWarning: Converting a tensor with requires_grad=True to a scalar may lead to unexpected behavior.\n",
      "Consider using tensor.detach() first. (Triggered internally at /pytorch/torch/csrc/autograd/generated/python_variable_methods.cpp:836.)\n",
      "  loss_list.append(float(loss))\n",
      "Training: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████| 2000/2000 [00:07<00:00, 254.93it/s, loss=2.515338e-02]\n"
     ]
    }
   ],
   "source": [
    "# ---- models\n",
    "vf_model = NeuralVectorField(latent_dim=latent_dim, hidden_dim=256, n_resblocks=3, time_embed_dim=64).to(device)\n",
    "cell_conditioner = CellTypeConditioner(n_cell_types=num_cell_types, latent_dim=latent_dim, use_one_hot=True).to(device)\n",
    "optimizer = torch.optim.AdamW(list(vf_model.parameters()) + list(cell_conditioner.parameters()), lr=learning_rate)\n",
    "\n",
    "# ---- training loop (Classifier-Free Guidance training on cell type)\n",
    "# We'll train so that when we drop conditioning we feed z_null (zero vector) and sample x consistent with that null conditioning.\n",
    "z_null = torch.zeros(1, latent_dim, device=device)  # null token (broadcastable)\n",
    "\n",
    "num_data = latent_tensor.shape[0]\n",
    "# create a mapping from dataset indices to cell type indices (to sample cell-type for each sampled latent index)\n",
    "# We will sample cell types by sampling indices in dataset\n",
    "dataset_indices = torch.arange(num_data, device=device)\n",
    "cell_type_indices_per_data = cell_type_idx  # length N longs\n",
    "\n",
    "pbar = tqdm(range(num_epochs), desc=\"Training\")\n",
    "\n",
    "loss_list = []\n",
    "epoch_list= []\n",
    "\n",
    "for epoch in pbar:\n",
    "    # sample dataset indices for batch (with replacement)\n",
    "    idx = torch.randint(0, num_data, (batch_size,), device=device)\n",
    "    # get cell types for those indices\n",
    "    types = cell_type_indices_per_data[idx]  # (bs,)\n",
    "    # create drop mask for classifier-free (True => drop -> unconditional)\n",
    "    drop_mask = (torch.rand(batch_size, device=device) < drop_prob)\n",
    "\n",
    "    # create z_used (conditioning) per example: either cell-type embedding or null\n",
    "    # but sample z_used such that x is sampled from p_t(x | z_used)\n",
    "    t = torch.rand(batch_size, 1, device=device)  # times\n",
    "    # compute type-conditioned z vectors\n",
    "    z_type = cell_conditioner(types)  # (bs, latent_dim)\n",
    "    # mask and choose z_used\n",
    "    z_used = z_type.clone()\n",
    "    if drop_mask.any():\n",
    "        z_used[drop_mask] = z_null  # unconditional entries\n",
    "\n",
    "    # sample x from conditional path consistent with z_used\n",
    "    with torch.no_grad():\n",
    "        x = path.sample_conditional_path(z_used, t)          # (bs, latent_dim)\n",
    "        u_target = path.conditional_vector_field(x, z_used, t)  # target vector field (bs, latent_dim)\n",
    "\n",
    "    # forward pass through network (it receives the same z_used the target was computed with)\n",
    "    v_pred = vf_model(x, z_used, t)\n",
    "\n",
    "    # loss: direct MSE between predicted and analytic vector field (no ad-hoc normalization)\n",
    "    loss = F.mse_loss(v_pred, u_target)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    torch.nn.utils.clip_grad_norm_(vf_model.parameters(), max_norm=1.0)\n",
    "    optimizer.step()\n",
    "\n",
    "    loss_list.append(float(loss))\n",
    "    epoch_list.append(epoch)\n",
    "\n",
    "    if epoch % 50 == 0:\n",
    "        pbar.set_postfix_str(f\"loss={loss.item():.6e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "63449016-51d9-412d-9faa-dd1b4cefab49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(epoch_list, loss_list)\n",
    "plt.title('Training of flow')\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Average loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e24d889e-7f18-4956-b87d-19677c2bf38b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model state to /dtu/blackhole/1e/213566/models/simple_flow_model_state.pth\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ---- save state dicts\n",
    "torch.save({\n",
    "    'vf_state': vf_model.state_dict(),\n",
    "    'cell_conditioner_state': cell_conditioner.state_dict(),\n",
    "    'latent_dim': latent_dim,\n",
    "    'num_cell_types': num_cell_types,\n",
    "}, flow_model_save_path)\n",
    "print(\"Saved model state to\", flow_model_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4d8d9d09-6ab2-4c0a-a43e-44f8f866cd26",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# ---- sampling with classifier-free guidance (generate latent samples conditioned on a desired cell type)\n",
    "def sample_with_cfg(vf_model, cell_conditioner, target_type_idx:int, n_samples=1000, guidance_scale=2.0, n_steps=50, dt=1.0/50, device='cpu'):\n",
    "    vf_model.eval()\n",
    "    cell_conditioner.eval()\n",
    "    latent_dim = next(vf_model.parameters()).shape[-1] if False else latent_dim_global  # we'll supply latent_dim_global below\n",
    "\n",
    "    # initial noise\n",
    "    x = torch.randn(n_samples, latent_dim, device=device)\n",
    "\n",
    "    # conditioning vectors\n",
    "    # z_cond: conditioning embedding for the requested cell type (broadcasted to n_samples)\n",
    "    type_idx_tensor = torch.full((n_samples,), target_type_idx, dtype=torch.long, device=device)\n",
    "    z_cond = cell_conditioner(type_idx_tensor)  # (n_samples, latent_dim)\n",
    "    # z_uncond: null token (zeros)\n",
    "    z_uncond = torch.zeros(n_samples, latent_dim, device=device)\n",
    "\n",
    "    t = torch.zeros(n_samples, 1, device=device)  # starting t=0, we'll step forward to t=1 (note: your alpha/beta definitions use t in [0,1])\n",
    "    # We trained with sampling x from p_t(x|z) with t drawn ~ Uniform(0,1). For sampling path integration: integrate from t=0 to t=1 with learned vector field\n",
    "    for step in range(n_steps):\n",
    "        # compute current time (t scalar for this step) as a tensor matching batch\n",
    "        # in our simple Euler loop we keep t increasing uniformly\n",
    "        # t is used inside the network TimeEmbedder; we keep it as current t\n",
    "        # compute predictions for cond and uncond\n",
    "        v_uncond = vf_model(x, z_uncond, t)\n",
    "        v_cond = vf_model(x, z_cond, t)\n",
    "        # classifier-free guidance: uncond + scale * (cond - uncond)\n",
    "        v_guided = v_uncond + guidance_scale * (v_cond - v_uncond)\n",
    "\n",
    "        # Euler step\n",
    "        x = x + v_guided * dt\n",
    "\n",
    "        # increment time\n",
    "        t = t + dt\n",
    "\n",
    "    return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "81efd971-c9fc-4e3e-ae68-33195432c742",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated shape: torch.Size([1000, 50])\n",
      "Saved generated latent to /dtu/blackhole/1e/213566/gen_data/pbmc3k/simple_generated_latent.pt\n"
     ]
    }
   ],
   "source": [
    "# convenience helper to provide latent_dim into sampling function\n",
    "latent_dim_global = latent_dim  # make available for sampling helper above\n",
    "\n",
    "# Example: generate 1000 samples conditioned on the first cell type\n",
    "target_type_idx_example = 0\n",
    "generated = sample_with_cfg(vf_model, cell_conditioner, target_type_idx_example, n_samples=1000,\n",
    "                            guidance_scale=guidance_scale, n_steps=n_steps, dt=dt, device=device)\n",
    "\n",
    "print(\"Generated shape:\", generated.shape)\n",
    "torch.save(generated.cpu(), generated_save_path)\n",
    "print(\"Saved generated latent to\", generated_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9585bfba-2d2d-4a6d-940d-8cd34e15715f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4824f906-224c-4aaa-83db-0ef7995132e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1207d54f-991f-42c1-8874-175aafd89f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this the cleaner version of the flow matching model\n",
    "# import all packages and data\n",
    "# the data comes from the encoder in 50 dimensional format\n",
    "from abc import ABC, abstractmethod\n",
    "from typing import Optional, List, Type, Tuple, Dict\n",
    "import math\n",
    "import anndata as ad\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "from matplotlib.axes._axes import Axes\n",
    "import torch\n",
    "import torch.distributions as D\n",
    "from torch.func import vmap, jacrev\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "from sklearn.datasets import make_moons, make_circles\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e98a63f9-469b-4f22-9da0-a88d91f27b7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of latent space: (2110, 50)\n",
      "[[-4.8265247e+00  6.4398712e-01  2.9313943e-01  3.0890481e+00\n",
      "   1.1765828e+00 -7.8912878e-01 -5.3665400e+00 -1.3968008e+00\n",
      "   1.2098600e+00  3.3365767e+00 -3.8481004e+00  7.0330495e-01\n",
      "  -3.4451597e+00  4.1077366e+00  4.2849655e+00  6.9920130e+00\n",
      "   3.0892158e+00 -7.6523461e+00 -1.8158824e+00  2.7222965e+00\n",
      "  -2.8834870e+00 -2.7645674e+00  1.6244851e+00  4.3940554e+00\n",
      "   6.3701739e+00 -2.4180744e+00  3.1864629e+00 -1.7486143e+00\n",
      "  -2.4821444e+00  5.4535675e+00 -3.1519279e+00  2.4320188e+00\n",
      "  -3.4471009e+00  1.7183326e+00 -1.6651822e+00  5.9247975e+00\n",
      "  -5.0021301e-04  2.7415204e+00  3.2821023e+00  6.1637068e+00\n",
      "  -6.2996321e+00  3.1250734e+00  1.8593316e+00 -7.3208661e+00\n",
      "  -1.1019467e+00 -1.6716359e+00  6.3101897e+00  6.6704327e-01\n",
      "   1.1906556e+00  9.7726297e+00]\n",
      " [ 1.5488584e+00  8.6747295e-01  2.4328077e+00  5.4669249e-01\n",
      "  -1.4461365e+00  9.0370119e-01 -1.4667183e+00  5.5467706e+00\n",
      "   2.7354531e+00  5.1444712e+00 -3.5800772e+00  6.4247775e-01\n",
      "   2.1787410e+00  6.3186998e+00 -5.5455709e-01  4.6751018e+00\n",
      "  -9.3820441e-01 -2.2597036e+00 -2.7249477e+00 -1.9599915e+00\n",
      "  -5.9335990e+00  1.2720106e+00 -4.6455646e-01  5.3204620e-01\n",
      "  -2.9415808e+00  3.6324754e+00  1.7678853e+00 -2.8310272e-01\n",
      "  -3.7237737e+00  7.9976339e+00 -2.0772293e+00  2.4106984e+00\n",
      "  -9.8446913e+00 -1.4068246e+00 -1.4844252e+00 -6.1113896e+00\n",
      "   3.8356486e-01 -6.3886142e+00  7.1353310e-01  6.3777995e+00\n",
      "  -8.9152366e-01  5.6871819e+00 -5.4136047e+00 -1.4658002e+00\n",
      "   2.8592350e+00  7.9939657e-01  4.8240552e+00 -3.8440723e+00\n",
      "  -2.6065490e+00 -1.9924434e+00]\n",
      " [ 6.7751184e+00 -1.9650035e+00  6.6917911e-03  1.6059226e+00\n",
      "   2.7730074e+00  2.9611313e+00  1.4775300e+00  3.0489528e+00\n",
      "  -4.7885275e+00  4.4003568e+00  1.2807679e+00 -2.3877699e+00\n",
      "   2.0206100e-01 -4.9933977e+00  2.8354318e+00 -1.6389264e+00\n",
      "  -4.4867449e+00 -5.4850860e+00 -7.4981719e-01 -4.0616407e+00\n",
      "  -1.0990691e+00  3.9984593e+00  3.1979673e+00 -4.0054750e+00\n",
      "  -1.9100716e+00  8.1177788e+00 -6.0076094e+00 -2.9372659e-01\n",
      "   2.2602201e+00 -3.2328019e+00  5.0461969e+00  3.2422843e+00\n",
      "  -7.6047438e-01  5.0867615e+00 -5.5351119e+00 -9.0320683e+00\n",
      "  -1.5276861e+00  7.4957901e-01  3.1575108e+00  5.0317769e+00\n",
      "  -4.1042337e+00 -3.7397331e-01 -2.0166941e+00 -2.7442350e+00\n",
      "   8.2472286e+00  3.2472920e+00 -5.4465232e+00  2.3579447e+00\n",
      "   2.0914984e+00 -1.8767326e+00]\n",
      " [ 5.0700288e+00  2.2409852e+00  2.3104541e+00 -6.6748877e+00\n",
      "   2.8069370e+00 -4.8635693e+00  1.4162869e+00 -3.3387730e+00\n",
      "  -2.6978464e+00  2.0403345e+00 -5.6362209e+00 -7.7254191e-02\n",
      "   5.5195814e-01 -3.0642953e+00  7.0819384e-01 -4.0020428e+00\n",
      "   5.1475711e+00 -1.7155046e+00 -9.2213974e+00 -1.9366992e+00\n",
      "  -2.8229001e+00  3.0421391e+00 -7.3566008e-01 -9.2591009e+00\n",
      "   7.8342052e+00  1.3716816e+00 -5.7953882e+00  5.1934987e-01\n",
      "   4.5598283e+00  1.8589866e+00  1.2835141e-01  3.5464725e+00\n",
      "   8.3187437e+00  5.7540255e+00  2.2155868e-01  2.0466888e+00\n",
      "   3.0196857e+00 -7.0920529e+00 -4.6274800e+00 -6.4521365e+00\n",
      "   2.0799942e+00  5.8254786e+00  7.6756306e+00 -1.8239713e+00\n",
      "   4.4370918e+00  3.6463275e+00  2.8738267e+00  2.3060329e+00\n",
      "  -6.2184973e+00  1.8938814e+00]\n",
      " [-2.3850689e+00 -5.7374591e-01 -1.3855569e+00  3.8847613e-01\n",
      "   7.0980268e+00 -5.4684505e+00 -2.6609707e+00 -4.7543464e+00\n",
      "   4.8109221e+00 -3.7715290e+00 -4.3458061e+00  3.7296431e+00\n",
      "  -4.3459749e-01  4.3304949e+00  3.2698853e+00  4.4319296e+00\n",
      "   1.3189467e+00  1.8493114e+00  4.4517989e+00 -3.1720688e+00\n",
      "  -4.5946267e-01 -9.7169036e-01  9.4882574e+00  2.5796080e+00\n",
      "  -3.2056787e+00  5.5426359e-01 -1.7064942e+00  1.9991691e+00\n",
      "  -6.2869930e+00  6.2788601e+00 -2.2004094e+00  5.5189166e+00\n",
      "  -4.0317602e+00 -2.3209066e+00  4.5294300e-01 -6.5755069e-01\n",
      "   8.3470106e-01  2.0718412e+00  3.8887563e+00  1.0863941e+00\n",
      "  -1.4920738e+00 -4.4379124e-01 -1.6892056e+00 -6.5763249e+00\n",
      "   3.8011248e+00 -1.2591158e+00 -1.7584739e+00  8.0035706e+00\n",
      "   2.2274804e+00  3.4165080e+00]]\n"
     ]
    }
   ],
   "source": [
    "# Load the encoded data from the autoencoder\n",
    "input_file_path = \"/dtu/blackhole/1e/213566/data/datasets/pbmc3k/pbmc3k_train_with_latent.h5ad\"\n",
    "flow_model_save_path = \"/dtu/blackhole/1e/213566/models/simple_flow_model.pt\"\n",
    "adata = ad.read_h5ad(input_file_path)\n",
    "\n",
    "# Access latent representation\n",
    "latent = adata.obsm[\"X_latent\"]\n",
    "# make it to a tensor and save in GPU\n",
    "latent_tensor = torch.tensor(latent, dtype=torch.float32, device = device)\n",
    "print(\"Shape of latent space:\", latent.shape)\n",
    "print(latent[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2d9554cd-e92b-4ffd-a307-89cfcadca6ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a way of encoding our data for empirical data\n",
    "class EmpiricalDistribution(torch.nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        data: torch.Tensor,\n",
    "        bandwidth: Optional[float] = None,\n",
    "        compute_log_density: bool = True,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        assert data.dim() == 2, \"data must be shape (N, D)\"\n",
    "        data = data.contiguous()\n",
    "        \n",
    "        self.register_buffer(\"data\", data)   # (N, D)\n",
    "        self.n = data.shape[0]\n",
    "        self.data_dim = data.shape[1]        # <-- renamed attribute\n",
    "        self.compute_log_density_flag = compute_log_density\n",
    "\n",
    "        # Bandwidth estimation\n",
    "        if bandwidth is None:\n",
    "            std = torch.std(data, dim=0).mean().item()\n",
    "            factor = (4.0 / (self.data_dim + 2.0)) ** (1.0 / (self.data_dim + 4.0))\n",
    "            bw = factor * (self.n ** (-1.0 / (self.data_dim + 4.0))) * (std + 1e-6)\n",
    "            self.bandwidth = torch.tensor(float(bw), device=self.data.device)\n",
    "        else:\n",
    "            self.bandwidth = torch.tensor(float(bandwidth), device=self.data.device)\n",
    "\n",
    "        self._log_const = -0.5 * self.data_dim * math.log(2.0 * math.pi) - self.data_dim * torch.log(self.bandwidth).item()\n",
    "\n",
    "    @property\n",
    "    def dim(self):\n",
    "        return self.data_dim\n",
    "    def sample(self, num_samples: int) -> torch.Tensor:\n",
    "        idx = torch.randint(0, self.n, (num_samples,), device=self.data.device)\n",
    "        return self.data[idx]\n",
    "\n",
    "    def log_density(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        if not self.compute_log_density_flag:\n",
    "            raise RuntimeError(\"log_density disabled (compute_log_density=False).\")\n",
    "\n",
    "        assert x.dim() == 2 and x.shape[1] == self.data_dim\n",
    "\n",
    "        x = x.to(self.data.device)\n",
    "        x_norm2 = (x ** 2).sum(dim=1, keepdim=True)\n",
    "        data_norm2 = (self.data ** 2).sum(dim=1).unsqueeze(0)\n",
    "        cross = x @ self.data.t()\n",
    "        d2 = x_norm2 + data_norm2 - 2.0 * cross\n",
    "\n",
    "        sigma2 = (self.bandwidth ** 2).item()\n",
    "        exponents = -0.5 * d2 / (sigma2 + 1e-12)\n",
    "        lse = torch.logsumexp(exponents, dim=1, keepdim=True)\n",
    "\n",
    "        log_prob = math.log(1.0 / self.n) + lse + self._log_const\n",
    "        return log_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cbd6c723-2603-4ee4-a2e4-4444bf07beb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-111.4463],\n",
      "        [-111.4463],\n",
      "        [-111.4463]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# lets test if the empirical distribution class actually works\n",
    "# the data has to be a torch tensor\n",
    "\n",
    "dist = EmpiricalDistribution(latent_tensor)\n",
    "samples = dist.sample(3)\n",
    "logp = dist.log_density(samples)\n",
    "print(logp)\n",
    "\n",
    "# it seems to work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7cbc68f2-372e-428d-b98e-4d1f3a4d9b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we have to have a class that can draw from a Gaussian distribution\n",
    "\n",
    "class Gaussian(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Multivariate Gaussian distribution\n",
    "    \"\"\"\n",
    "    def __init__(self, mean: torch.Tensor, cov: torch.Tensor):\n",
    "        \"\"\"\n",
    "        mean: shape (dim,)\n",
    "        cov: shape (dim,dim)\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.register_buffer(\"mean\", mean)\n",
    "        self.register_buffer(\"cov\", cov)\n",
    "\n",
    "    @property\n",
    "    def dim(self) -> int:\n",
    "        return self.mean.shape[0]\n",
    "\n",
    "    @property\n",
    "    def distribution(self):\n",
    "        return D.MultivariateNormal(self.mean, self.cov, validate_args=False)\n",
    "\n",
    "    def sample(self, num_samples) -> torch.Tensor:\n",
    "        return self.distribution.sample((num_samples,))\n",
    "        \n",
    "    def log_density(self, x: torch.Tensor):\n",
    "        return self.distribution.log_prob(x).view(-1, 1)\n",
    "\n",
    "    @classmethod\n",
    "    def isotropic(cls, dim: int, std: float) -> \"Gaussian\":\n",
    "        mean = torch.zeros(dim)\n",
    "        cov = torch.eye(dim) * std ** 2\n",
    "        return cls(mean, cov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3433c200-5e40-4dc6-8fca-201b13c7b531",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We want to go with Gaussian probability path, therefore we need to load functions for alpha and beta\n",
    "class LinearAlpha():\n",
    "    \"\"\"Implements alpha_t = t\"\"\"\n",
    "    \n",
    "    def __call__(self, t: torch.Tensor) -> torch.Tensor:\n",
    "        return t  # linear in time\n",
    "\n",
    "    def dt(self, t: torch.Tensor) -> torch.Tensor:\n",
    "        return torch.ones_like(t)  # derivative of t is 1\n",
    "\n",
    "\n",
    "class LinearBeta():\n",
    "    \"\"\"Implements beta_t = 1 - t\"\"\"\n",
    "    \n",
    "    def __call__(self, t: torch.Tensor) -> torch.Tensor:\n",
    "        return 1 - t\n",
    "\n",
    "    def dt(self, t: torch.Tensor) -> torch.Tensor:\n",
    "        return -torch.ones_like(t)  # derivative of 1 - t is -1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "98ba9fdd-c53b-4e8e-b80d-a142773b04aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GaussianConditionalProbabilityPath():\n",
    "    def __init__(self, p_data, alpha, beta):\n",
    "        self.p_data = p_data \n",
    "        p_simple = Gaussian.isotropic(p_data.dim, 1.0)\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "\n",
    "    def sample_conditioning_variable(self, num_samples: int) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Samples the conditioning variable z ~ p_data(x)\n",
    "        Args:\n",
    "            - num_samples: the number of samples\n",
    "        Returns:\n",
    "            - z: samples from p(z), (num_samples, dim)\n",
    "        \"\"\"\n",
    "        return self.p_data.sample(num_samples)\n",
    "    \n",
    "    def sample_conditional_path(self, z: torch.Tensor, t: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Samples from the conditional distribution p_t(x|z) = N(alpha_t * z, beta_t**2 * I_d)\n",
    "        Args:\n",
    "            - z: conditioning variable (num_samples, dim)\n",
    "            - t: time (num_samples, 1)\n",
    "        Returns:\n",
    "            - x: samples from p_t(x|z), (num_samples, dim)\n",
    "        \"\"\"\n",
    "        return self.alpha(t) * z + self.beta(t) * torch.randn_like(z)\n",
    "        \n",
    "    def conditional_vector_field(self, x: torch.Tensor, z: torch.Tensor, t: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Evaluates the conditional vector field u_t(x|z)\n",
    "        Note: Only defined on t in [0,1)\n",
    "        Args:\n",
    "            - x: position variable (num_samples, dim)\n",
    "            - z: conditioning variable (num_samples, dim)\n",
    "            - t: time (num_samples, 1)\n",
    "        Returns:\n",
    "            - conditional_vector_field: conditional vector field (num_samples, dim)\n",
    "        \"\"\" \n",
    "        alpha_t = self.alpha(t) # (num_samples, 1)\n",
    "        beta_t = self.beta(t) # (num_samples, 1)\n",
    "        dt_alpha_t = self.alpha.dt(t) # (num_samples, 1)\n",
    "        dt_beta_t = self.beta.dt(t) # (num_samples, 1)\n",
    "\n",
    "        return (dt_alpha_t - dt_beta_t / beta_t * alpha_t) * z + dt_beta_t / beta_t * x\n",
    "\n",
    "    def conditional_score(self, x: torch.Tensor, z: torch.Tensor, t: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Evaluates the conditional score of p_t(x|z) = N(alpha_t * z, beta_t**2 * I_d)\n",
    "        Note: Only defined on t in [0,1)\n",
    "        Args:\n",
    "            - x: position variable (num_samples, dim)\n",
    "            - z: conditioning variable (num_samples, dim)\n",
    "            - t: time (num_samples, 1)\n",
    "        Returns:\n",
    "        - conditional_score: conditional score (num_samples, dim)\n",
    "        \"\"\" \n",
    "        alpha_t = self.alpha(t)\n",
    "        beta_t = self.beta(t)\n",
    "        return (z * alpha_t - x) / beta_t ** 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8b44fee9-b80d-4755-ba62-3f83f82a5d6c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'emp_dist' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m alpha = LinearAlpha()\n\u001b[32m      2\u001b[39m beta = LinearBeta()\n\u001b[32m      3\u001b[39m path = GaussianConditionalProbabilityPath(\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m     p_data=\u001b[43memp_dist\u001b[49m,\n\u001b[32m      5\u001b[39m     alpha=alpha,\n\u001b[32m      6\u001b[39m     beta=beta\n\u001b[32m      7\u001b[39m )\n\u001b[32m      8\u001b[39m \u001b[38;5;28mprint\u001b[39m(path)\n",
      "\u001b[31mNameError\u001b[39m: name 'emp_dist' is not defined"
     ]
    }
   ],
   "source": [
    "alpha = LinearAlpha()\n",
    "beta = LinearBeta()\n",
    "emp_dist=\n",
    "\n",
    "path = GaussianConditionalProbabilityPath(\n",
    "    p_data=emp_dist,\n",
    "    alpha=alpha,\n",
    "    beta=beta\n",
    ")\n",
    "print(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "901c8e9e-c97e-49a9-8c88-a2645798df18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now that we were able to construct a Gaussian probability path, we have to be able to make a conditional vector field\n",
    "\n",
    "class ConditionalVectorFieldODE():\n",
    "    def __init__(self, path, z: torch.Tensor):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "        - path: the ConditionalProbabilityPath object to which this vector field corresponds\n",
    "        - z: the conditioning variable, (1, dim)\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.path = path\n",
    "        self.z = z\n",
    "\n",
    "    def drift_coefficient(self, x: torch.Tensor, t: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Returns the conditional vector field u_t(x|z)\n",
    "        Args:\n",
    "            - x: state at time t, shape (bs, dim)\n",
    "            - t: time, shape (bs,.)\n",
    "        Returns:\n",
    "            - u_t(x|z): shape (batch_size, dim)\n",
    "        \"\"\"\n",
    "        bs = x.shape[0]\n",
    "        z = self.z.expand(bs, *self.z.shape[1:])\n",
    "        return self.path.conditional_vector_field(x,z,t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "8de56993-96dc-427b-a843-1c0dc16a7ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "cvf_ode = ConditionalVectorFieldODE(path, z)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "8fbd6bfb-437d-45e7-a33c-5f97c26691f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we somehow want to model the marginal vector field from the conditonal vector field\n",
    "# for that we will use eulers:\n",
    "class EulerSimulator():\n",
    "    def __init__(self, ode, z: torch.Tensor):\n",
    "        self.ode = ode\n",
    "        self.z = z\n",
    "\n",
    "    def step(self, xt: torch.Tensor, t: torch.Tensor, h: float):\n",
    "        \n",
    "        # Expand z to match batch size\n",
    "        if self.z.shape[0] == 1:\n",
    "            z_exp = self.z.expand(xt.shape[0], -1)\n",
    "        else:\n",
    "            z_exp = self.z\n",
    "        dx = self.ode.drift_coefficient(xt, t, z_exp)\n",
    "        return xt + dx * h\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "302131ba-68b1-4470-818b-979253a25ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch.nn as nn\n",
    "\n",
    "class TimeEmbedder(nn.Module):\n",
    "    def __init__(self, embed_dim=32, max_freq=1e4):\n",
    "        super().__init__()\n",
    "        self.embed_dim = embed_dim\n",
    "        self.max_freq = max_freq\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(embed_dim, embed_dim),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(embed_dim, embed_dim),\n",
    "            nn.SiLU()\n",
    "        )\n",
    "\n",
    "    def forward(self, t):\n",
    "        freqs = torch.exp(torch.linspace(0, math.log(self.max_freq), self.embed_dim // 2, device=t.device))\n",
    "        args = t * freqs\n",
    "        emb = torch.cat([torch.sin(args), torch.cos(args)], dim=-1)\n",
    "        return self.mlp(emb)\n",
    "\n",
    "class ResNetBlock(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super().__init__()\n",
    "        self.block = nn.Sequential(\n",
    "            nn.Linear(dim, dim),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(dim, dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x + self.block(x)\n",
    "\n",
    "class NeuralVectorField(nn.Module):\n",
    "    def __init__(self, latent_dim, hidden_dim=128, n_resblocks=3, time_embed_dim=32):\n",
    "        super().__init__()\n",
    "        self.x_proj = nn.Linear(latent_dim, hidden_dim)\n",
    "        self.z_proj = nn.Linear(latent_dim, hidden_dim)\n",
    "        self.time_embedder = TimeEmbedder(time_embed_dim)\n",
    "\n",
    "        self.resblocks = nn.ModuleList([\n",
    "            ResNetBlock(hidden_dim*2 + time_embed_dim) for _ in range(n_resblocks)\n",
    "        ])\n",
    "        self.output_layer = nn.Linear(hidden_dim*2 + time_embed_dim, latent_dim)\n",
    "\n",
    "    def forward(self, x, z, t):\n",
    "        xh = self.x_proj(x)\n",
    "        zh = self.z_proj(z)\n",
    "        th = self.time_embedder(t)\n",
    "        h = torch.cat([xh, zh, th], dim=-1)\n",
    "        for block in self.resblocks:\n",
    "            h = block(h)\n",
    "        return self.output_layer(h)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "2986d674-1040-4060-afd7-e60f1fdd74c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] Loss: 1.900425\n",
      "[50] Loss: 0.076403\n",
      "[100] Loss: 0.064227\n",
      "[150] Loss: 0.061644\n",
      "[200] Loss: 0.053724\n",
      "[250] Loss: 0.035737\n",
      "[300] Loss: 0.027486\n",
      "[350] Loss: 0.023804\n",
      "[400] Loss: 0.021102\n",
      "[450] Loss: 0.019818\n",
      "[500] Loss: 0.017939\n",
      "[550] Loss: 0.016885\n",
      "[600] Loss: 0.015444\n",
      "[650] Loss: 0.015229\n",
      "[700] Loss: 0.013819\n",
      "[750] Loss: 0.013889\n",
      "[800] Loss: 0.013724\n",
      "[850] Loss: 0.012990\n",
      "[900] Loss: 0.012491\n",
      "[950] Loss: 0.012056\n",
      "[1000] Loss: 0.011001\n",
      "[1050] Loss: 0.011520\n",
      "[1100] Loss: 0.011166\n",
      "[1150] Loss: 0.012368\n",
      "[1200] Loss: 0.010196\n",
      "[1250] Loss: 0.010411\n",
      "[1300] Loss: 0.010866\n",
      "[1350] Loss: 0.010570\n",
      "[1400] Loss: 0.011119\n",
      "[1450] Loss: 0.009777\n",
      "[1500] Loss: 0.010421\n",
      "[1550] Loss: 0.010046\n",
      "[1600] Loss: 0.010495\n",
      "[1650] Loss: 0.010226\n",
      "[1700] Loss: 0.009873\n",
      "[1750] Loss: 0.009400\n",
      "[1800] Loss: 0.010520\n",
      "[1850] Loss: 0.009726\n",
      "[1900] Loss: 0.008957\n",
      "[1950] Loss: 0.009032\n",
      "[2000] Loss: 0.009762\n",
      "[2050] Loss: 0.008079\n",
      "[2100] Loss: 0.008867\n",
      "[2150] Loss: 0.009604\n",
      "[2200] Loss: 0.009041\n",
      "[2250] Loss: 0.009238\n",
      "[2300] Loss: 0.009397\n",
      "[2350] Loss: 0.009499\n",
      "[2400] Loss: 0.009006\n",
      "[2450] Loss: 0.009298\n",
      "[2500] Loss: 0.009147\n",
      "[2550] Loss: 0.009095\n",
      "[2600] Loss: 0.008846\n",
      "[2650] Loss: 0.008508\n",
      "[2700] Loss: 0.010306\n",
      "[2750] Loss: 0.008183\n",
      "[2800] Loss: 0.009226\n",
      "[2850] Loss: 0.009003\n",
      "[2900] Loss: 0.009155\n",
      "[2950] Loss: 0.009024\n",
      "[3000] Loss: 0.008712\n",
      "[3050] Loss: 0.008452\n",
      "[3100] Loss: 0.008235\n",
      "[3150] Loss: 0.008883\n",
      "[3200] Loss: 0.009288\n",
      "[3250] Loss: 0.009641\n",
      "[3300] Loss: 0.008679\n",
      "[3350] Loss: 0.008965\n",
      "[3400] Loss: 0.009653\n",
      "[3450] Loss: 0.008329\n",
      "[3500] Loss: 0.008213\n",
      "[3550] Loss: 0.008264\n",
      "[3600] Loss: 0.009620\n",
      "[3650] Loss: 0.009602\n",
      "[3700] Loss: 0.008745\n",
      "[3750] Loss: 0.009466\n",
      "[3800] Loss: 0.008676\n",
      "[3850] Loss: 0.008274\n",
      "[3900] Loss: 0.008808\n",
      "[3950] Loss: 0.007877\n",
      "[4000] Loss: 0.007999\n",
      "[4050] Loss: 0.008510\n",
      "[4100] Loss: 0.008512\n",
      "[4150] Loss: 0.008992\n",
      "[4200] Loss: 0.008901\n",
      "[4250] Loss: 0.009591\n",
      "[4300] Loss: 0.009030\n",
      "[4350] Loss: 0.008808\n",
      "[4400] Loss: 0.009364\n",
      "[4450] Loss: 0.009096\n",
      "[4500] Loss: 0.008839\n",
      "[4550] Loss: 0.008918\n",
      "[4600] Loss: 0.010165\n",
      "[4650] Loss: 0.008653\n",
      "[4700] Loss: 0.009057\n",
      "[4750] Loss: 0.009093\n",
      "[4800] Loss: 0.008296\n",
      "[4850] Loss: 0.008383\n",
      "[4900] Loss: 0.009410\n",
      "[4950] Loss: 0.009202\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "batch_size = 2110\n",
    "num_epochs = 5000\n",
    "learning_rate = 1e-3\n",
    "latent_dim = latent_tensor.shape[1]  # e.g., 50\n",
    "epochs_list = []\n",
    "loss_list = []\n",
    "\n",
    "vf_model = NeuralVectorField(latent_dim=latent_dim).to(device)\n",
    "optimizer = torch.optim.AdamW(vf_model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Initialize GaussianConditionalProbabilityPath and ConditionalVectorFieldODE\n",
    "path = GaussianConditionalProbabilityPath(emp_dist, alpha, beta)  # define alpha, beta\n",
    "cvf_ode = ConditionalVectorFieldODE(path, z=torch.zeros(1, latent_dim, device=device))\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # --- Sample conditioning variable z ---\n",
    "    z = emp_dist.sample(batch_size).to(device)\n",
    "\n",
    "    # --- Sample time ---\n",
    "    t = torch.rand(batch_size, 1, device=device)\n",
    "\n",
    "    # --- Sample x_t from conditional path ---\n",
    "    with torch.no_grad():\n",
    "        x = path.sample_conditional_path(z, t)\n",
    "        u_target = path.conditional_vector_field(x, z, t)\n",
    "\n",
    "    # --- Normalize target ---\n",
    "    u_mean = u_target.mean(dim=0, keepdim=True)\n",
    "    u_std = u_target.std(dim=0, keepdim=True) + 1e-6\n",
    "    u_target_norm = (u_target - u_mean) / u_std\n",
    "\n",
    "    # --- Forward pass ---\n",
    "    v_pred = vf_model(x, z, t)\n",
    "\n",
    "    # --- Loss ---\n",
    "    loss = F.mse_loss(v_pred, u_target_norm)\n",
    "\n",
    "    # --- Backprop ---\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    torch.nn.utils.clip_grad_norm_(vf_model.parameters(), max_norm=1.0)\n",
    "    optimizer.step()\n",
    "\n",
    "    # --- Save stats ---\n",
    "    epochs_list.append(epoch)\n",
    "    loss_list.append(float(loss))\n",
    "\n",
    "    if epoch % 50 == 0:\n",
    "        print(f\"[{epoch}] Loss: {loss.item():.6f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0379eb13-6e48-4e09-9699-b7a932bb9ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(epoch_list, loss_list)\n",
    "plt.title('Training of flow')\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Average loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "b46c5956-d23f-463a-8541-7e85d2e52888",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we want to save the best vector field:\n",
    "class LearnedVectorFieldODE():\n",
    "    def __init__(self, vf_model):\n",
    "        self.vf_model = vf_model\n",
    "\n",
    "    def drift_coefficient(self, x: torch.Tensor, t: torch.Tensor, z: torch.Tensor) -> torch.Tensor:\n",
    "        # x, z: (batch_size, latent_dim)\n",
    "        # t: (batch_size, 1)\n",
    "        return self.vf_model(x, z, t)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "2376f019-c84c-4f60-bc09-84ec341a1511",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrap the trained neural network\n",
    "learned_ode = LearnedVectorFieldODE(vf_model)\n",
    "\n",
    "# Save the wrapper\n",
    "torch.save(learned_ode, flow_model_save_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "d6f33abc-c1b8-410a-bc3c-8e047d42ce30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1000, 50])\n"
     ]
    }
   ],
   "source": [
    "# Number of samples and latent dimension\n",
    "n_samples = 1000\n",
    "latent_dim = latent_tensor.shape[1]\n",
    "\n",
    "# Starting points (noise)\n",
    "x = torch.randn(n_samples, latent_dim, device=device)\n",
    "\n",
    "# Conditioning variable z\n",
    "# Single vector, broadcast to all samples\n",
    "z = torch.zeros(1, latent_dim, device=device)  # or z = emp_dist.sample(1)\n",
    "\n",
    "# Wrap the trained neural network as an ODE\n",
    "learned_ode = LearnedVectorFieldODE(vf_model)\n",
    "\n",
    "# Create Euler simulator with the conditioning variable\n",
    "simulator = EulerSimulator(learned_ode, z)\n",
    "\n",
    "# Simulation parameters\n",
    "t0, t1 = 0.0, 1.0\n",
    "n_steps = 50\n",
    "dt = (t1 - t0) / n_steps\n",
    "\n",
    "# Store trajectory\n",
    "trajectory = [x.clone()]\n",
    "t = torch.full((n_samples, 1), t0, device=device)\n",
    "\n",
    "# Euler integration\n",
    "for _ in range(n_steps):\n",
    "    x = simulator.step(x, t, dt)\n",
    "    trajectory.append(x.clone())\n",
    "    t = t + dt\n",
    "\n",
    "# Final generated samples\n",
    "generated_cells = trajectory[-1]\n",
    "print(generated_cells.shape)  # (1000, latent_dim)\n",
    "torch.save(generated_cells, \"/dtu/blackhole/1e/213566/gen_data/pbmc3k/simple_generated_latent.pt\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
