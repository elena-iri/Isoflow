{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Flow Matching with Classifier-Free Guidance & Library Size Conditioning\n",
    "\n",
    "**Updates:**\n",
    "1. **Training:** Uses OT-Flow Matching (Gaussian Conditional Probability Path).\n",
    "2. **Conditioning:** Conditions on both **Cell Type** and **Library Size**.\n",
    "3. **Sampling:** Uses Euler ODE integration\n",
    "4. **Decoding:** Rescales latents and decodes to counts using Negative Binomial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import math\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import anndata as ad\n",
    "import scanpy as sc\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from typing import Optional, List, Tuple\n",
    "from scvi.distributions import NegativeBinomial\n",
    "\n",
    "# Imports for VAE (Ensure autoencoder_utils.py is in the same directory)\n",
    "try:\n",
    "    from autoencoder_utils import NB_Autoencoder\n",
    "except ImportError:\n",
    "    # Fallback if file not found, defining minimal class for loading\n",
    "    print(\"lol\")\n",
    "    class NB_Autoencoder(nn.Module):\n",
    "        def __init__(self, num_features, latent_dim=50, hidden_dims=[512, 256]):\n",
    "            super().__init__()\n",
    "            self.num_features = num_features\n",
    "            self.latent_dim = latent_dim\n",
    "            # ... (Architecture assumed match)\n",
    "            # Placeholder for loading state dict\n",
    "            self.encoder = nn.Sequential(nn.Linear(num_features, 512), nn.ReLU(), nn.Linear(512, 256), nn.ReLU())\n",
    "            self.mu = nn.Linear(256, latent_dim)\n",
    "            self.logvar = nn.Linear(256, latent_dim)\n",
    "            self.decoder = nn.Sequential(nn.Linear(latent_dim, 256), nn.ReLU(), nn.Linear(256, 512), nn.ReLU())\n",
    "            self.mu_dec = nn.Linear(512, num_features)\n",
    "            self.theta = nn.Parameter(torch.randn(num_features))\n",
    "        def decode(self, z, library_size):\n",
    "            h = self.decoder(z)\n",
    "            mu = torch.softmax(self.mu_dec(h), dim=1) * library_size\n",
    "            return {\"mu\": mu, \"theta\": self.theta}\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Configuration & Paths ----\n",
    "input_file_path = \"/dtu/blackhole/06/213542/paperdata/pbmc3k_train_with_latent.h5ad\"\n",
    "vae_model_path = \"/dtu/blackhole/06/213542/paperdata/pbmc3k_train_nb_autoencoder.pt\" # Path to trained VAE\n",
    "flow_model_save_path = \"/dtu/blackhole/06/213542/paperdata/lib_size_flow_model.pt\"\n",
    "\n",
    "os.makedirs(os.path.dirname(flow_model_save_path), exist_ok=True)\n",
    "\n",
    "# Hyperparameters\n",
    "batch_size = 256\n",
    "num_epochs = 4000\n",
    "learning_rate = 5e-4\n",
    "latent_dim = 50\n",
    "drop_prob = 0.1   # Classifier-free guidance dropout probability\n",
    "guidance_scale = 2.0\n",
    "n_steps = 50      # Euler integration steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Shape: (2110, 50)\n",
      "Library Size: Min=6.49, Max=7.86, Mean=7.42\n",
      "Cell Types: ['B cells' 'CD14+ Monocytes' 'CD4 T cells' 'CD8 T cells' 'Dendritic cells'\n",
      " 'FCGR3A+ Monocytes' 'Megakaryocytes' 'NK cells']\n"
     ]
    }
   ],
   "source": [
    "# ---- Load Data ----\n",
    "adata = ad.read_h5ad(input_file_path)\n",
    "latent = adata.obsm[\"X_latent\"]\n",
    "latent_tensor = torch.tensor(latent, dtype=torch.float32, device=device)\n",
    "\n",
    "# Library Sizes\n",
    "if \"total_counts\" in adata.obs:\n",
    "    lib_sizes = adata.obs[\"total_counts\"].values\n",
    "else:\n",
    "    lib_sizes = np.array(adata.X.sum(1)).flatten()\n",
    "\n",
    "log_lib_sizes = np.log1p(lib_sizes)\n",
    "log_lib_tensor = torch.tensor(log_lib_sizes, dtype=torch.float32, device=device).unsqueeze(1)\n",
    "\n",
    "# Stats for normalization and sampling\n",
    "lib_min, lib_max = log_lib_tensor.min(), log_lib_tensor.max()\n",
    "lib_mean, lib_std = log_lib_tensor.mean(), log_lib_tensor.std()\n",
    "\n",
    "# Cell Types\n",
    "cell_types = adata.obs[\"cell_type\"].astype(str).values\n",
    "unique_types, inverse_idx = np.unique(cell_types, return_inverse=True)\n",
    "num_cell_types = len(unique_types)\n",
    "cell_type_idx = torch.tensor(inverse_idx, dtype=torch.long, device=device)\n",
    "\n",
    "print(f\"Data Shape: {latent.shape}\")\n",
    "print(f\"Library Size: Min={lib_min:.2f}, Max={lib_max:.2f}, Mean={lib_mean:.2f}\")\n",
    "print(f\"Cell Types: {unique_types}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Flow Matching Classes (OT Path) ----\n",
    "\n",
    "class EmpiricalDistribution(nn.Module):\n",
    "    def __init__(self, data):\n",
    "        super().__init__()\n",
    "        self.register_buffer(\"data\", data)\n",
    "    def sample(self, n):\n",
    "        idx = torch.randint(0, len(self.data), (n,), device=self.data.device)\n",
    "        return self.data[idx]\n",
    "\n",
    "class GaussianConditionalProbabilityPath:\n",
    "    def __init__(self, p_data):\n",
    "        self.p_data = p_data\n",
    "    def sample_conditional_path(self, z, t):\n",
    "        # Linear interpolation: t * z + (1-t) * noise\n",
    "        # Note: Train_flow_cfg typically uses x1 (data) and x0 (noise)\n",
    "        # Here we adapt to match the provided notebook logic:\n",
    "        # Target is usually data, Source is noise.\n",
    "        # path: x_t = t * x_1 + (1 - t) * x_0\n",
    "        # vector field u_t = x_1 - x_0\n",
    "        return t * z + (1 - t) * torch.randn_like(z)\n",
    "\n",
    "    def conditional_vector_field(self, x_1, x_0):\n",
    "        return x_1 - x_0\n",
    "\n",
    "# ---- Neural Network (With Library Size) ----\n",
    "\n",
    "class TimeEmbedder(nn.Module):\n",
    "    def __init__(self, embed_dim=32):\n",
    "        super().__init__()\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(embed_dim, embed_dim), nn.SiLU(),\n",
    "            nn.Linear(embed_dim, embed_dim), nn.SiLU()\n",
    "        )\n",
    "        self.embed_dim = embed_dim\n",
    "    def forward(self, t):\n",
    "        # Sinusoidal embedding\n",
    "        half_dim = self.embed_dim // 2\n",
    "        emb = math.log(10000) / (half_dim - 1)\n",
    "        emb = torch.exp(torch.arange(half_dim, device=t.device) * -emb)\n",
    "        emb = t * emb[None, :]\n",
    "        emb = torch.cat((torch.sin(emb), torch.cos(emb)), dim=1)\n",
    "        return self.mlp(emb)\n",
    "\n",
    "class NeuralVectorField(nn.Module):\n",
    "    def __init__(self, latent_dim, hidden_dim=256, time_embed_dim=64, lib_min=0, lib_max=10):\n",
    "        super().__init__()\n",
    "        self.x_proj = nn.Linear(latent_dim, hidden_dim)\n",
    "        self.z_proj = nn.Linear(latent_dim, hidden_dim) # Type conditioning\n",
    "        self.time_embedder = TimeEmbedder(time_embed_dim)\n",
    "        \n",
    "        # Library size embedding\n",
    "        self.lib_min = lib_min\n",
    "        self.lib_max = lib_max\n",
    "        self.l_proj = nn.Sequential(\n",
    "            nn.Linear(time_embed_dim, hidden_dim),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim)\n",
    "        )\n",
    "\n",
    "        in_dim = hidden_dim * 3 + time_embed_dim\n",
    "        self. net = nn.Sequential(\n",
    "            nn.Linear(in_dim, hidden_dim), nn.SiLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim), nn.SiLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim), nn.SiLU(),\n",
    "            nn.Linear(hidden_dim, latent_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x, z, t, l):\n",
    "        # x: current state, z: type condition, t: time, l: library size\n",
    "        hx = self.x_proj(x)\n",
    "        hz = self.z_proj(z)\n",
    "        ht = self.time_embedder(t)\n",
    "        \n",
    "        # Library embedding (normalize first)\n",
    "        l_norm = (l - self.lib_min) / (self.lib_max - self.lib_min)\n",
    "        # Re-use time embedder logic for continuous scalar l\n",
    "        hl_emb = self.time_embedder.forward(l_norm) \n",
    "        hl = self.l_proj(hl_emb)\n",
    "\n",
    "        h = torch.cat([hx, hz, ht, hl], dim=-1)\n",
    "        return self.net(h)\n",
    "\n",
    "class CellTypeConditioner(nn.Module):\n",
    "    def __init__(self, n_types, latent_dim):\n",
    "        super().__init__()\n",
    "        self.embed = nn.Embedding(n_types, latent_dim)\n",
    "    def forward(self, idx):\n",
    "        return self.embed(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Initialize Models ----\n",
    "vf_model = NeuralVectorField(latent_dim, lib_min=lib_min, lib_max=lib_max).to(device)\n",
    "conditioner = CellTypeConditioner(num_cell_types, latent_dim).to(device)\n",
    "\n",
    "optimizer = torch.optim.AdamW(list(vf_model.parameters()) + list(conditioner.parameters()), lr=learning_rate)\n",
    "\n",
    "emp_dist = EmpiricalDistribution(latent_tensor)\n",
    "path = GaussianConditionalProbabilityPath(emp_dist)\n",
    "\n",
    "# Null token for classifier-free guidance\n",
    "z_null = torch.zeros(1, latent_dim, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 4000/4000 [01:01<00:00, 65.54it/s]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ---- Training Loop (Flow Matching) ----\n",
    "loss_history = []\n",
    "\n",
    "vf_model.train()\n",
    "conditioner.train()\n",
    "\n",
    "for epoch in tqdm(range(num_epochs), desc=\"Training\"):\n",
    "    # 1. Sample Batch\n",
    "    idx = torch.randint(0, len(latent_tensor), (batch_size,), device=device)\n",
    "    x_1 = latent_tensor[idx] # Target data\n",
    "    x_0 = torch.randn_like(x_1) # Source noise\n",
    "    \n",
    "    # Conditions\n",
    "    batch_types = cell_type_idx[idx]\n",
    "    batch_libs = log_lib_tensor[idx]\n",
    "\n",
    "    # 2. Sample Time\n",
    "    t = torch.rand(batch_size, 1, device=device)\n",
    "\n",
    "    # 3. Compute Path (Interpolation)\n",
    "    # x_t = t * x_1 + (1-t) * x_0\n",
    "    x_t = t * x_1 + (1 - t) * x_0\n",
    "    \n",
    "    # 4. Compute Target Vector Field\n",
    "    # u_t = x_1 - x_0\n",
    "    u_target = x_1 - x_0\n",
    "\n",
    "    # 5. Conditioning w/ Drop (CFG)\n",
    "    z_emb = conditioner(batch_types)\n",
    "    drop_mask = (torch.rand(batch_size, 1, device=device) < drop_prob)\n",
    "    z_used = torch.where(drop_mask, z_null, z_emb)\n",
    "\n",
    "    # 6. Prediction\n",
    "    v_pred = vf_model(x_t, z_used, t, batch_libs)\n",
    "\n",
    "    # 7. Loss\n",
    "    loss = F.mse_loss(v_pred, u_target)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    loss_history.append(loss.item())\n",
    "\n",
    "plt.plot(loss_history)\n",
    "plt.title(\"Flow Matching Loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved models to /dtu/blackhole/06/213542/paperdata/lib_size_flow_model.pt\n"
     ]
    }
   ],
   "source": [
    "# ---- Save Models ----\n",
    "torch.save({\n",
    "    'vf_state': vf_model.state_dict(),\n",
    "    'cond_state': conditioner.state_dict()\n",
    "}, flow_model_save_path)\n",
    "print(f\"Saved models to {flow_model_save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VAE loaded successfully.\n",
      "Sampling 200 cells (Type 2)...\n",
      "Decoding to counts...\n",
      "Final Generated Counts Shape: (200, 8573)\n"
     ]
    }
   ],
   "source": [
    "# ==================================================================================\n",
    "# SAMPLING AND DECODING \n",
    "# ==================================================================================\n",
    "\n",
    "# 1. Load VAE for Decoding\n",
    "# We need the VAE to map latents -> gene counts\n",
    "vae = NB_Autoencoder(num_features=adata.n_vars, latent_dim=latent_dim)\n",
    "try:\n",
    "    vae.load_state_dict(torch.load(vae_model_path, map_location=device))\n",
    "    vae.to(device)\n",
    "    vae.eval()\n",
    "    print(\"VAE loaded successfully.\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"Warning: VAE model not found at {vae_model_path}. Decoding will fail.\")\n",
    "\n",
    "# 2. Euler Integration Simulator \n",
    "class LearnedVectorFieldODE:\n",
    "    def __init__(self, vf_model, conditioner, z_target, l_target, guidance_scale=2.0):\n",
    "        self.vf = vf_model\n",
    "        self.z = conditioner(z_target)\n",
    "        self.l = l_target\n",
    "        self.scale = guidance_scale\n",
    "        self.z_null = torch.zeros_like(self.z)\n",
    "    \n",
    "    def drift(self, x, t):\n",
    "        # Duplicate inputs for Cond and Uncond pass\n",
    "        x_in = torch.cat([x, x], dim=0)\n",
    "        t_in = torch.cat([t, t], dim=0)\n",
    "        l_in = torch.cat([self.l, self.l], dim=0)\n",
    "        z_in = torch.cat([self.z, self.z_null], dim=0)\n",
    "        \n",
    "        v_out = self.vf(x_in, z_in, t_in, l_in)\n",
    "        v_cond, v_uncond = v_out.chunk(2, dim=0)\n",
    "        \n",
    "        # CFG Formula: v = v_uncond + s * (v_cond - v_uncond)\n",
    "        return v_uncond + self.scale * (v_cond - v_uncond)\n",
    "\n",
    "def generate_samples(target_type_idx, num_samples, fix_library_size=True):\n",
    "    vf_model.eval()\n",
    "    conditioner.eval()\n",
    "    \n",
    "    # A. Setup Latents\n",
    "    #x = torch.randn(num_samples, latent_dim, device=device) # Noise x0\n",
    "    x = torch.rand(num_samples, latent_dim, device=device)\n",
    "    # B. Setup Conditions\n",
    "    # 1. Cell Typ\n",
    "\n",
    "    type_tensor = torch.full((num_samples,), target_type_idx, dtype=torch.long, device=device)\n",
    "\n",
    "    # 2. Library Size\n",
    "    # We can either sample from the empirical distribution or fix it for evaluation\n",
    "    if fix_library_size:\n",
    "        # Fix to mean for cleaner evaluation\n",
    "        l_val = lib_mean.item()\n",
    "        l_tensor = torch.full((num_samples, 1), l_val, device=device)\n",
    "    else:\n",
    "        # Sample from normal approx of log-libs\n",
    "        l_tensor = torch.normal(lib_mean.item(), lib_std.item(), (num_samples, 1), device=device)\n",
    "\n",
    "    # C. ODE Integration (Euler)\n",
    "    \n",
    "\n",
    "    ode = LearnedVectorFieldODE(vf_model, conditioner, type_tensor, l_tensor, guidance_scale)\n",
    "    dt = 1.0 / n_steps\n",
    "    t = torch.zeros(num_samples, 1, device=device)\n",
    "    \n",
    "    print(f\"Sampling {num_samples} cells (Type {target_type_idx})...\")\n",
    "    with torch.no_grad():\n",
    "        for _ in range(n_steps):\n",
    "            v = ode.drift(x, t)\n",
    "            x = x + v * dt\n",
    "            t = t + dt\n",
    "            \n",
    "    return x\n",
    "\n",
    "\"\"\"['B cells' 'CD14+ Monocytes' 'CD4 T cells' 'CD8 T cells' 'Dendritic cells'\n",
    " 'FCGR3A+ Monocytes' 'Megakaryocytes' 'NK cells']\"\"\"\n",
    "\n",
    "target_idx = 2\n",
    "n_gen = 200\n",
    "generated_latents = generate_samples(target_idx, n_gen)\n",
    "\n",
    "# 4. Rescaling\n",
    "# \"generated_rescaled = (generated_tensor - generated_tensor.mean(dim=0)) / std_gen * std_orig + latent_tensor.mean(dim=0)\"\n",
    "std_orig = latent_tensor.std(dim=0)\n",
    "mean_orig = latent_tensor.mean(dim=0)\n",
    "std_gen = generated_latents.std(dim=0)\n",
    "mean_gen = generated_latents.mean(dim=0)\n",
    "\n",
    "generated_rescaled = (generated_latents - mean_gen) / std_gen * std_orig + mean_orig\n",
    "\n",
    "# 5. Decoding with Fixed Library Size\n",
    "target_lib_size = 1000 \n",
    "\n",
    "print(\"Decoding to counts...\")\n",
    "with torch.no_grad():\n",
    "    outputs = vae.decode(generated_rescaled, target_lib_size)\n",
    "    mu = outputs[\"mu\"]\n",
    "    theta = torch.exp(outputs[\"theta\"])\n",
    "    \n",
    "    # Sample from Negative Binomial\n",
    "    nb_dist = NegativeBinomial(mu=mu, theta=theta)\n",
    "    X_gen_counts = nb_dist.sample().cpu().numpy()\n",
    "\n",
    "print(f\"Final Generated Counts Shape: {X_gen_counts.shape}\")\n",
    "\n",
    "\n",
    "\n",
    "# Optional: Save or Plot\n",
    "# sc.AnnData(X=X_gen_counts).write(...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2243fbcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved generated counts to: /dtu/blackhole/06/213542/paperdata/new_generated_pbmc3k_counts.h5ad\n"
     ]
    }
   ],
   "source": [
    "import anndata as ad\n",
    "import os\n",
    "\n",
    "# Paths\n",
    "save_dir = \"/dtu/blackhole/06/213542/paperdata/\"\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "counts_save_path = os.path.join(save_dir, \"new_generated_pbmc3k_counts.h5ad\")\n",
    "latents_save_path = os.path.join(save_dir, \"new_generated_pbmc3k_latents.pt\")\n",
    "\n",
    "# --- 1. Save Final Counts (for Scanpy/Evaluation) ---\n",
    "# Create AnnData from the generated counts\n",
    "adata_gen = ad.AnnData(X=X_gen_counts)\n",
    "\n",
    "# Transfer gene names from the original data (if available)\n",
    "if 'adata' in globals():\n",
    "    adata_gen.var_names = adata.var_names\n",
    "\n",
    "# Add metadata (e.g., which cell type was generated)\n",
    "# Assuming 'target_type_idx' and 'unique_types' exist from previous cells\n",
    "if 'unique_types' in globals() and 'target_type_idx' in globals():\n",
    "    cell_type_name = unique_types[target_type_idx]\n",
    "    adata_gen.obs['cell_type'] = cell_type_name\n",
    "    \n",
    "adata_gen.write(counts_save_path)\n",
    "print(f\"Saved generated counts to: {counts_save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3ca4bec9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating 100 cells for each of 8 cell types...\n",
      "Sampling 100 cells (Type 0)...\n",
      "Sampling 100 cells (Type 1)...\n",
      "Sampling 100 cells (Type 2)...\n",
      "Sampling 100 cells (Type 3)...\n",
      "Sampling 100 cells (Type 4)...\n",
      "Sampling 100 cells (Type 5)...\n",
      "Sampling 100 cells (Type 6)...\n",
      "Sampling 100 cells (Type 7)...\n",
      "Saving evaluation data to: /dtu/blackhole/06/213542/paperdata/eval_data_latents.h5ad\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "# ==================================================================================\n",
    "# GENERATE AND SAVE EVALUATION DATA (H5AD)\n",
    "# ==================================================================================\n",
    "\n",
    "import scanpy as sc\n",
    "import anndata as ad\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# 1. GENERATE SYNTHETIC DATA (Balanced across all types)\n",
    "# ------------------------------------------------------------------\n",
    "n_per_type = 100  # Number of cells to generate per type\n",
    "generated_list = []\n",
    "gen_labels_list = []\n",
    "\n",
    "print(f\"Generating {n_per_type} cells for each of {num_cell_types} cell types...\")\n",
    "\n",
    "for type_idx in range(num_cell_types):\n",
    "    # Generate batch for this specific type\n",
    "    # Fix library size to mean for cleaner evaluation\n",
    "    batch = generate_samples(target_type_idx=type_idx, num_samples=n_per_type, fix_library_size=True)\n",
    "    \n",
    "    generated_list.append(batch)\n",
    "    \n",
    "    # Store the label name (e.g., 'B cells')\n",
    "    type_name = unique_types[type_idx]\n",
    "    gen_labels_list.extend([type_name] * n_per_type)\n",
    "\n",
    "# Concatenate all generated batches (Latent Space)\n",
    "X_gen = torch.cat(generated_list, dim=0).cpu().numpy()\n",
    "labels_gen = np.array(gen_labels_list)\n",
    "\n",
    "# 2. PREPARE REAL DATA (Reference)\n",
    "# ------------------------------------------------------------------\n",
    "# Use the latent_tensor loaded at the start of the notebook\n",
    "X_real = latent_tensor.cpu().numpy()\n",
    "labels_real = cell_types  # The original string labels\n",
    "\n",
    "# Optional: Subsample real data to match generated size if it's too large\n",
    "if len(X_real) > len(X_gen):\n",
    "    idx_sub = np.random.choice(len(X_real), len(X_gen), replace=False)\n",
    "    X_real = X_real[idx_sub]\n",
    "    labels_real = labels_real[idx_sub]\n",
    "\n",
    "# 3. COMBINE INTO ANNDATA\n",
    "# ------------------------------------------------------------------\n",
    "# Stack features\n",
    "X_combined = np.concatenate([X_real, X_gen], axis=0)\n",
    "\n",
    "# Create metadata arrays\n",
    "condition_labels = (['Real'] * len(X_real)) + (['Generated'] * len(X_gen))\n",
    "type_labels_combined = np.concatenate([labels_real, labels_gen], axis=0)\n",
    "\n",
    "# Create AnnData object\n",
    "adata_eval = ad.AnnData(X=X_combined)\n",
    "adata_eval.obs['Condition'] = condition_labels\n",
    "adata_eval.obs['Cell_Type'] = type_labels_combined\n",
    "\n",
    "# 4. SAVE TO H5AD\n",
    "# ------------------------------------------------------------------\n",
    "# Save in the same directory as the input file\n",
    "save_dir = os.path.dirname(input_file_path)\n",
    "save_path = os.path.join(save_dir, \"eval_data_latents.h5ad\")\n",
    "\n",
    "print(f\"Saving evaluation data to: {save_path}\")\n",
    "adata_eval.write_h5ad(save_path)\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "938a9257",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating 50 cells for each of 8 cell types...\n",
      "Sampling 50 cells (Type 0)...\n",
      "Sampling 50 cells (Type 1)...\n",
      "Sampling 50 cells (Type 2)...\n",
      "Sampling 50 cells (Type 3)...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 20\u001b[39m\n\u001b[32m     15\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mGenerating \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_per_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m cells for each of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_cell_types\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m cell types...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     17\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m type_idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_cell_types):\n\u001b[32m     18\u001b[39m     \u001b[38;5;66;03m# Generate batch for this specific type\u001b[39;00m\n\u001b[32m     19\u001b[39m     \u001b[38;5;66;03m# Note: We fix library size to mean for cleaner evaluation, or set fix_library_size=False for more variance\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m20\u001b[39m     batch = \u001b[43mgenerate_samples\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtarget_type_idx\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtype_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_samples\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_per_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfix_library_size\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     22\u001b[39m     generated_list.append(batch)\n\u001b[32m     24\u001b[39m     \u001b[38;5;66;03m# Store the label name (e.g., 'B cells') for plotting\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 70\u001b[39m, in \u001b[36mgenerate_samples\u001b[39m\u001b[34m(target_type_idx, num_samples, fix_library_size)\u001b[39m\n\u001b[32m     68\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n\u001b[32m     69\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_steps):\n\u001b[32m---> \u001b[39m\u001b[32m70\u001b[39m         v = \u001b[43mode\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdrift\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     71\u001b[39m         x = x + v * dt\n\u001b[32m     72\u001b[39m         t = t + dt\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 32\u001b[39m, in \u001b[36mLearnedVectorFieldODE.drift\u001b[39m\u001b[34m(self, x, t)\u001b[39m\n\u001b[32m     29\u001b[39m l_in = torch.cat([\u001b[38;5;28mself\u001b[39m.l, \u001b[38;5;28mself\u001b[39m.l], dim=\u001b[32m0\u001b[39m)\n\u001b[32m     30\u001b[39m z_in = torch.cat([\u001b[38;5;28mself\u001b[39m.z, \u001b[38;5;28mself\u001b[39m.z_null], dim=\u001b[32m0\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m32\u001b[39m v_out = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mvf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_in\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mz_in\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt_in\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ml_in\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     33\u001b[39m v_cond, v_uncond = v_out.chunk(\u001b[32m2\u001b[39m, dim=\u001b[32m0\u001b[39m)\n\u001b[32m     35\u001b[39m \u001b[38;5;66;03m# CFG Formula: v = v_uncond + s * (v_cond - v_uncond)\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/venv_1/lib/python3.11/site-packages/torch/nn/modules/module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/venv_1/lib/python3.11/site-packages/torch/nn/modules/module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 73\u001b[39m, in \u001b[36mNeuralVectorField.forward\u001b[39m\u001b[34m(self, x, z, t, l)\u001b[39m\n\u001b[32m     71\u001b[39m hx = \u001b[38;5;28mself\u001b[39m.x_proj(x)\n\u001b[32m     72\u001b[39m hz = \u001b[38;5;28mself\u001b[39m.z_proj(z)\n\u001b[32m---> \u001b[39m\u001b[32m73\u001b[39m ht = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtime_embedder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     75\u001b[39m \u001b[38;5;66;03m# Library embedding (normalize first)\u001b[39;00m\n\u001b[32m     76\u001b[39m l_norm = (l - \u001b[38;5;28mself\u001b[39m.lib_min) / (\u001b[38;5;28mself\u001b[39m.lib_max - \u001b[38;5;28mself\u001b[39m.lib_min)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/venv_1/lib/python3.11/site-packages/torch/nn/modules/module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/venv_1/lib/python3.11/site-packages/torch/nn/modules/module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 43\u001b[39m, in \u001b[36mTimeEmbedder.forward\u001b[39m\u001b[34m(self, t)\u001b[39m\n\u001b[32m     41\u001b[39m emb = t * emb[\u001b[38;5;28;01mNone\u001b[39;00m, :]\n\u001b[32m     42\u001b[39m emb = torch.cat((torch.sin(emb), torch.cos(emb)), dim=\u001b[32m1\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m43\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmlp\u001b[49m\u001b[43m(\u001b[49m\u001b[43memb\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/venv_1/lib/python3.11/site-packages/torch/nn/modules/module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/venv_1/lib/python3.11/site-packages/torch/nn/modules/module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/venv_1/lib/python3.11/site-packages/torch/nn/modules/container.py:250\u001b[39m, in \u001b[36mSequential.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    246\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    247\u001b[39m \u001b[33;03mRuns the forward pass.\u001b[39;00m\n\u001b[32m    248\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    249\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m250\u001b[39m     \u001b[38;5;28minput\u001b[39m = \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    251\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/venv_1/lib/python3.11/site-packages/torch/nn/modules/module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/venv_1/lib/python3.11/site-packages/torch/nn/modules/module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/venv_1/lib/python3.11/site-packages/torch/nn/modules/linear.py:134\u001b[39m, in \u001b[36mLinear.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    130\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) -> Tensor:\n\u001b[32m    131\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    132\u001b[39m \u001b[33;03m    Runs the forward pass.\u001b[39;00m\n\u001b[32m    133\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m134\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# ==================================================================================\n",
    "# UMAP EVALUATION: REAL (TEST) vs GENERATED\n",
    "# ==================================================================================\n",
    "\n",
    "import scanpy as sc\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 1. GENERATE SYNTHETIC DATA (Balanced across all types)\n",
    "# ------------------------------------------------------------------\n",
    "n_per_type = 100  # Number of cells to generate per type\n",
    "generated_list = []\n",
    "gen_labels_list = []\n",
    "\n",
    "print(f\"Generating {n_per_type} cells for each of {num_cell_types} cell types...\")\n",
    "\n",
    "for type_idx in range(num_cell_types):\n",
    "    # Generate batch for this specific type\n",
    "    # Note: We fix library size to mean for cleaner evaluation, or set fix_library_size=False for more variance\n",
    "    batch = generate_samples(target_type_idx=type_idx, num_samples=n_per_type, fix_library_size=True)\n",
    "    \n",
    "    generated_list.append(batch)\n",
    "    \n",
    "    # Store the label name (e.g., 'B cells') for plotting\n",
    "    type_name = unique_types[type_idx]\n",
    "    gen_labels_list.extend([type_name] * n_per_type)\n",
    "\n",
    "# Concatenate all generated batches\n",
    "X_gen = torch.cat(generated_list, dim=0).cpu().numpy()\n",
    "labels_gen = np.array(gen_labels_list)\n",
    "\n",
    "# 2. PREPARE REAL DATA (Reference)\n",
    "# ------------------------------------------------------------------\n",
    "# We simply move the GPU tensor to CPU numpy\n",
    "# You can also sample a subset if the dataset is too huge\n",
    "X_real = latent_tensor.cpu().numpy()\n",
    "labels_real = cell_types  # The original string labels loaded earlier\n",
    "\n",
    "# Optionally subsample real data to match generated size if needed\n",
    "if len(X_real) > len(X_gen):\n",
    "    idx_sub = np.random.choice(len(X_real), len(X_gen), replace=False)\n",
    "    X_real = X_real[idx_sub]\n",
    "    labels_real = labels_real[idx_sub]\n",
    "\n",
    "# 3. COMBINE INTO ANNDATA FOR UMAP\n",
    "# ------------------------------------------------------------------\n",
    "# Stack features\n",
    "X_combined = np.concatenate([X_real, X_gen], axis=0)\n",
    "\n",
    "# Create \"Condition\" labels (Real vs Generated)\n",
    "condition_labels = (['Real'] * len(X_real)) + (['Generated'] * len(X_gen))\n",
    "\n",
    "# Create \"Cell Type\" labels\n",
    "type_labels_combined = np.concatenate([labels_real, labels_gen], axis=0)\n",
    "\n",
    "# Create AnnData object\n",
    "adata_eval = ad.AnnData(X=X_combined)\n",
    "adata_eval.obs['Condition'] = condition_labels\n",
    "adata_eval.obs['Cell Type'] = type_labels_combined\n",
    "\n",
    "# 4. COMPUTE UMAP\n",
    "# ------------------------------------------------------------------\n",
    "print(\"Computing Neighbors and UMAP...\")\n",
    "sc.pp.neighbors(adata_eval, use_rep='X')\n",
    "sc.tl.umap(adata_eval)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0885dee0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
