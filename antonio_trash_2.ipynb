{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d3c8a9c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Could not find generated_latent.pt. Please ensure you save the 'generated_full' tensor in the training script.\n"
     ]
    }
   ],
   "source": [
    "import scanpy as sc\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "import umap\n",
    "\n",
    "# --- 1. Load Data ---\n",
    "# We compare against the TRAINING latents (because that's what the flow learned)\n",
    "# Update this path to where your training data with latents is stored\n",
    "TRAIN_DATA_PATH = \"/dtu/blackhole/06/213542/paperdata/pbmc3k_train_with_latent.h5ad\"\n",
    "GEN_LATENT_PATH = \"/dtu/blackhole/06/213542/paperdata/simple_generated_latent.pt\" # Note: Load the latent, not counts!\n",
    "\n",
    "print(\"Loading data...\")\n",
    "adata_train = sc.read_h5ad(TRAIN_DATA_PATH)\n",
    "real_latents = adata_train.obsm[\"X_latent\"]\n",
    "\n",
    "# Load Generated Latents\n",
    "# (We need the output of the Flow model, before decoding)\n",
    "# If you haven't saved the intermediate latents in the new loop, you might need to grab them from the 'generated_full' tensor in the training notebook\n",
    "# For now, let's assume you saved it or can access the variable 'generated_full' directly if running in the same session.\n",
    "if 'generated_full' in locals():\n",
    "    gen_latents = generated_full.cpu().numpy()\n",
    "else:\n",
    "    # If you saved it to a file in the previous step, load it here:\n",
    "    # You might need to update your training script to save 'generated_latent.pt' *after* the loop.\n",
    "    try:\n",
    "        gen_latents = torch.load(GEN_LATENT_PATH, map_location='cpu').numpy()\n",
    "    except:\n",
    "        print(\"Could not find generated_latent.pt. Please ensure you save the 'generated_full' tensor in the training script.\")\n",
    "        # Stop here if we can't find data\n",
    "        gen_latents = None\n",
    "\n",
    "if gen_latents is not None:\n",
    "    print(f\"Real Latents: {real_latents.shape}\")\n",
    "    print(f\"Gen Latents:  {gen_latents.shape}\")\n",
    "\n",
    "    # --- 2. Run UMAP on Latents ---\n",
    "    print(\"Running UMAP on Latent Space...\")\n",
    "    reducer = umap.UMAP()\n",
    "    \n",
    "    # Combine for joint reduction\n",
    "    combined = np.vstack([real_latents, gen_latents])\n",
    "    labels = np.array([\"Real\"] * len(real_latents) + [\"Generated\"] * len(gen_latents))\n",
    "    \n",
    "    embedding = reducer.fit_transform(combined)\n",
    "\n",
    "    # --- 3. Plot ---\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    # Plot Real (Blue)\n",
    "    mask_real = labels == \"Real\"\n",
    "    plt.scatter(embedding[mask_real, 0], embedding[mask_real, 1], \n",
    "                c='tab:blue', s=10, alpha=0.3, label='Real (Train)')\n",
    "    \n",
    "    # Plot Generated (Orange)\n",
    "    mask_gen = labels == \"Generated\"\n",
    "    plt.scatter(embedding[mask_gen, 0], embedding[mask_gen, 1], \n",
    "                c='tab:orange', s=10, alpha=0.5, label='Generated')\n",
    "    \n",
    "    plt.legend()\n",
    "    plt.title(\"Latent Space Comparison (Flow Output)\")\n",
    "    plt.xlabel(\"UMAP 1\")\n",
    "    plt.ylabel(\"UMAP 2\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "006e2c01",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
