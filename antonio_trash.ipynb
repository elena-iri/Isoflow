{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db712383",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scanpy as sc\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# --- 1. Load Data ---\n",
    "# Real Data\n",
    "real_path = \"/dtu/blackhole/06/213542/paperdata/pbmc3k_test.h5ad\"\n",
    "adata_real = sc.read_h5ad(real_path)\n",
    "\n",
    "# Generated Data\n",
    "gen_path = \"/dtu/blackhole/06/213542/paperdata/final_generated_counts.pt\"\n",
    "X_gen_tensor = torch.load(gen_path, map_location='cpu')\n",
    "X_gen = X_gen_tensor.numpy()\n",
    "\n",
    "# --- 2. Calculate Library Sizes (Total Counts per Cell) ---\n",
    "# Real\n",
    "if hasattr(adata_real.X, \"toarray\"):\n",
    "    real_counts = adata_real.X.toarray()\n",
    "else:\n",
    "    real_counts = adata_real.X\n",
    "lib_size_real = real_counts.sum(axis=1).flatten()\n",
    "\n",
    "# Generated\n",
    "lib_size_gen = X_gen.sum(axis=1).flatten()\n",
    "\n",
    "# --- 3. Print Statistics ---\n",
    "print(f\"{'Metric':<15} | {'Real Data':<15} | {'Generated Data':<15}\")\n",
    "print(\"-\" * 50)\n",
    "print(f\"{'Mean':<15} | {lib_size_real.mean():<15.2f} | {lib_size_gen.mean():<15.2f}\")\n",
    "print(f\"{'Median':<15} | {np.median(lib_size_real):<15.2f} | {np.median(lib_size_gen):<15.2f}\")\n",
    "print(f\"{'Std Dev':<15} | {lib_size_real.std():<15.2f} | {lib_size_gen.std():<15.2f}\")\n",
    "print(f\"{'Min':<15} | {lib_size_real.min():<15.2f} | {lib_size_gen.min():<15.2f}\")\n",
    "print(f\"{'Max':<15} | {lib_size_real.max():<15.2f} | {lib_size_gen.max():<15.2f}\")\n",
    "\n",
    "# --- 4. Visualize Distributions ---\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.hist(lib_size_real, bins=50, alpha=0.5, label='Real', density=True, color='blue')\n",
    "plt.hist(lib_size_gen, bins=50, alpha=0.5, label='Generated', density=True, color='orange')\n",
    "plt.title(\"Comparison of Library Size Distributions\")\n",
    "plt.xlabel(\"Total Counts per Cell\")\n",
    "plt.ylabel(\"Density\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77bcecac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scanpy as sc\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "import umap\n",
    "\n",
    "# --- 1. Load Data ---\n",
    "# We compare against the TRAINING latents (because that's what the flow learned)\n",
    "# Update this path to where your training data with latents is stored\n",
    "TRAIN_DATA_PATH = \"/dtu/blackhole/06/213542/paperdata/pbmc3k_train_with_latent.h5ad\"\n",
    "GEN_LATENT_PATH =  \"/dtu/blackhole/06/213542/paperdata/simple_generated_latent.pt \"# Note: Load the latent, not counts!\n",
    "\n",
    "print(\"Loading data...\")\n",
    "adata_train = sc.read_h5ad(TRAIN_DATA_PATH)\n",
    "real_latents = adata_train.obsm[\"X_latent\"]\n",
    "\n",
    "# Load Generated Latents\n",
    "# (We need the output of the Flow model, before decoding)\n",
    "# If you haven't saved the intermediate latents in the new loop, you might need to grab them from the 'generated_full' tensor in the training notebook\n",
    "# For now, let's assume you saved it or can access the variable 'generated_full' directly if running in the same session.\n",
    "if 'generated_full' in locals():\n",
    "    gen_latents = generated_full.cpu().numpy()\n",
    "else:\n",
    "    # If you saved it to a file in the previous step, load it here:\n",
    "    # You might need to update your training script to save 'generated_latent.pt' *after* the loop.\n",
    "    try:\n",
    "        gen_latents = torch.load(GEN_LATENT_PATH, map_location='cpu').numpy()\n",
    "    except:\n",
    "        print(\"Could not find generated_latent.pt. Please ensure you save the 'generated_full' tensor in the training script.\")\n",
    "        # Stop here if we can't find data\n",
    "        gen_latents = None\n",
    "\n",
    "if gen_latents is not None:\n",
    "    print(f\"Real Latents: {real_latents.shape}\")\n",
    "    print(f\"Gen Latents:  {gen_latents.shape}\")\n",
    "\n",
    "    # --- 2. Run UMAP on Latents ---\n",
    "    print(\"Running UMAP on Latent Space...\")\n",
    "    reducer = umap.UMAP()\n",
    "    \n",
    "    # Combine for joint reduction\n",
    "    combined = np.vstack([real_latents, gen_latents])\n",
    "    labels = np.array([\"Real\"] * len(real_latents) + [\"Generated\"] * len(gen_latents))\n",
    "    \n",
    "    embedding = reducer.fit_transform(combined)\n",
    "\n",
    "    # --- 3. Plot ---\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    # Plot Real (Blue)\n",
    "    mask_real = labels == \"Real\"\n",
    "    plt.scatter(embedding[mask_real, 0], embedding[mask_real, 1], \n",
    "                c='tab:blue', s=10, alpha=0.3, label='Real (Train)')\n",
    "    \n",
    "    # Plot Generated (Orange)\n",
    "    mask_gen = labels == \"Generated\"\n",
    "    plt.scatter(embedding[mask_gen, 0], embedding[mask_gen, 1], \n",
    "                c='tab:orange', s=10, alpha=0.5, label='Generated')\n",
    "    \n",
    "    plt.legend()\n",
    "    plt.title(\"Latent Space Comparison (Flow Output)\")\n",
    "    plt.xlabel(\"UMAP 1\")\n",
    "    plt.ylabel(\"UMAP 2\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da6634d4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pai-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
