{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1207d54f-991f-42c1-8874-175aafd89f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this the cleaner version of the flow matching model\n",
    "# import all packages and data\n",
    "# the data comes from the encoder in 50 dimensional format\n",
    "from abc import ABC, abstractmethod\n",
    "from typing import Optional, List, Type, Tuple, Dict\n",
    "import math\n",
    "import anndata as ad\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "from matplotlib.axes._axes import Axes\n",
    "import torch\n",
    "import torch.distributions as D\n",
    "from torch.func import vmap, jacrev\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "from sklearn.datasets import make_moons, make_circles\n",
    "import torch.nn.functional as F\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e98a63f9-469b-4f22-9da0-a88d91f27b7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of latent space: (2110, 50)\n",
      "[[-0.73999023 -0.30417988 -1.285224   ...  1.3769633  -1.2980818\n",
      "  -2.4973695 ]\n",
      " [-1.6311297   0.79522806  0.57356    ...  0.01298059  1.5286484\n",
      "  -0.33341846]\n",
      " [-1.7894255  -1.0775845  -0.04044178 ... -2.2817814   0.2767796\n",
      "   0.13969077]\n",
      " ...\n",
      " [-0.51170725  1.1472821  -1.6270131  ... -0.8541527  -0.26255128\n",
      "  -0.5412597 ]\n",
      " [ 3.331458    2.1567702   0.62212026 ... -0.98680913  0.24760334\n",
      "  -0.55045176]\n",
      " [ 1.4783815   0.40659148 -0.41529042 ... -0.87594026 -0.26800925\n",
      "  -0.2350354 ]]\n"
     ]
    }
   ],
   "source": [
    "# Load the encoded data from the autoencoder\n",
    "input_file_path = \"/dtu/blackhole/06/213542/paperdata/pbmc3k_train_with_latent.h5ad\"\n",
    "adata = ad.read_h5ad(input_file_path)\n",
    "\n",
    "# Access latent representation\n",
    "latent = adata.obsm[\"X_latent\"]\n",
    "# make it to a tensor and save in GPU\n",
    "latent_tensor = torch.tensor(latent, dtype=torch.float32, device = device)\n",
    "print(\"Shape of latent space:\", latent.shape)\n",
    "print(latent)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2d9554cd-e92b-4ffd-a307-89cfcadca6ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a way of encoding our data for empirical data\n",
    "class EmpiricalDistribution(torch.nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        data: torch.Tensor,\n",
    "        bandwidth: Optional[float] = None,\n",
    "        compute_log_density: bool = True,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        assert data.dim() == 2, \"data must be shape (N, D)\"\n",
    "        data = data.contiguous()\n",
    "        \n",
    "        self.register_buffer(\"data\", data)   # (N, D)\n",
    "        self.n = data.shape[0]\n",
    "        self.data_dim = data.shape[1]        # <-- renamed attribute\n",
    "        self.compute_log_density_flag = compute_log_density\n",
    "\n",
    "        # Bandwidth estimation\n",
    "        if bandwidth is None:\n",
    "            std = torch.std(data, dim=0).mean().item()\n",
    "            factor = (4.0 / (self.data_dim + 2.0)) ** (1.0 / (self.data_dim + 4.0))\n",
    "            bw = factor * (self.n ** (-1.0 / (self.data_dim + 4.0))) * (std + 1e-6)\n",
    "            self.bandwidth = torch.tensor(float(bw), device=self.data.device)\n",
    "        else:\n",
    "            self.bandwidth = torch.tensor(float(bandwidth), device=self.data.device)\n",
    "\n",
    "        self._log_const = -0.5 * self.data_dim * math.log(2.0 * math.pi) - self.data_dim * torch.log(self.bandwidth).item()\n",
    "\n",
    "    @property\n",
    "    def dim(self):\n",
    "        return self.data_dim\n",
    "    def sample(self, num_samples: int) -> torch.Tensor:\n",
    "        idx = torch.randint(0, self.n, (num_samples,), device=self.data.device)\n",
    "        return self.data[idx]\n",
    "\n",
    "    def log_density(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        if not self.compute_log_density_flag:\n",
    "            raise RuntimeError(\"log_density disabled (compute_log_density=False).\")\n",
    "\n",
    "        assert x.dim() == 2 and x.shape[1] == self.data_dim\n",
    "\n",
    "        x = x.to(self.data.device)\n",
    "        x_norm2 = (x ** 2).sum(dim=1, keepdim=True)\n",
    "        data_norm2 = (self.data ** 2).sum(dim=1).unsqueeze(0)\n",
    "        cross = x @ self.data.t()\n",
    "        d2 = x_norm2 + data_norm2 - 2.0 * cross\n",
    "\n",
    "        sigma2 = (self.bandwidth ** 2).item()\n",
    "        exponents = -0.5 * d2 / (sigma2 + 1e-12)\n",
    "        lse = torch.logsumexp(exponents, dim=1, keepdim=True)\n",
    "\n",
    "        log_prob = math.log(1.0 / self.n) + lse + self._log_const\n",
    "        return log_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cbd6c723-2603-4ee4-a2e4-4444bf07beb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-67.2104],\n",
      "        [-67.2105],\n",
      "        [-67.2104]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# lets test if the empirical distribution class actually works\n",
    "# the data has to be a torch tensor\n",
    "\n",
    "dist = EmpiricalDistribution(latent_tensor)\n",
    "samples = dist.sample(3)\n",
    "logp = dist.log_density(samples)\n",
    "print(logp)\n",
    "\n",
    "# it seems to work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7cbc68f2-372e-428d-b98e-4d1f3a4d9b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we have to have a class that can draw from a Gaussian distribution\n",
    "\n",
    "class Gaussian(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Multivariate Gaussian distribution\n",
    "    \"\"\"\n",
    "    def __init__(self, mean: torch.Tensor, cov: torch.Tensor):\n",
    "        \"\"\"\n",
    "        mean: shape (dim,)\n",
    "        cov: shape (dim,dim)\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.register_buffer(\"mean\", mean)\n",
    "        self.register_buffer(\"cov\", cov)\n",
    "\n",
    "    @property\n",
    "    def dim(self) -> int:\n",
    "        return self.mean.shape[0]\n",
    "\n",
    "    @property\n",
    "    def distribution(self):\n",
    "        return D.MultivariateNormal(self.mean, self.cov, validate_args=False)\n",
    "\n",
    "    def sample(self, num_samples) -> torch.Tensor:\n",
    "        return self.distribution.sample((num_samples,))\n",
    "        \n",
    "    def log_density(self, x: torch.Tensor):\n",
    "        return self.distribution.log_prob(x).view(-1, 1)\n",
    "\n",
    "    @classmethod\n",
    "    def isotropic(cls, dim: int, std: float) -> \"Gaussian\":\n",
    "        mean = torch.zeros(dim)\n",
    "        cov = torch.eye(dim) * std ** 2\n",
    "        return cls(mean, cov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3433c200-5e40-4dc6-8fca-201b13c7b531",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We want to go with Gaussian probability path, therefore we need to load functions for alpha and beta\n",
    "class LinearAlpha():\n",
    "    \"\"\"Implements alpha_t = t\"\"\"\n",
    "    \n",
    "    def __call__(self, t: torch.Tensor) -> torch.Tensor:\n",
    "        return t  # linear in time\n",
    "\n",
    "    def dt(self, t: torch.Tensor) -> torch.Tensor:\n",
    "        return torch.ones_like(t)  # derivative of t is 1\n",
    "\n",
    "\n",
    "class LinearBeta():\n",
    "    \"\"\"Implements beta_t = 1 - t\"\"\"\n",
    "    \n",
    "    def __call__(self, t: torch.Tensor) -> torch.Tensor:\n",
    "        return 1 - t\n",
    "\n",
    "    def dt(self, t: torch.Tensor) -> torch.Tensor:\n",
    "        return -torch.ones_like(t)  # derivative of 1 - t is -1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "98ba9fdd-c53b-4e8e-b80d-a142773b04aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GaussianConditionalProbabilityPath():\n",
    "    def __init__(self, p_data, alpha, beta):\n",
    "        self.p_data = p_data \n",
    "        p_simple = Gaussian.isotropic(p_data.dim, 1.0)\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "\n",
    "    def sample_conditioning_variable(self, num_samples: int) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Samples the conditioning variable z ~ p_data(x)\n",
    "        Args:\n",
    "            - num_samples: the number of samples\n",
    "        Returns:\n",
    "            - z: samples from p(z), (num_samples, dim)\n",
    "        \"\"\"\n",
    "        return self.p_data.sample(num_samples)\n",
    "    \n",
    "    def sample_conditional_path(self, z: torch.Tensor, t: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Samples from the conditional distribution p_t(x|z) = N(alpha_t * z, beta_t**2 * I_d)\n",
    "        Args:\n",
    "            - z: conditioning variable (num_samples, dim)\n",
    "            - t: time (num_samples, 1)\n",
    "        Returns:\n",
    "            - x: samples from p_t(x|z), (num_samples, dim)\n",
    "        \"\"\"\n",
    "        return self.alpha(t) * z + self.beta(t) * torch.randn_like(z)\n",
    "        \n",
    "    def conditional_vector_field(self, x: torch.Tensor, z: torch.Tensor, t: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Evaluates the conditional vector field u_t(x|z)\n",
    "        Note: Only defined on t in [0,1)\n",
    "        Args:\n",
    "            - x: position variable (num_samples, dim)\n",
    "            - z: conditioning variable (num_samples, dim)\n",
    "            - t: time (num_samples, 1)\n",
    "        Returns:\n",
    "            - conditional_vector_field: conditional vector field (num_samples, dim)\n",
    "        \"\"\" \n",
    "        alpha_t = self.alpha(t) # (num_samples, 1)\n",
    "        beta_t = self.beta(t) # (num_samples, 1)\n",
    "        dt_alpha_t = self.alpha.dt(t) # (num_samples, 1)\n",
    "        dt_beta_t = self.beta.dt(t) # (num_samples, 1)\n",
    "\n",
    "        return (dt_alpha_t - dt_beta_t / beta_t * alpha_t) * z + dt_beta_t / beta_t * x\n",
    "\n",
    "    def conditional_score(self, x: torch.Tensor, z: torch.Tensor, t: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Evaluates the conditional score of p_t(x|z) = N(alpha_t * z, beta_t**2 * I_d)\n",
    "        Note: Only defined on t in [0,1)\n",
    "        Args:\n",
    "            - x: position variable (num_samples, dim)\n",
    "            - z: conditioning variable (num_samples, dim)\n",
    "            - t: time (num_samples, 1)\n",
    "        Returns:\n",
    "        - conditional_score: conditional score (num_samples, dim)\n",
    "        \"\"\" \n",
    "        alpha_t = self.alpha(t)\n",
    "        beta_t = self.beta(t)\n",
    "        return (z * alpha_t - x) / beta_t ** 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8b44fee9-b80d-4755-ba62-3f83f82a5d6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.GaussianConditionalProbabilityPath object at 0x7fe331b02a90>\n"
     ]
    }
   ],
   "source": [
    "emp_dist = dist\n",
    "alpha = LinearAlpha()\n",
    "beta = LinearBeta()\n",
    "path = GaussianConditionalProbabilityPath(\n",
    "    p_data=emp_dist,\n",
    "    alpha=alpha,\n",
    "    beta=beta\n",
    ")\n",
    "print(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "901c8e9e-c97e-49a9-8c88-a2645798df18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now that we were able to construct a Gaussian probability path, we have to be able to make a conditional vector field\n",
    "\n",
    "class ConditionalVectorFieldODE():\n",
    "    def __init__(self, path, z: torch.Tensor):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "        - path: the ConditionalProbabilityPath object to which this vector field corresponds\n",
    "        - z: the conditioning variable, (1, dim)\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.path = path\n",
    "        self.z = z\n",
    "\n",
    "    def drift_coefficient(self, x: torch.Tensor, t: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Returns the conditional vector field u_t(x|z)\n",
    "        Args:\n",
    "            - x: state at time t, shape (bs, dim)\n",
    "            - t: time, shape (bs,.)\n",
    "        Returns:\n",
    "            - u_t(x|z): shape (batch_size, dim)\n",
    "        \"\"\"\n",
    "        bs = x.shape[0]\n",
    "        z = self.z.expand(bs, *self.z.shape[1:])\n",
    "        return self.path.conditional_vector_field(x,z,t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8fbd6bfb-437d-45e7-a33c-5f97c26691f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we somehow want to model the marginal vector field from the conditonal vector field\n",
    "# for that we will use eulers:\n",
    "class EulerSimulator():\n",
    "    def __init__(self, ode, z: torch.Tensor):\n",
    "        self.ode = ode\n",
    "        self.z = z\n",
    "\n",
    "    def step(self, xt: torch.Tensor, t: torch.Tensor, h: float):\n",
    "        \n",
    "        # Expand z to match batch size\n",
    "        if self.z.shape[0] == 1:\n",
    "            z_exp = self.z.expand(xt.shape[0], -1)\n",
    "        else:\n",
    "            z_exp = self.z\n",
    "        dx = self.ode.drift_coefficient(xt, t, z_exp)\n",
    "        return xt + dx * h\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "302131ba-68b1-4470-818b-979253a25ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch.nn as nn\n",
    "\n",
    "class TimeEmbedder(nn.Module):\n",
    "    def __init__(self, embed_dim=32, max_freq=1e4):\n",
    "        super().__init__()\n",
    "        self.embed_dim = embed_dim\n",
    "        self.max_freq = max_freq\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(embed_dim, embed_dim),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(embed_dim, embed_dim),\n",
    "            nn.SiLU()\n",
    "        )\n",
    "\n",
    "    def forward(self, t):\n",
    "        freqs = torch.exp(torch.linspace(0, math.log(self.max_freq), self.embed_dim // 2, device=t.device))\n",
    "        args = t * freqs\n",
    "        emb = torch.cat([torch.sin(args), torch.cos(args)], dim=-1)\n",
    "        return self.mlp(emb)\n",
    "\n",
    "class ResNetBlock(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super().__init__()\n",
    "        self.block = nn.Sequential(\n",
    "            nn.Linear(dim, dim),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(dim, dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x + self.block(x)\n",
    "\n",
    "class NeuralVectorField(nn.Module):\n",
    "    def __init__(self, latent_dim, hidden_dim=128, n_resblocks=3, time_embed_dim=32):\n",
    "        super().__init__()\n",
    "        self.x_proj = nn.Linear(latent_dim, hidden_dim)\n",
    "        self.z_proj = nn.Linear(latent_dim, hidden_dim)\n",
    "        self.time_embedder = TimeEmbedder(time_embed_dim)\n",
    "\n",
    "        self.resblocks = nn.ModuleList([\n",
    "            ResNetBlock(hidden_dim*2 + time_embed_dim) for _ in range(n_resblocks)\n",
    "        ])\n",
    "        self.output_layer = nn.Linear(hidden_dim*2 + time_embed_dim, latent_dim)\n",
    "\n",
    "    def forward(self, x, z, t):\n",
    "        xh = self.x_proj(x)\n",
    "        zh = self.z_proj(z)\n",
    "        th = self.time_embedder(t)\n",
    "        h = torch.cat([xh, zh, th], dim=-1)\n",
    "        for block in self.resblocks:\n",
    "            h = block(h)\n",
    "        return self.output_layer(h)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2986d674-1040-4060-afd7-e60f1fdd74c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] Loss: 1.200364\n",
      "[50] Loss: 0.176225\n",
      "[100] Loss: 0.108974\n",
      "[150] Loss: 0.062044\n",
      "[200] Loss: 0.052081\n",
      "[250] Loss: 0.045564\n",
      "[300] Loss: 0.037275\n",
      "[350] Loss: 0.036976\n",
      "[400] Loss: 0.032999\n",
      "[450] Loss: 0.029546\n",
      "[500] Loss: 0.029356\n",
      "[550] Loss: 0.026791\n",
      "[600] Loss: 0.029909\n",
      "[650] Loss: 0.028649\n",
      "[700] Loss: 0.025951\n",
      "[750] Loss: 0.025470\n",
      "[800] Loss: 0.022430\n",
      "[850] Loss: 0.023387\n",
      "[900] Loss: 0.023360\n",
      "[950] Loss: 0.023436\n",
      "[1000] Loss: 0.021695\n",
      "[1050] Loss: 0.019885\n",
      "[1100] Loss: 0.022355\n",
      "[1150] Loss: 0.021102\n",
      "[1200] Loss: 0.021124\n",
      "[1250] Loss: 0.019362\n",
      "[1300] Loss: 0.019131\n",
      "[1350] Loss: 0.019317\n",
      "[1400] Loss: 0.018037\n",
      "[1450] Loss: 0.018901\n",
      "[1500] Loss: 0.019989\n",
      "[1550] Loss: 0.018504\n",
      "[1600] Loss: 0.018839\n",
      "[1650] Loss: 0.018711\n",
      "[1700] Loss: 0.019824\n",
      "[1750] Loss: 0.019214\n",
      "[1800] Loss: 0.019012\n",
      "[1850] Loss: 0.017719\n",
      "[1900] Loss: 0.018242\n",
      "[1950] Loss: 0.018228\n",
      "[2000] Loss: 0.017979\n",
      "[2050] Loss: 0.016595\n",
      "[2100] Loss: 0.018450\n",
      "[2150] Loss: 0.018540\n",
      "[2200] Loss: 0.017151\n",
      "[2250] Loss: 0.017496\n",
      "[2300] Loss: 0.018086\n",
      "[2350] Loss: 0.017045\n",
      "[2400] Loss: 0.016869\n",
      "[2450] Loss: 0.016143\n",
      "[2500] Loss: 0.019524\n",
      "[2550] Loss: 0.016406\n",
      "[2600] Loss: 0.019150\n",
      "[2650] Loss: 0.015908\n",
      "[2700] Loss: 0.018241\n",
      "[2750] Loss: 0.016832\n",
      "[2800] Loss: 0.016818\n",
      "[2850] Loss: 0.015491\n",
      "[2900] Loss: 0.017378\n",
      "[2950] Loss: 0.014201\n",
      "[3000] Loss: 0.014193\n",
      "[3050] Loss: 0.015971\n",
      "[3100] Loss: 0.014834\n",
      "[3150] Loss: 0.016061\n",
      "[3200] Loss: 0.017872\n",
      "[3250] Loss: 0.017456\n",
      "[3300] Loss: 0.016784\n",
      "[3350] Loss: 0.016863\n",
      "[3400] Loss: 0.017148\n",
      "[3450] Loss: 0.016549\n",
      "[3500] Loss: 0.018781\n",
      "[3550] Loss: 0.015696\n",
      "[3600] Loss: 0.015853\n",
      "[3650] Loss: 0.016668\n",
      "[3700] Loss: 0.015343\n",
      "[3750] Loss: 0.016919\n",
      "[3800] Loss: 0.015769\n",
      "[3850] Loss: 0.016255\n",
      "[3900] Loss: 0.014859\n",
      "[3950] Loss: 0.014147\n",
      "[4000] Loss: 0.015425\n",
      "[4050] Loss: 0.015901\n",
      "[4100] Loss: 0.015035\n",
      "[4150] Loss: 0.014775\n",
      "[4200] Loss: 0.013785\n",
      "[4250] Loss: 0.015522\n",
      "[4300] Loss: 0.017076\n",
      "[4350] Loss: 0.015174\n",
      "[4400] Loss: 0.014784\n",
      "[4450] Loss: 0.015513\n",
      "[4500] Loss: 0.015705\n",
      "[4550] Loss: 0.015387\n",
      "[4600] Loss: 0.014386\n",
      "[4650] Loss: 0.014690\n",
      "[4700] Loss: 0.015479\n",
      "[4750] Loss: 0.012928\n",
      "[4800] Loss: 0.015306\n",
      "[4850] Loss: 0.017350\n",
      "[4900] Loss: 0.014218\n",
      "[4950] Loss: 0.015316\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "batch_size = 2110\n",
    "num_epochs = 5000\n",
    "learning_rate = 1e-3\n",
    "latent_dim = latent_tensor.shape[1]  # e.g., 50\n",
    "\n",
    "vf_model = NeuralVectorField(latent_dim=latent_dim).to(device)\n",
    "optimizer = torch.optim.AdamW(vf_model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Initialize GaussianConditionalProbabilityPath and ConditionalVectorFieldODE\n",
    "path = GaussianConditionalProbabilityPath(emp_dist, alpha, beta)  # define alpha, beta\n",
    "#cvf_ode = ConditionalVectorFieldODE(path, z=torch.zeros(1, latent_dim, device=device))\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # --- Sample conditioning variable z ---\n",
    "    z = emp_dist.sample(batch_size).to(device)\n",
    "    # lets try sampling from real points\n",
    "    #indices = torch.randint(0, latent_tensor.shape[0], (batch_size,))\n",
    "    #z = latent_tensor[indices].to(device)\n",
    "    # --- Sample time ---\n",
    "    t = torch.rand(batch_size, 1, device=device)\n",
    "\n",
    "    # --- Sample x_t from conditional path ---\n",
    "    with torch.no_grad():\n",
    "        x = path.sample_conditional_path(z, t)\n",
    "        u_target = path.conditional_vector_field(x, z, t)\n",
    "\n",
    "    # --- Normalize target ---\n",
    "    u_mean = u_target.mean(dim=0, keepdim=True)\n",
    "    u_std = u_target.std(dim=0, keepdim=True) + 1e-6\n",
    "    u_target_norm = (u_target - u_mean) / u_std\n",
    "\n",
    "    # --- Forward pass ---\n",
    "    v_pred = vf_model(x, z, t)\n",
    "\n",
    "    # --- Loss ---\n",
    "    loss = F.mse_loss(v_pred, u_target_norm)\n",
    "\n",
    "    # --- Backprop ---\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    torch.nn.utils.clip_grad_norm_(vf_model.parameters(), max_norm=1.0)\n",
    "    optimizer.step()\n",
    "\n",
    "    if epoch % 50 == 0:\n",
    "        print(f\"[{epoch}] Loss: {loss.item():.6f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5c1cd184-80d2-48a0-93ac-38e25a43c206",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(vf_model.state_dict(), \"vf_model_weights.pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b46c5956-d23f-463a-8541-7e85d2e52888",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we want to save the best vector field:\n",
    "class LearnedVectorFieldODE():\n",
    "    def __init__(self, vf_model):\n",
    "        self.vf_model = vf_model\n",
    "\n",
    "    def drift_coefficient(self, x: torch.Tensor, t: torch.Tensor, z: torch.Tensor) -> torch.Tensor:\n",
    "        # x, z: (batch_size, latent_dim)\n",
    "        # t: (batch_size, 1)\n",
    "        return self.vf_model(x, z, t)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2376f019-c84c-4f60-bc09-84ec341a1511",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrap the trained neural network\n",
    "learned_ode = LearnedVectorFieldODE(vf_model)\n",
    "\n",
    "# Save the wrapper\n",
    "torch.save(learned_ode, \"learned_ode.pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d6f33abc-c1b8-410a-bc3c-8e047d42ce30",
   "metadata": {},
   "outputs": [
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 15.77 GiB of which 18.19 MiB is free. Process 3264432 has 684.00 MiB memory in use. Process 3599363 has 1.93 GiB memory in use. Process 3621337 has 4.53 GiB memory in use. Process 3644582 has 384.00 MiB memory in use. Including non-PyTorch memory, this process has 8.23 GiB memory in use. Of the allocated memory 7.29 GiB is allocated by PyTorch, and 587.88 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mOutOfMemoryError\u001b[39m                          Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 30\u001b[39m\n\u001b[32m     28\u001b[39m \u001b[38;5;66;03m# Euler integration\u001b[39;00m\n\u001b[32m     29\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_steps):\n\u001b[32m---> \u001b[39m\u001b[32m30\u001b[39m     x = \u001b[43msimulator\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     31\u001b[39m     trajectory.append(x.clone())\n\u001b[32m     32\u001b[39m     t = t + dt\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 15\u001b[39m, in \u001b[36mEulerSimulator.step\u001b[39m\u001b[34m(self, xt, t, h)\u001b[39m\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     14\u001b[39m     z_exp = \u001b[38;5;28mself\u001b[39m.z\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m dx = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mode\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdrift_coefficient\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mz_exp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     16\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m xt + dx * h\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 9\u001b[39m, in \u001b[36mLearnedVectorFieldODE.drift_coefficient\u001b[39m\u001b[34m(self, x, t, z)\u001b[39m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdrift_coefficient\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: torch.Tensor, t: torch.Tensor, z: torch.Tensor) -> torch.Tensor:\n\u001b[32m      7\u001b[39m     \u001b[38;5;66;03m# x, z: (batch_size, latent_dim)\u001b[39;00m\n\u001b[32m      8\u001b[39m     \u001b[38;5;66;03m# t: (batch_size, 1)\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mvf_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mz\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/venv_1/lib/python3.11/site-packages/torch/nn/modules/module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/venv_1/lib/python3.11/site-packages/torch/nn/modules/module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 52\u001b[39m, in \u001b[36mNeuralVectorField.forward\u001b[39m\u001b[34m(self, x, z, t)\u001b[39m\n\u001b[32m     50\u001b[39m h = torch.cat([xh, zh, th], dim=-\u001b[32m1\u001b[39m)\n\u001b[32m     51\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m block \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.resblocks:\n\u001b[32m---> \u001b[39m\u001b[32m52\u001b[39m     h = \u001b[43mblock\u001b[49m\u001b[43m(\u001b[49m\u001b[43mh\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     53\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.output_layer(h)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/venv_1/lib/python3.11/site-packages/torch/nn/modules/module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/venv_1/lib/python3.11/site-packages/torch/nn/modules/module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 32\u001b[39m, in \u001b[36mResNetBlock.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m     31\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[32m---> \u001b[39m\u001b[32m32\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m x + \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mblock\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/venv_1/lib/python3.11/site-packages/torch/nn/modules/module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/venv_1/lib/python3.11/site-packages/torch/nn/modules/module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/venv_1/lib/python3.11/site-packages/torch/nn/modules/container.py:250\u001b[39m, in \u001b[36mSequential.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    246\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    247\u001b[39m \u001b[33;03mRuns the forward pass.\u001b[39;00m\n\u001b[32m    248\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    249\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m250\u001b[39m     \u001b[38;5;28minput\u001b[39m = \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    251\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/venv_1/lib/python3.11/site-packages/torch/nn/modules/module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/venv_1/lib/python3.11/site-packages/torch/nn/modules/module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/venv_1/lib/python3.11/site-packages/torch/nn/modules/linear.py:134\u001b[39m, in \u001b[36mLinear.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    130\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) -> Tensor:\n\u001b[32m    131\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    132\u001b[39m \u001b[33;03m    Runs the forward pass.\u001b[39;00m\n\u001b[32m    133\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m134\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mOutOfMemoryError\u001b[39m: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 15.77 GiB of which 18.19 MiB is free. Process 3264432 has 684.00 MiB memory in use. Process 3599363 has 1.93 GiB memory in use. Process 3621337 has 4.53 GiB memory in use. Process 3644582 has 384.00 MiB memory in use. Including non-PyTorch memory, this process has 8.23 GiB memory in use. Of the allocated memory 7.29 GiB is allocated by PyTorch, and 587.88 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# Number of samples and latent dimension\n",
    "n_samples = 2110\n",
    "latent_dim = latent_tensor.shape[1]\n",
    "\n",
    "# Starting points (pure noise)\n",
    "x = torch.randn(n_samples, latent_dim, device=device)\n",
    "\n",
    "# Unconditional generation: use a single zero vector as z\n",
    "z = torch.zeros(1, latent_dim, device=device)\n",
    "\n",
    "# Wrap the trained neural network as an ODE\n",
    "learned_ode = LearnedVectorFieldODE(vf_model)\n",
    "\n",
    "# Euler simulator with unconditional z\n",
    "simulator = EulerSimulator(learned_ode, z)\n",
    "\n",
    "# Simulation parameters\n",
    "t0, t1 = 0.0, 1.0\n",
    "n_steps = 500\n",
    "dt = (t1 - t0) / n_steps\n",
    "\n",
    "# Store trajectory (optional, can skip intermediate steps if memory is tight)\n",
    "trajectory = [x.clone()]\n",
    "t = torch.full((n_samples, 1), t0, device=device)\n",
    "\n",
    "# Euler integration\n",
    "for _ in range(n_steps):\n",
    "    x = simulator.step(x, t, dt)\n",
    "    trajectory.append(x.clone())\n",
    "    t = t + dt\n",
    "\n",
    "# Final generated samples\n",
    "generated_cells = trajectory[-1]\n",
    "print(generated_cells.shape)  # (n_samples, latent_dim)\n",
    "\n",
    "# Save the generated latent space\n",
    "torch.save(generated_cells, \"generated_latent.pt\")\n",
    "print(generated_cells)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6943fb65-fb24-41be-b2ec-168ab5b58161",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
